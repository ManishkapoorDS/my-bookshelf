author: Mahadevan, Sridhar
author_list:
- affiliation: []
  family: Mahadevan
  given: Sridhar
citations:
- unstructured: Baird, L. Personal Communication.
- doi: 10.1016/B978-1-55860-377-6.50013-X
  unstructured: 'Baird, L., (1995). Residual algorithms: Reinforcement learning with
    function approximation. InProceedings of the 12th International Conference on
    Machine Learning, pages 30?37. Morgan Kaufmann.'
- author: A. Barto
  doi: 10.1016/0004-3702(94)00011-O
  first-page: '81'
  issue: '1'
  journal-title: Artificial Intelligence
  unstructured: Barto, A., Bradtke, S. & Singh, S., (1995). Learning to act using
    real-time dynamic programming.Artificial Intelligence, 72(1):81?138.
  volume: '72'
  year: '1995'
- doi: 10.1109/TAC.1982.1102980
  unstructured: Bertsekas, D., (1982). Distributed dynamic programming.IEEE Transactions
    on Automatic Control. AC-27(3)
- unstructured: 'Bertsekas, D., (1987).Dynamic Programming: Deterministic and Stochastic
    Models. Prentice-Hall.'
- author: D. Blackwell
  doi: 10.1214/aoms/1177704593
  first-page: '719'
  journal-title: Annals of Mathematical Statistics
  unstructured: Blackwell, D., (1962). Discrete dynamic programming.Annals of Mathematical
    Statistics, 33 719?726.
  volume: '33'
  year: '1962'
- unstructured: Boutilier, C. & Puterman, M., (1995). Process-oriented planning and
    average-reward optimality. InProceedings of the Fourteenth JCAI, pages 1096?1103.
    Morgan Kaufmann.
- unstructured: Dayan, P. & Hinton, G., (1992). Feudal reinforcement learning. InNeural
    Information Processing Systems (NIPS), pages 271?278.
- author: E. Denardo
  doi: 10.1287/opre.18.2.279
  first-page: '272'
  journal-title: Operations Research
  unstructured: Denardo, E., (1970). Computing a bias-optimal policy in a discrete-time
    Markov decision problem.Operations Research, 18:272?289.
  volume: '18'
  year: '1970'
- unstructured: Dent, L., Boticario, J., McDermott, J., Mitchell, T. & Zabowski, D.,
    (1992). A personal learning apprentice InProceedings of the Tenth National Conference
    on Artificial Intelligence (AAAI), pages 96?103. MIT Press.
- doi: 10.1007/978-94-009-1099-7
  unstructured: Engelberger, J., (1989).Robotics in Service. MIT Press.
- author: A. Federgruen
  doi: 10.1287/moor.9.3.319
  first-page: '319'
  journal-title: Mathematics of Operations Research
  unstructured: Federgruen, A. & Schweitzer, P., (1984). Successive approximation
    methods for solving nested functional equations in Markov decision problems.Mathematics
    of Operations Research, 9:319?344.
  volume: '9'
  year: '1984'
- author: M. Haviv
  doi: 10.1007/BF02055583
  first-page: '229'
  journal-title: Annals of Operations Research
  unstructured: Haviv, M. & Puterman, M., (1991) An improved algorithm for solving
    communicating average reward markov decision processes.Annals of Operations Research,
    28:229?242.
  volume: '28'
  year: '1991'
- author: A. Hordijk
  doi: 10.1214/aos/1176343008
  first-page: '203'
  journal-title: Annals of Statistics
  unstructured: Hordijk, A. & Tijms, H., (1975). A modified form of the iterative
    method of dynamic programming.Annals of Statistics, 3:203?208.
  volume: '3'
  year: '1975'
- unstructured: Howard, R., (1960).Dynamic Programming and Markov Processes. MIT Press.
- unstructured: Jalali, A. & Ferguson, M., (1989). Computationally efficient adaptive
    control algorithms for Markov chains InProceedings of the 28th IEEE Conference
    on Decision and Control, pages 1283?1288.
- doi: 10.1109/CDC.1990.203839
  unstructured: Jalali, A. & Ferguson, M., (1990). A distributed asynchronous algorithm
    for expected average cost dynamic programming. InProceedings of the 29th IEEE
    Conference on Dectsion and Control. pages 1394?1395.
- doi: 10.1016/B978-1-55860-307-3.50028-9
  unstructured: 'Kaelbling, L., (1993a). Hierarchical learning in stochastic domains:
    Preliminary results. InProceedings of the Tenth International Conference on Machine
    Learning, pages 167?173 Morgan Kaufmann.'
- doi: 10.7551/mitpress/4168.001.0001
  unstructured: Kaelbling, L., (1993b)Learning in Embedded Systems. MIT Press.
- unstructured: Lin, L., (1993).Reinforcement Learning for Robots using Neural Networks.
    PhD thesis. Carnegie-Mellon Univ.
- unstructured: Mahadevan, S. A model-based bias-optimal reinforcement learning algorithm.
    In preparation.
- doi: 10.1016/B978-1-55860-247-2.50042-5
  unstructured: Mahadevan, S., (1992). Enhancing transfer in reinforcement learning
    by building stochastic models of robot actions. InProceedings of the Seventh International
    Conference on Machine Learning, pages 290?299 Morgan Kaufmann.
- doi: 10.1016/B978-1-55860-335-6.50028-3
  unstructured: 'Mahadevan, S., (1994). To discount or not to discount in reinforcement
    learning: A case study comparing R-learning and Q-learning. InProceedings of the
    Eleventh International Conference on Machine Learning. pages 164?172. Morgan Kaufmann.'
- unstructured: Mahadevan, S. & Baird, L. Value function approximation in average
    reward reinforcement learning. In preparation.
- author: S. Mahadevan
  doi: 10.1016/0004-3702(92)90058-6
  first-page: '311'
  journal-title: Artificial Intelligence
  unstructured: Mahadevan, S. & Connell, J., (1992). Automatic programming of behavior-based
    robots using reinforcement learning.Artificial Intelligence, 55:311?365. Appeared
    originally as IBM TR RC16359. Dec 1990.
  volume: '55'
  year: '1992'
- doi: 10.1016/B978-1-55860-200-7.50069-6
  unstructured: 'Moore, A., (1991). Variable resolution dynamic programming: Efficiently
    learning action maps in multivariate real-valued state spaces. InProceedings of
    the Eighth International Workshop on Machine Learning, pages 333?337. Morgan Kaufmann.'
- unstructured: 'Narendra, K. & Thathachar, M., (1989).Learning Automata: An Introduction.
    Prentice Hall.'
- doi: 10.1002/9780470316887
  unstructured: 'Puterman, M., (1994).Markov Decision Processes: Discrete Dynamic
    Stochastic Programming. John Wiley.'
- unstructured: Ross, S., (1983).Introduction to Stochastic Dynamic Programming. Academic
    Press.
- doi: 10.1016/B978-1-55860-307-3.50042-3
  unstructured: Salganicoff, M., (1993). Density-adaptive learning and forgetting.
    InProceedings of the Tenth International Conference on Machine Learning, pages
    276?283. Morgan Kaufmann.
- doi: 10.1016/B978-1-55860-307-3.50045-9
  unstructured: Schwartz, A., (1993). A reinforcement learning method for maximizing
    undiscounted rewards. InProceedings of the Tenth International Conference on Machine
    Learning, pages 298?305. Morgan Kaufmann.
- unstructured: Singh, S., (1994a).Learning to Solve Markovian Decision Processes.
    PhD thesis, Univ of Massachusetts, Amherst.
- unstructured: Singh, S., (1994b) Reinforcement learning algorithms for average-payoff
    Markovian decision processes. InProceedings of the 12th AAAI. MIT Press.
- doi: 10.1007/BF00115009
  unstructured: Sutton, R., (1988). Learning to predict by the method of temporal
    differences.Machine Learning, 3:9?44.
- doi: 10.1016/B978-1-55860-141-3.50030-4
  unstructured: Sutton, R., (1990). Integrated architectures for learning, planning,
    and reacting based on approximating dynamic programming. InProceedings of the
    Seventh International Conference on Machine Learning, pages 216?224. Morgan Kaufmann.
- doi: 10.1007/978-1-4615-3618-5
  unstructured: Sutton, R., editor, (1992).Reinforcement Learning. Kluwer Academic
    Press. Special Issue of Machine Learning Journal Vol 8, Nos 3?4, May 1992.
- unstructured: Tadepall, P. Personal Communication.
- unstructured: 'Tadepalli, P. & Ok, D., (1994). H learning: A reinforcement learning
    method to optimize undiscounted average reward. Technical Report 94-30-01, Oregon
    State Univ.'
- doi: 10.1007/978-1-4615-3618-5_3
  unstructured: Tesauro, G., (1992). Practical issues in temporal difference learning.
    In R. Sutton, editor,Reinforcement Learning. Kluwer Academic Publishers.
- unstructured: 'Thrun, S. The role of exploration in learning control. In D. A. White
    and D. A. Sofge, editors,Handbook of Intelligent Control: Neural, Fuzzy, and Adaptive
    Approaches. Van Nostrand Reinhold.'
- author: J. Tsitsiklis
  first-page: '185'
  journal-title: Machine Learning
  unstructured: Tsitsiklis, J., (1994). Asynchronous stochastic approximation and
    Q-learning.Machine Learning, 16:185?202.
  volume: '16'
  year: '1994'
- author: A. Veinott
  doi: 10.1214/aoms/1177697379
  first-page: '1635'
  issue: '5'
  journal-title: Annals of Mathematical Statistics
  unstructured: Veinott, A., (1969) Discrete dynamic programming with sensitive discount
    optimality criteria.Annals of Mathematical Statistics, 40(5):1635?1660.
  volume: '40'
  year: '1969'
- unstructured: Watkins, C., (1989).Learning from Delayed Rewards. PhD thesis, King's
    College, Cambridge, England.
- doi: 10.1109/TAC.1986.1104342
  unstructured: Wheeler, R. & Narendra, K., (1986). Decentralized learning in finite
    Markov chains.IEEE Transactions on Automatic Control, AC-31(6)
- author: D. White
  doi: 10.1016/0022-247X(63)90017-9
  first-page: '373'
  journal-title: Journal of Mathematical Analysis and Applications
  unstructured: White, D., (1963). Dynamic programming, markov chains, and the method
    of successive approximationsJournal of Mathematical Analysis and Applications,
    6:373?376.
  volume: '6'
  year: '1963'
- doi: 10.1007/978-1-4615-3184-5_3
  unstructured: Whitehead, S., Karlsson, J. & Tenenberg, J., (1993). Learning multiple
    goal behavior via task decomposition and dynamic policy merging. In J. Connell
    and S. Mahadevan, editors,Robot Learning. Kluwer Academic Publishers.
doc_url: http://link.springer.com/article/10.1007/BF00114727/fulltext.html
doi: 10.1007/bf00114727
files:
- mahadevan-sridharaverage-reward-reinforcement-learning-foundations-algorithms-and-empirical-results1996.data
- mahadevan-sridharaverage-reward-reinforcement-learning-foundations-algorithms-and-empirical-results1996-a.pdf
issue: 1-3
journal: Machine Learning
language: en
pages: 159--195
publisher: Springer Science and Business Media LLC
time-added: 2020-07-12-19:26:30
title: 'Average reward reinforcement learning: Foundations, algorithms, and empirical
  results'
type: article
url: http://dx.doi.org/10.1007/bf00114727
volume: '22'
year: 1996
