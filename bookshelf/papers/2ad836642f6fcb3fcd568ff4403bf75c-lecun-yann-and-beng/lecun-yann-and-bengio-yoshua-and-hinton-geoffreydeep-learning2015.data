<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Deep learning | Nature</title>

    
        
<link rel="preload" href=/static/fonts/HardingText-Regular-Web.b167e675dc.woff2 as="font" type="font/woff2" crossorigin>


<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes"/>



<script>
    (function(e){var t=e.documentElement,n=e.implementation;t.className+=' js';if(n&&n.hasFeature('http://www.w3.org/TR/SVG11/feature#Image','1.1')){t.className+=' svg'}})(document)
</script>

<script data-test="dataLayer">
    dataLayer = [{"content":{"category":{"contentType":"review article","legacy":{"webtrendsPrimaryArticleType":"reviews","webtrendsSubjectTerms":"computer-science;mathematics-and-computing","webtrendsContentCategory":null,"webtrendsContentCollection":"The multidisciplinary nature of machine intelligence;The Go Files","webtrendsContentGroup":"Nature","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Review Article"}},"article":{"doi":"10.1038/nature14539"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Yann LeCun","Yoshua Bengio","Geoffrey Hinton"],"publishedAt":1432684800,"publishedAtString":"2015-05-27","title":"Deep learning","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"nature","title":"nature","volume":"521","issue":"7553"},"authorization":{"status":false},"features":[{"name":"furtherReadingSection","present":true}],"collection":{"id":"csgqqsrfxh;hqwpvkfhrr"}},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"ab_test_nature_rebrand_150_header","active":false},{"name":"ab_test_subscribe_button","active":true},{"name":"ab_test_briefing_new_signup_box","active":true},{"name":"ab_test_briefing_new_banner","active":true},{"name":"ab_test_best_available_version","active":false},{"name":"ab_test_magazine_article_native_ads","active":false},{"name":"ra21","active":true},{"name":"ab_test_author_journal_info","active":false}]},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true}];
</script>
<script src="//cdn.cookielaw.org/consent/792a5a21-3d99-4432-8f70-957d389bf2b9.js" async=""></script>
<script>
    window.abTestSharedArticleRenderer = true;
    window.idpVerifyPrefix = 'https://verify.nature.com';
    window.ra21FeatureFlag = true;
    window.ra21Host = 'https://wayf.springernature.com';
</script>


    <script id="mosaic-loader">
        var scriptList = [
            {match: 'div[data-pan-container]', src: '/static/js/pan-zoom.5b1c5087ae.js'},
            {match: 'math,span.mathjax-tex', src: '/static/js/math.acd6b1bcfe.js'},
            {match: 'div.c-article-metrics__wrapper', src: '/static/js/graphing.f48adf9026.js'}
            
        ];

        (function (win, doc, bundles) {
            var scripts = bundles;

            if (!doc.querySelector) { return; }

            var script = function(attrs) {
                var s = doc.createElement('script');
                for (var attr in attrs) {
                    if (attrs.hasOwnProperty(attr)) {
                        s[attr] = attrs[attr];
                    }
                }
                return s;
            };

            var insertAfter = function(node, dest) {
                dest.parentNode.insertBefore(node, dest.nextSibling);
            };

            win.Component = win.Component || {};
            win.Component.Loader = {
                init: function() {
                    this.main = script({src: '/static/js/nature.38e749f804.js', id: 'mosaic', defer: true});
                    insertAfter(this.main, doc.getElementById('mosaic-loader'));
                },
                loadPageBundles: function() {
                    var lastId = this.main.id;
                    console.log('window.ra21FeatureFlag', window.ra21FeatureFlag);

                    if (!window.ra21FeatureFlag) {
                        scripts.push({match: 'body', src: 'https://verify.nature.com/verify/nature.min.js'});
                    }

                    for (var i = 0; scripts[i]; ++i) {
                        if (doc.querySelector(scripts[i].match)) {
                            insertAfter(script({src: scripts[i].src, id: 'bundle' + i, defer: true}), doc.getElementById(lastId));
                            lastId = 'bundle' + i;
                        }
                    }
                }
            };
            win.Component.Loader.init();

        })(window, document, scriptList);
    </script>


<!-- Anti-flicker snippet for Google Optimize A/B tests on the SREP homepage -->
<style>.async-hide { opacity: 0 !important} </style>
<script id="google-optimize-anti-flicker">
    var flickrFunc = function(a,s,y,n,c,h,i,d,e){s.className+=' '+y;h.start=1*new Date;
        h.end=i=function(){s.className=s.className.replace(RegExp(' ?'+y),'')};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
    };
    var isLocalSrep = document.location.href ? document.location.href === 'http://local-www.nature.com:7890/srep' : false;
    var isQaSrep = document.location.href ? document.location.href === 'https://qa-snpaas-www.nature.com/srep/' : false;
    var isLiveSrep = document.location.href ? document.location.href === 'https://www.nature.com/srep/' : false;
    if (isLocalSrep || isQaSrep || isLiveSrep) {
        flickrFunc(window,document.documentElement,'async-hide','dataLayer',4000, {'GTM-NWDMT9Q':true});
    }
</script>
<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon.f39cb19454.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32.3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16.951651ab72.png>
<link rel="manifest" href=/static/manifest.1a481c42b1.json>
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab.69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.62367f778b.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.e35b3b052c.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">




    
        <link href="/static/css/grade-c-150.4729985977.css" rel="stylesheet"/>
    
     
        <link href="/static/css/grade-c.95232fc63f.css" rel="stylesheet"/>
        
        
            <link id="mustard" rel="stylesheet" type="text/css" href="/static/css/article-150.b4e907f2b3.css" media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)" />
            <link data-test="journal-mosaic-150-css" href="/static/css/journal-mosaic-150.45b57d3078.css" rel="stylesheet"  media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)" />
        
        <link rel="stylesheet" type="text/css" href="/static/css/article-print.9181f48632.css" media="print">
    



    
        
            <style>
                .default-header {
                    border-bottom: 5px solid #222;
                    overflow: hidden;
                    box-sizing: content-box;
                }

                .background-brand-primary,
                .sticky-header .inner-banner,
                .banner {
                    background-color: #fff;
                    color: #222;
                }

                .small-header-icons {
                    width: 65px;
                }

                .sticky-header .small-header-icons {
                    border: 0;
                    background-color: #fff;
                }

                .sticky-header .header-logo img {
                    height: 25px;
                }

                @media only screen and (max-width: 54.688em) {
                    .header-logo img {
                        height: 25px;
                    }
                }

                @media only screen and (max-width: 54.688em) {
                    .small-header-icons {
                        border: 0;
                        background-color: #fff;
                        width: auto;
                    }
                }

                @media only screen and (max-width: 54.688em) {
                    .menu-button,
                    .sticky-header .menu-button {
                        margin-right: 10px;
                    }

                    .nature-research-logo {
                        margin-right: 0;
                    }
                }

                .icon-login-25x25-black {
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTEyLjUgOS40YzIuNiAwIDQuNy0yLjEgNC43LTQuN1MxNS4xIDAgMTIuNSAwIDcuOCAyLjEgNy44IDQuN3MyLjEgNC43IDQuNyA0Ljd6bTQuOCAxLjVjLTIuNSAwLTIuNCA1LTQuOCA1cy0yLjMtNS00LjgtNS02LjEgNC02LjEgOS4zYzAgNS4xIDUuOCA0LjggMTAuOSA0LjhzMTAuOS40IDEwLjktNC43YzAtNS4zLTMuNi05LjQtNi4xLTkuNHoiIGZpbGw9IiMyMjIiLz48L3N2Zz4=);
                }
                .icon-login-25x25-black:hover {
                    color: #069;
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTEyLjUgOS40YzIuNiAwIDQuNy0yLjEgNC43LTQuN1MxNS4xIDAgMTIuNSAwIDcuOCAyLjEgNy44IDQuN3MyLjEgNC43IDQuNyA0Ljd6bTQuOCAxLjVjLTIuNSAwLTIuNCA1LTQuOCA1cy0yLjMtNS00LjgtNS02LjEgNC02LjEgOS4zYzAgNS4xIDUuOCA0LjggMTAuOSA0LjhzMTAuOS40IDEwLjktNC43YzAtNS4zLTMuNi05LjQtNi4xLTkuNHoiIGZpbGw9IiMwNjkiLz48L3N2Zz4=);
                }

                .icon-search-25x25-black {
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTE2LjYgMmMzLjYgMCA2LjYgMyA2LjYgNi42cy0zIDYuNi02LjYgNi42LTYuNi0zLTYuNi02LjZTMTMgMiAxNi42IDJtMC0yYy00LjcgMC04LjQgMy44LTguNCA4LjRzMy44IDguNCA4LjQgOC40UzI1IDEzLjIgMjUgOC40IDIxLjIgMCAxNi42IDB6bS01LjUgMTcuM0wzLjQgMjUgMCAyMS42bDcuNy03LjcgMy40IDMuNHoiIGZpbGw9IiMyMjIiLz48L3N2Zz4=);
                }
                .icon-search-25x25-black:hover {
                    color: #069;
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTE2LjYgMmMzLjYgMCA2LjYgMyA2LjYgNi42cy0zIDYuNi02LjYgNi42LTYuNi0zLTYuNi02LjZTMTMgMiAxNi42IDJtMC0yYy00LjcgMC04LjQgMy44LTguNCA4LjRzMy44IDguNCA4LjQgOC40UzI1IDEzLjIgMjUgOC40IDIxLjIgMCAxNi42IDB6bS01LjUgMTcuM0wzLjQgMjUgMCAyMS42bDcuNy03LjcgMy40IDMuNHoiIGZpbGw9IiMwNjkiLz48L3N2Zz4=);
                }


                .icon-ealert-25x25-black {
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTI1IDMuMUgwdjE4LjhoMjVWMy4xek03LjIgMTUuOWwtMy45IDQuNGMtLjIuMi0uNS4zLS42LjMtLjIgMC0uNS0uMi0uNi0uMy0uMy0uMy0uMy0uOSAwLTEuNEw2IDE0LjVjLjMtLjMuOS0uMyAxLjMgMCAuMi41LjIgMS4xLS4xIDEuNHptNS4zLS45Yy0uMiAwLS4zIDAtLjUtLjJMMi4yIDUuOWMtLjUtLjMtLjUtLjctLjItMS4xLjMtLjUuOC0uNSAxLjEtLjJsOS40IDguNCA5LjQtOC40Yy4zLS4zLjgtLjMgMS4xLjIuMy4zLjMuOS0uMiAxLjFsLTkuNyA4LjljLS4xLjItLjQuMi0uNi4yek0yMyAyMC4zYy0uMi4yLS41LjMtLjYuM3MtLjUtLjItLjYtLjNsLTQuMS00LjRjLS4zLS4zLS4zLS45IDAtMS40LjMtLjMuOS0uMyAxLjMgMGw0LjEgNC40Yy4yLjUuMiAxLjEtLjEgMS40eiIgZmlsbD0iIzIyMiIvPjwvc3ZnPg==);
                }
                .icon-ealert-25x25-black:hover {
                    color: #069;
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTI1IDMuMUgwdjE4LjhoMjVWMy4xek03LjIgMTUuOWwtMy45IDQuNGMtLjIuMi0uNS4zLS42LjMtLjIgMC0uNS0uMi0uNi0uMy0uMy0uMy0uMy0uOSAwLTEuNEw2IDE0LjVjLjMtLjMuOS0uMyAxLjMgMCAuMi41LjIgMS4xLS4xIDEuNHptNS4zLS45Yy0uMiAwLS4zIDAtLjUtLjJMMi4yIDUuOWMtLjUtLjMtLjUtLjctLjItMS4xLjMtLjUuOC0uNSAxLjEtLjJsOS40IDguNCA5LjQtOC40Yy4zLS4zLjgtLjMgMS4xLjIuMy4zLjMuOS0uMiAxLjFsLTkuNyA4LjljLS4xLjItLjQuMi0uNi4yek0yMyAyMC4zYy0uMi4yLS41LjMtLjYuM3MtLjUtLjItLjYtLjNsLTQuMS00LjRjLS4zLS4zLS4zLS45IDAtMS40LjMtLjMuOS0uMyAxLjMgMGw0LjEgNC40Yy4yLjUuMiAxLjEtLjEgMS40eiIgZmlsbD0iIzA2OSIvPjwvc3ZnPg==);
                }

                .icon-submit-25x25-black {
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTE1LjYgMS4zdjUuM2g1LjN2MTdoLTE3VjEuM2gxMS43TTE3IDBIMi43djI1aDE5LjZWNS40aC01LjRMMTcgMHptLS42IDEuM0wyMSA1Ljl2MTcuN0g0VjEuM2gxMi40TTE3IDBIMi43djI1aDE5LjZWNS40TDE3IDB6bS0uNCAxMy41bC0zLjEtMy4xLS44LS44Yy0uMS0uMS0uMy0uMS0uNCAwbC0uOC44LTMuMSAzLjEtLjcuN2MtLjEuMS0uMi4yLS4yLjNzLjEuMi4yLjJoMi43Yy4xIDAgLjIuMS4yLjJ2My4zYzAgLjIuMi40LjQuNGgzYy4yIDAgLjQtLjIuNC0uNHYtMy4zYzAtLjEuMS0uMi4yLS4yaDIuN2MuMSAwIC4yLS4xLjItLjJzLS4xLS4zLS4yLS40Yy0uMS0uMS0uNC0uMy0uNy0uNnoiIGZpbGw9IiMyMjIiLz48L3N2Zz4=);
                }
                .icon-submit-25x25-black:hover {
                    color: #069;
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNSIgaGVpZ2h0PSIyNSI+PHBhdGggZD0iTTE1LjYgMS4zdjUuM2g1LjN2MTdoLTE3VjEuM2gxMS43TTE3IDBIMi43djI1aDE5LjZWNS40aC01LjRMMTcgMHptLS42IDEuM0wyMSA1Ljl2MTcuN0g0VjEuM2gxMi40TTE3IDBIMi43djI1aDE5LjZWNS40TDE3IDB6bS0uNCAxMy41bC0zLjEtMy4xLS44LS44Yy0uMS0uMS0uMy0uMS0uNCAwbC0uOC44LTMuMSAzLjEtLjcuN2MtLjEuMS0uMi4yLS4yLjNzLjEuMi4yLjJoMi43Yy4xIDAgLjIuMS4yLjJ2My4zYzAgLjIuMi40LjQuNGgzYy4yIDAgLjQtLjIuNC0uNHYtMy4zYzAtLjEuMS0uMi4yLS4yaDIuN2MuMSAwIC4yLS4xLjItLjJzLS4xLS4zLS4yLS40Yy0uMS0uMS0uNC0uMy0uNy0uNnoiIGZpbGw9IiMwNjkiLz48L3N2Zz4=);
                }

                .icon-arrow-right-6x10-black {
                    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2IiBoZWlnaHQ9IjEwIj48cGF0aCBkPSJNMCAybDMuNyAzTDAgOHYybDYtNS02LTV2MnoiIGZpbGw9IiMyMjIiLz48L3N2Zz4=);
                }

                .background-brand-secondary-pdf {
                    background-color: #036599;
                    background-size: 22px auto;
                    background-position: 80% 50%;
                    margin-right: 5px;
                    color: #fff;
                }

                .background-brand-secondary-pdf a {
                    color: #fff;
                }

                .nature-research-logo {
                    background-image: url("/static/images/product-logos/nature-research-logo-dark.2dec4e5439.svg");
                    background-position: 100%;
                    background-repeat: no-repeat;
                }

                .menu-button,
                .menu-button-clone,
                .header-submit-button {
                    border: 1px solid #222;
                    border: 1px solid rgba(34,34,34,.75);
                    color: #222;
                }
                .nature-research-logo {
                    background-image: url("/static/images/product-logos/nature-research-logo-dark.2dec4e5439.svg"), none;
                }

                .icon-rotate.tools-menu-button-icon:after,
                .menu-button-icon:after {
                    background-image: url("/static/images/icons/icon-arrow-down-12x7-gray-dark.d2d673ff2e.svg"), none;
                }

                 .header-promo-button {
                     margin-top: 20px;
                     margin-right: 10px;
                 }

                .sticky-header .header-promo-button {
                     padding: 8px 16px;
                 }
            </style>
        
    


<script>(function(w,d){if(w.matchMedia && w.matchMedia(d.getElementById('mustard').media).matches){d.documentElement.className=d.documentElement.className.replace(/\s*grade-c/, "")}})(window,document)</script>

<!-- SpringerLink's event tracker, as per: https://github.com/springernature/springerlink-event-tracker -->

<script type="text/javascript">
document.addEventListener('accessdetailsloaded', function(e) {
    var dL, doi, pageType, eventObject, i, script, loginEventData;

    for (i = 0; i < window.dataLayer.length; i++) {
        if (window.dataLayer[i]["content"] && window.dataLayer[i]["page"]) {
            dL = window.dataLayer[i];
        }
    }

    if (!dL
        || !dL.content.article
        || !(doi = dL.content.article.doi) && doi.length > 0
        || (pageType = dL.page.category.pageType.toLowerCase()) !== "article"
    ) {return false;}

    pageType = pageType.charAt(0).toUpperCase() + pageType.substring(1);

    eventObject = {'content_type': pageType, 'doi': doi};

    loginEventData = e.detail;
    if (loginEventData && loginEventData.business_partner_id) {
        eventObject['business_partner_ids'] = loginEventData.business_partner_id;
    }

    script = document.createElement('script');
    script.id = 'springerlink-event-tracker';
    script.src = 'https://event-tracker.springernature.com/dist/eventTracker.js';
    script.onload = function() {
        new EventTracker({'platform': 'Nature'}).sendEvent('display', eventObject);
    };
    document.head.appendChild(script);
});
</script>

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NWDMT9Q');</script>
<!-- End Google Tag Manager -->


<meta name="robots" content="noarchive">
<meta name="access" content="No">
<meta name="WT.cg_s" content="Article"/>
<meta name="WT.z_bandiera_abtest" content="a"/>
<meta name="WT.page_categorisation" content="Article_HTML"/>

    <meta name="WT.template" content="oscar"/>
    <meta name="WT.z_cg_type" content="Nature Research Journals"/>
    <meta name="WT.cg_n" content="Nature"/>
    <meta name="dc.rights" content="©2019 Macmillan Publishers Limited. All Rights Reserved."/>
    <meta name="prism.issn" content="1476-4687"/>


<link rel="search" href="http://www.nature.com/search">
<link rel="search" href="http://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="http://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">


    
    

    <meta name="journal_id" content="41586"/>

    <meta name="dc.title" content="Deep learning"/>

    <meta name="dc.source" content="Nature 2015 521:7553"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Nature Publishing Group"/>

    <meta name="dc.date" content="2015-05-27"/>

    <meta name="dc.type" content="ReviewPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved."/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech."/>

    <meta name="prism.issn" content="1476-4687"/>

    <meta name="prism.publicationName" content="Nature"/>

    <meta name="prism.publicationDate" content="2015-05-27"/>

    <meta name="prism.volume" content="521"/>

    <meta name="prism.number" content="7553"/>

    <meta name="prism.section" content="ReviewPaper"/>

    <meta name="prism.startingPage" content="436"/>

    <meta name="prism.endingPage" content="444"/>

    <meta name="prism.copyright" content="2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved."/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://www.nature.com/articles/nature14539"/>

    <meta name="prism.doi" content="doi:10.1038/nature14539"/>

    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nature14539.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nature14539"/>

    <meta name="citation_journal_title" content="Nature"/>

    <meta name="citation_journal_abbrev" content="Nature"/>

    <meta name="citation_publisher" content="Nature Publishing Group"/>

    <meta name="citation_issn" content="1476-4687"/>

    <meta name="citation_title" content="Deep learning"/>

    <meta name="citation_volume" content="521"/>

    <meta name="citation_issue" content="7553"/>

    <meta name="citation_publication_date" content="2015/05"/>

    <meta name="citation_online_date" content="2015/05/27"/>

    <meta name="citation_firstpage" content="436"/>

    <meta name="citation_lastpage" content="444"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1038/nature14539"/>

    <meta name="DOI" content="10.1038/nature14539"/>

    <meta name="citation_doi" content="10.1038/nature14539"/>

    <meta name="description" content="Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech."/>

    <meta name="dc.creator" content="Yann LeCun"/>

    <meta name="dc.creator" content="Yoshua Bengio"/>

    <meta name="dc.creator" content="Geoffrey Hinton"/>

    <meta name="dc.subject" content="Computer science"/>

    <meta name="dc.subject" content="Mathematics and computing"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 25; citation_publication_date=2012; citation_id=CR1; citation_author=A Krizhevsky; citation_author=I Sutskever; citation_author=G Hinton"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.; citation_title=Learning hierarchical features for scene labeling; citation_author=C Farabet, C Couprie, L Najman, Y LeCun; citation_volume=35; citation_publication_date=2013; citation_pages=1915-1929; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 27; citation_publication_date=2014; citation_id=CR3; citation_author=J Tompson; citation_author=A Jain; citation_author=Y LeCun; citation_author=C Bregler"/>

    <meta name="citation_reference" content="Szegedy, C. et al. Going deeper with convolutions. Preprint at 
                    http://arxiv.org/abs/1409.4842
                    
                   (2014)."/>

    <meta name="citation_reference" content="citation_title=Proc. Automatic Speech Recognition and Understanding; citation_publication_date=2011; citation_id=CR5; citation_author=T Mikolov; citation_author=A Deoras; citation_author=D Povey; citation_author=L Burget; citation_author=J Cernocky"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Signal Processing Magazine; citation_title=Deep neural networks for acoustic modeling in speech recognition; citation_author=G Hinton; citation_volume=29; citation_publication_date=2012; citation_pages=82-97; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_title=Proc. Acoustics, Speech and Signal Processing; citation_publication_date=2013; citation_id=CR7; citation_author=T Sainath; citation_author=A-R Mohamed; citation_author=B Kingsbury; citation_author=B Ramabhadran"/>

    <meta name="citation_reference" content="citation_journal_title=J. Chem. Inf. Model.; citation_title=Deep neural nets as a method for quantitative structure-activity relationships; citation_author=J Ma, RP Sheridan, A Liaw, GE Dahl, V Svetnik; citation_volume=55; citation_publication_date=2015; citation_pages=263-274; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=J. Phys. Conf. Series; citation_title=Online particle detection with neural networks based on topological calorimetry information; citation_author=T Ciodaro, D Deva, J de Seixas, D Damazio; citation_volume=368; citation_publication_date=2012; citation_pages=012030; citation_id=CR9"/>

    <meta name="citation_reference" content="Kaggle. Higgs boson machine learning challenge. Kaggle 
                    https://www.kaggle.com/c/higgs-boson
                    
                   (2014)."/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Connectomic reconstruction of the inner plexiform layer in the mouse retina; citation_author=M Helmstaedter; citation_volume=500; citation_publication_date=2013; citation_pages=168-174; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Bioinformatics; citation_title=Deep learning of the tissue-regulated splicing code; citation_author=MK Leung, HY Xiong, LJ Lee, BJ Frey; citation_volume=30; citation_publication_date=2014; citation_pages=i121-i129; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=The human splicing code reveals new insights into the genetic determinants of disease; citation_author=HY Xiong; citation_volume=347; citation_publication_date=2015; citation_pages=6218; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Natural language processing (almost) from scratch; citation_author=R Collobert; citation_volume=12; citation_publication_date=2011; citation_pages=2493-2537; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_title=Proc. Empirical Methods in Natural Language Processing; citation_publication_date=2014; citation_id=CR15; citation_author=A Bordes; citation_author=S Chopra; citation_author=J Weston"/>

    <meta name="citation_reference" content="citation_title=Proc. ACL-IJCNLP; citation_publication_date=2015; citation_id=CR16; citation_author=S Jean; citation_author=K Cho; citation_author=R Memisevic; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 27; citation_publication_date=2014; citation_id=CR17; citation_author=I Sutskever; citation_author=O Vinyals; citation_author=QV Le"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 20; citation_publication_date=2007; citation_id=CR18; citation_author=L Bottou; citation_author=O Bousquet"/>

    <meta name="citation_reference" content="citation_title=Pattern Classification and Scene Analysis; citation_publication_date=1973; citation_id=CR19; citation_author=RO Duda; citation_author=PE Hart"/>

    <meta name="citation_reference" content="citation_title=Learning with Kernels; citation_publication_date=2002; citation_id=CR20; citation_author=B Sch&#246;lkopf; citation_author=A Smola"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 18; citation_publication_date=2005; citation_id=CR21; citation_author=Y Bengio; citation_author=O Delalleau; citation_author=N Le Roux"/>

    <meta name="citation_reference" content="citation_title=Proc. Symposium on Mechanisation of Thought Processes; citation_publication_date=1958; citation_id=CR22; citation_author=OG Selfridge"/>

    <meta name="citation_reference" content="citation_title=The Perceptron &#8212; A Perceiving and Recognizing Automaton; citation_publication_date=1957; citation_id=CR23; citation_author=F Rosenblatt"/>

    <meta name="citation_reference" content="citation_title=Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences; citation_publication_date=1974; citation_id=CR24; citation_author=P Werbos"/>

    <meta name="citation_reference" content="citation_title=Learning Logic; citation_publication_date=1985; citation_id=CR25; citation_author=DB Parker"/>

    <meta name="citation_reference" content="citation_title=Cognitiva 85: a la Fronti&#232;re de l&#39;Intelligence Artificielle, des Sciences de la Connaissance et des Neurosciences; citation_publication_date=1985; citation_id=CR26; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Learning representations by back-propagating errors; citation_author=DE Rumelhart, GE Hinton, RJ Williams; citation_volume=323; citation_publication_date=1986; citation_pages=533-536; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_title=Proc. 14th International Conference on Artificial Intelligence and Statistics; citation_publication_date=2011; citation_id=CR28; citation_author=X Glorot; citation_author=A Bordes; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 27; citation_publication_date=2014; citation_id=CR29; citation_author=Y Dauphin"/>

    <meta name="citation_reference" content="citation_title=Proc. Conference on AI and Statistics; citation_publication_date=2014; citation_id=CR30; citation_author=A Choromanska; citation_author=M Henaff; citation_author=M Mathieu; citation_author=GB Arous; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_title=Proc. 19th International Joint Conference on Artificial intelligence; citation_publication_date=2005; citation_id=CR31; citation_author=GE Hinton"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comp.; citation_title=A fast learning algorithm for deep belief nets; citation_author=GE Hinton, S Osindero, Y-W Teh; citation_volume=18; citation_publication_date=2006; citation_pages=1527-1554; citation_id=CR32"/>

    <meta name="citation_reference" content="Bengio, Y., Lamblin, P., Popovici, D. &amp; Larochelle, H. Greedy layer-wise training of deep networks. In Proc. Advances in Neural Information Processing Systems 19 153&#8211;160 (2006). This report demonstrated that the unsupervised pre-training method introduced in ref. 32 significantly improves performance on test data and generalizes the method to other unsupervised representation-learning techniques, such as auto-encoders."/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 19; citation_publication_date=2006; citation_id=CR34; citation_author=M Ranzato; citation_author=C Poultney; citation_author=S Chopra; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Reducing the dimensionality of data with neural networks; citation_author=GE Hinton, R Salakhutdinov; citation_volume=313; citation_publication_date=2006; citation_pages=504-507; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Computer Vision and Pattern Recognition; citation_publication_date=2013; citation_id=CR36; citation_author=P Sermanet; citation_author=K Kavukcuoglu; citation_author=S Chintala; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_title=Proc. 26th Annual International Conference on Machine Learning; citation_publication_date=2009; citation_id=CR37; citation_author=R Raina; citation_author=A Madhavan; citation_author=AY Ng"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Audio Speech Lang. Process.; citation_title=Acoustic modeling using deep belief networks; citation_author=A-R Mohamed, GE Dahl, G Hinton; citation_volume=20; citation_publication_date=2012; citation_pages=14-22; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Audio Speech Lang. Process.; citation_title=Context-dependent pre-trained deep neural networks for large vocabulary speech recognition; citation_author=GE Dahl, D Yu, L Deng, A Acero; citation_volume=20; citation_publication_date=2012; citation_pages=33-42; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Machine Intell.; citation_title=Representation learning: a review and new perspectives; citation_author=Y Bengio, A Courville, P Vincent; citation_volume=35; citation_publication_date=2013; citation_pages=1798-1828; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems; citation_publication_date=1990; citation_id=CR41; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_journal_title=Proc. IEEE; citation_title=Gradient-based learning applied to document recognition; citation_author=Y LeCun, L Bottou, Y Bengio, P Haffner; citation_volume=86; citation_publication_date=1998; citation_pages=2278-2324; citation_id=CR42"/>

    <meta name="citation_reference" content="citation_journal_title=J. Physiol.; citation_title=Receptive fields, binocular interaction, and functional architecture in the cat&#39;s visual cortex; citation_author=DH Hubel, TN Wiesel; citation_volume=160; citation_publication_date=1962; citation_pages=106-154; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Distributed hierarchical processing in the primate cerebral cortex; citation_author=DJ Felleman, DCV Essen; citation_volume=1; citation_publication_date=1991; citation_pages=1-47; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=PLoS Comp. Biol.; citation_title=Deep neural networks rival the representation of primate it cortex for core visual object recognition; citation_author=CF Cadieu; citation_volume=10; citation_publication_date=2014; citation_pages=e1003963; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Pattern Recognition; citation_title=Neocognitron: a new algorithm for pattern recognition tolerant of deformations and shifts in position; citation_author=K Fukushima, S Miyake; citation_volume=15; citation_publication_date=1982; citation_pages=455-469; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Acoustics Speech Signal Process.; citation_title=Phoneme recognition using time-delay neural networks; citation_author=A Waibel, T Hanazawa, GE Hinton, K Shikano, K Lang; citation_volume=37; citation_publication_date=1989; citation_pages=328-339; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_title=Proc. EuroSpeech 89; citation_publication_date=1989; citation_id=CR48; citation_author=L Bottou; citation_author=F Fogelman-Souli&#233;; citation_author=P Blanchet; citation_author=J Lienard"/>

    <meta name="citation_reference" content="citation_title=Proc. Document Analysis and Recognition; citation_publication_date=2003; citation_id=CR49; citation_author=D Simard; citation_author=PY Steinkraus; citation_author=JC Platt"/>

    <meta name="citation_reference" content="citation_title=Proc. Vision, Image, and Signal Processing; citation_publication_date=1994; citation_id=CR50; citation_author=R Vaillant; citation_author=C Monrocq; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_title=Neural Information Processing Systems; citation_publication_date=1995; citation_id=CR51; citation_author=S Nowlan; citation_author=J Platt"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Networks; citation_title=Face recognition: a convolutional neural-network approach; citation_author=S Lawrence, CL Giles, AC Tsoi, AD Back; citation_volume=8; citation_publication_date=1997; citation_pages=98-113; citation_id=CR52"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Networks; citation_title=Multi-column deep neural network for traffic sign classification; citation_author=D Ciresan, U Meier, J Masci, J Schmidhuber; citation_volume=32; citation_publication_date=2012; citation_pages=333-338; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Image Process.; citation_title=Toward automatic phenotyping of developing embryos from videos; citation_author=F Ning; citation_volume=14; citation_publication_date=2005; citation_pages=1360-1371; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Convolutional networks can learn to generate affinity graphs for image segmentation; citation_author=SC Turaga; citation_volume=22; citation_publication_date=2010; citation_pages=511-538; citation_id=CR55"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Machine Intell.; citation_title=Convolutional face finder: a neural architecture for fast and robust face detection; citation_author=C Garcia, M Delakis; citation_volume=26; citation_publication_date=2004; citation_pages=1408-1423; citation_id=CR56"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Synergistic face detection and pose estimation with energy-based models; citation_author=M Osadchy, Y LeCun, M Miller; citation_volume=8; citation_publication_date=2007; citation_pages=1197-1215; citation_id=CR57"/>

    <meta name="citation_reference" content="citation_title=Proc. Conference on Computer Vision and Pattern Recognition; citation_publication_date=2014; citation_id=CR58; citation_author=J Tompson; citation_author=RR Goroshin; citation_author=A Jain; citation_author=YY LeCun; citation_author=CC Bregler"/>

    <meta name="citation_reference" content="citation_title=Proc. Conference on Computer Vision and Pattern Recognition; citation_publication_date=2014; citation_id=CR59; citation_author=Y Taigman; citation_author=M Yang; citation_author=M Ranzato; citation_author=L Wolf"/>

    <meta name="citation_reference" content="citation_journal_title=J. Field Robot.; citation_title=Learning long-range vision for autonomous off-road driving; citation_author=R Hadsell; citation_volume=26; citation_publication_date=2009; citation_pages=120-144; citation_id=CR60"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Machine Learning; citation_publication_date=2012; citation_id=CR61; citation_author=C Farabet; citation_author=C Couprie; citation_author=L Najman; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_journal_title=J. Machine Learning Res.; citation_title=Dropout: a simple way to prevent neural networks from overfitting; citation_author=N Srivastava, G Hinton, A Krizhevsky, I Sutskever, R Salakhutdinov; citation_volume=15; citation_publication_date=2014; citation_pages=1929-1958; citation_id=CR62"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Learning Representations; citation_publication_date=2014; citation_id=CR63; citation_author=P Sermanet"/>

    <meta name="citation_reference" content="citation_title=Proc. Conference on Computer Vision and Pattern Recognition; citation_publication_date=2014; citation_id=CR64; citation_author=R Girshick; citation_author=J Donahue; citation_author=T Darrell; citation_author=J Malik"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Learning Representations; citation_publication_date=2014; citation_id=CR65; citation_author=K Simonyan; citation_author=A Zisserman"/>

    <meta name="citation_reference" content="citation_journal_title=J. Solid State Circuits; citation_title=An analog neural network processor with programmable topology; citation_author=B Boser, E Sackinger, J Bromley, Y LeCun, L Jackel; citation_volume=26; citation_publication_date=1991; citation_pages=2017-2025; citation_id=CR66"/>

    <meta name="citation_reference" content="citation_title=Scaling up Machine Learning: Parallel and Distributed Approaches; citation_publication_date=2011; citation_id=CR67; citation_author=C Farabet"/>

    <meta name="citation_reference" content="citation_title=Learning Deep Architectures for AI; citation_publication_date=2009; citation_id=CR68; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_journal_title=J. Discrete Math.; citation_title=When does a mixture of products contain a product of mixtures?; citation_author=G Montufar, J Morton; citation_volume=29; citation_publication_date=2014; citation_pages=321-347; citation_id=CR69"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 27; citation_publication_date=2014; citation_id=CR70; citation_author=GF Montufar; citation_author=R Pascanu; citation_author=K Cho; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 13; citation_publication_date=2001; citation_id=CR71; citation_author=Y Bengio; citation_author=R Ducharme; citation_author=P Vincent"/>

    <meta name="citation_reference" content="citation_title=Proc. Conference on Empirical Methods in Natural Language Processing; citation_publication_date=2014; citation_id=CR72; citation_author=K Cho"/>

    <meta name="citation_reference" content="citation_journal_title=Computer Speech Lang.; citation_title=Continuous space language models; citation_author=H Schwenk; citation_volume=21; citation_publication_date=2007; citation_pages=492-518; citation_id=CR73"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Machine Learning; citation_publication_date=2011; citation_id=CR74; citation_author=R Socher; citation_author=CC-Y Lin; citation_author=C Manning; citation_author=AY Ng"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 26; citation_publication_date=2013; citation_id=CR75; citation_author=T Mikolov; citation_author=I Sutskever; citation_author=K Chen; citation_author=G Corrado; citation_author=J Dean"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Learning Representations; citation_publication_date=2015; citation_id=CR76; citation_author=D Bahdanau; citation_author=K Cho; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="Hochreiter, S. Untersuchungen zu dynamischen neuronalen Netzen [in German] Diploma thesis, T.U. M&#252;nich (1991)."/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Networks; citation_title=Learning long-term dependencies with gradient descent is difficult; citation_author=Y Bengio, P Simard, P Frasconi; citation_volume=5; citation_publication_date=1994; citation_pages=157-166; citation_id=CR78"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Long short-term memory; citation_author=S Hochreiter, J Schmidhuber; citation_volume=9; citation_publication_date=1997; citation_pages=1735-1780; citation_id=CR79"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 8; citation_publication_date=1995; citation_id=CR80; citation_author=S ElHihi; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_title=Training Recurrent Neural Networks; citation_publication_date=2012; citation_id=CR81; citation_author=I Sutskever"/>

    <meta name="citation_reference" content="citation_title=Proc. 30th International Conference on Machine Learning; citation_publication_date=2013; citation_id=CR82; citation_author=R Pascanu; citation_author=T Mikolov; citation_author=Y Bengio"/>

    <meta name="citation_reference" content="citation_title=Proc. 28th International Conference on Machine Learning; citation_publication_date=2011; citation_id=CR83; citation_author=I Sutskever; citation_author=J Martens; citation_author=GE Hinton"/>

    <meta name="citation_reference" content="citation_title=Metaphors We Live By; citation_publication_date=2008; citation_id=CR84; citation_author=G Lakoff; citation_author=M Johnson"/>

    <meta name="citation_reference" content="citation_title=Semantic Cognition: A Parallel Distributed Processing Approach; citation_publication_date=2004; citation_id=CR85; citation_author=TT Rogers; citation_author=JL McClelland"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Learning Representations; citation_publication_date=2015; citation_id=CR86; citation_author=K Xu"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Acoustics, Speech and Signal Processing; citation_publication_date=2013; citation_id=CR87; citation_author=A Graves; citation_author=A-R Mohamed; citation_author=G Hinton"/>

    <meta name="citation_reference" content="Graves, A., Wayne, G. &amp; Danihelka, I. Neural Turing machines. 
                    http://arxiv.org/abs/1410.5401
                    
                   (2014)."/>

    <meta name="citation_reference" content="Weston, J. Chopra, S. &amp; Bordes, A. Memory networks. 
                    http://arxiv.org/abs/1410.3916
                    
                   (2014)."/>

    <meta name="citation_reference" content="Weston, J., Bordes, A., Chopra, S. &amp; Mikolov, T. Towards AI-complete question answering: a set of prerequisite toy tasks. 
                    http://arxiv.org/abs/1502.05698
                    
                   (2015)."/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=The wake-sleep algorithm for unsupervised neural networks; citation_author=GE Hinton, P Dayan, BJ Frey, RM Neal; citation_volume=268; citation_publication_date=1995; citation_pages=1558-1161; citation_id=CR91"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Artificial Intelligence and Statistics; citation_publication_date=2009; citation_id=CR92; citation_author=R Salakhutdinov; citation_author=G Hinton"/>

    <meta name="citation_reference" content="citation_title=Proc. 25th International Conference on Machine Learning; citation_publication_date=2008; citation_id=CR93; citation_author=P Vincent; citation_author=H Larochelle; citation_author=Y Bengio; citation_author=P-A Manzagol"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 23; citation_publication_date=2010; citation_id=CR94; citation_author=K Kavukcuoglu"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Machine Learning; citation_publication_date=2010; citation_id=CR95; citation_author=K Gregor; citation_author=Y LeCun"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Machine Intell.; citation_title=Modeling natural images using gated MRFs; citation_author=M Ranzato, V Mnih, JM Susskind, GE Hinton; citation_volume=35; citation_publication_date=2013; citation_pages=2206-2222; citation_id=CR96"/>

    <meta name="citation_reference" content="citation_title=Proc. 31st International Conference on Machine Learning; citation_publication_date=2014; citation_id=CR97; citation_author=Y Bengio; citation_author=E Thibodeau-Laufer; citation_author=G Alain; citation_author=J Yosinski"/>

    <meta name="citation_reference" content="citation_title=Proc. Advances in Neural Information Processing Systems 27; citation_publication_date=2014; citation_id=CR98; citation_author=D Kingma; citation_author=D Rezende; citation_author=S Mohamed; citation_author=M Welling"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Learning Representations; citation_publication_date=2014; citation_id=CR99; citation_author=J Ba; citation_author=V Mnih; citation_author=K Kavukcuoglu"/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Human-level control through deep reinforcement learning; citation_author=V Mnih; citation_volume=518; citation_publication_date=2015; citation_pages=529-533; citation_id=CR100"/>

    <meta name="citation_reference" content="citation_journal_title=Mach. Learn.; citation_title=From machine learning to machine reasoning; citation_author=L Bottou; citation_volume=94; citation_publication_date=2014; citation_pages=133-149; citation_id=CR101"/>

    <meta name="citation_reference" content="citation_title=Proc. International Conference on Machine Learning; citation_publication_date=2014; citation_id=CR102; citation_author=O Vinyals; citation_author=A Toshev; citation_author=S Bengio; citation_author=D Erhan"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn.Research; citation_title=Visualizing data using t-SNE; citation_author=L van der Maaten, GE Hinton; citation_volume=9; citation_publication_date=2008; citation_pages=2579-2605; citation_id=CR103"/>

    <meta name="citation_author" content="Yann LeCun"/>

    <meta name="citation_author_institution" content="Facebook AI Research, New York, USA"/>

    <meta name="citation_author_institution" content="New York University, New York, USA"/>

    <meta name="citation_author" content="Yoshua Bengio"/>

    <meta name="citation_author_institution" content="Department of Computer Science and Operations Research Universit&#233; de Montr&#233;al, Pavillon Andr&#233;-Aisenstadt, Montr&#233;al, Canada"/>

    <meta name="citation_author" content="Geoffrey Hinton"/>

    <meta name="citation_author_institution" content="Google, Mountain View, USA"/>

    <meta name="citation_author_institution" content="Department of Computer Science, University of Toronto, Toronto, Canada"/>

    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Deep learning"/>

    <meta name="twitter:site" content="@naturenews"/>

    <meta name="twitter:description" content="Deep learning"/>

    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig1_HTML.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="WT.z_cc_license_type" content=""/>

    <meta name="WT.z_primary_atype" content="Reviews"/>

    <meta name="WT.z_subject_term" content="Computer science;Mathematics and computing"/>

    <meta name="WT.z_subject_term_id" content="computer-science;mathematics-and-computing"/>


    
        <meta property="og:url" content="https://www.nature.com/articles/nature14539"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Nature"/>
        <meta property="og:title" content="Deep learning"/>
        
        <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig1_HTML.jpg"/>
    
</head>
<!--[if IE 9]><body class="ie9 article-page"><![endif]-->
<!--[if gt IE 9]><!--><body class="article-page"><!--<![endif]-->
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NWDMT9Q"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div role="banner" class="position-relative cleared z-index-50" data-test="top-containers">
    
    
        <div class="c-skip-link">
            <div class="c-skip-link__container">
                <a class="c-skip-link__text" href="#content">Skip to main content</a>
            </div>
        </div>
    

    
        

        

        
            <div class="u-hide-print leaderboard-or-billboard-container" data-container-type="banner-advert">
                <div class="u-container">
                    <div class="leaderboard-or-billboard-inner ad-with-label">
                        
            
            
                <div id="article-doubleclickad-container">
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-gpt-unitpath="/285/nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nature14539;doi=10.1038/nature14539;subjmeta=117,639,705;kwrd=Computer science,Mathematics and computing">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=728x90&amp;c=617438195&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature14539%26doi%3D10.1038/nature14539%26subjmeta%3D117,639,705%26kwrd%3DComputer science,Mathematics and computing">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=728x90&amp;c=617438195&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature14539%26doi%3D10.1038/nature14539%26subjmeta%3D117,639,705%26kwrd%3DComputer science,Mathematics and computing"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>
</div>

            
            
        
                    </div>
                </div>
            </div>
        
    

    

    
        <div class="c-grade-c-banner u-hide">
            <div class="c-grade-c-banner__container">
                
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>
    
            </div>
        </div>
    

    
        
            
                <div class="u-overflow-hidden">
                    <div class="content mq1200-padded">
                        <div class="c-banner c-banner--compact c-banner--marketing">
                            <div class="c-banner__container c-banner__container--center">
                                <div class="c-banner__item">
                                    <p class="ma0">Help us improve our products. <a class="c-banner__link u-underline" href="https://mailchi.mp/bcbfa719e0ab/snuxresearch" data-track="click" data-track-action="click" data-track-category="feedback banner top of page" data-track-label="ux recruitment link">Sign up to take part.</a></p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            
        
    
    
    <div class="hide-print container background-white text-gray border-gray-medium border-bottom-1 text14 strong lower mq640-hide position-relative z-index-100"
         data-test="header-breadcrumbs">
        <div class="content cleared mq1200-padded">
            
            <div class="breadcrumbs pin-left">
                <ol class="ma0 cleared clean-list inline-list"><li id="breadcrumb0" itemscope="itemscope" itemtype="http://data-vocabulary.org/Breadcrumb"
                                     itemref="breadcrumb1"><a href="/" itemprop="url" class="icon icon-right icon-arrow-right-6x10-black pr15 text-gray"
                                                                                                                 data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="title">nature</span></a></li><li id="breadcrumb1" itemscope="itemscope" itemtype="http://data-vocabulary.org/Breadcrumb"
                                     itemref="breadcrumb2" class="ml6"><a href="/nature/articles?type&#x3D;review-article" itemprop="url" class="icon icon-right icon-arrow-right-6x10-black pr15 text-gray"
                                                                                                                 data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:review articles"><span itemprop="title">review articles</span></a></li><li id="breadcrumb2" itemscope="itemscope" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="/articles/nature14539" itemprop="url" data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:article" class="ml6 text-gray"><span itemprop="title">article</span></a></li></ol>
            </div>
            
            
                <p class="pin-right box-sizing background-white nature-research-logo ma0 pa6 hide-text grade-c-hide">A Nature Research Journal</p>
            
        </div>
    </div>


    <div class="u-mb-16">
        
    
        <div class="hide-print container js-header-container mb20 position-relative z-index-50" data-ui="header-container"
             data-container-type="header">
            <div class="cleared clear hide-print position-relative background-white js-header default-header z-index-100 composite-layer tighten-line-height">
                <div class="banner js-banner content mq1200-padded position-relative">
                    <div class="inner-banner cleared">
                        <div class="main-column small-header-main pin-left">
                            <div class="header-logo-container background-white">
                                <a href="#menu" id="menu-button" class="js-header-menu-button menu-button js-no-scroll"
                                   data-test="menu-button">
                                    <span class="menu-button-icon icon-rotate">
                                        <span class="menu-button-label">Menu</span>
                                    </span>
                                </a>
                                <h1 class="inline-block">
                                    <a href="/nature"
                                       class="header-logo inline-block"
                                       data-track="click" data-track-action="home" data-track-category="header" data-track-label="image">
                                        
                                            <img src="/static/images/logos/nature-logo-40.21a62d60b0.svg" alt="Nature"/>
                                        
                                    </a>
                                </h1>
                            </div>
                        </div>
                        <div class="position-absolute position-right small-header-side">
                            <div class="pin-right">
                                
                                    <a class="mq875-hide pin-left inline-group-top pa6 pr10 pl10 text16 contrast-text mr1 header-promo-button"
                                       href="https://www.nature.com/nature/subscribe" data-track="click" data-track-action="subscribe"
                                       data-track-category="nature-header" data-track-label="link">
                                    <span class="block text-center">
                                        <span class="block mt6 mb6 pb1 header-promo-text">Subscribe</span>
                                    </span>
                                    </a>

                                    <a href="#search-menu" data-component="tray-button"
                                       class="pin-left inline-group-top pa10 pr15 pl15 small-header-icons background-white text-gray text11 mr1"
                                       data-test="search-link" data-track="click" data-track-category="header"
                                       data-track-action="open tray" data-track-label="button">
                                            <span class="icon icon-above icon-search-25x25-black block text-center">
                                                <span class="block mt6 mq875-hide small-header-hide">Search</span>
                                            </span>
                                    </a>

                                    
    <a href="/nams/svc/myaccount"
       id="my-account"
       class="placeholder inline-block pin-left inline-group-top pa10 pr15 pl15 small-header-icons background-white text-gray text11"
       data-test="login-link" data-track="click" data-track-action="my account" data-track-category="header" data-track-label="link">
        <span class="icon icon-above icon-login-25x25-black block text-center">
            <span class="block mt6 small-header-hide">My Account</span>
        </span>
    </a>
    <a href="https://idp.nature.com/authorize/natureuser?client_id&#x3D;grover&amp;redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539"
       id="login-button"
       style="display: none;"
       class="placeholder inline-block pin-left inline-group-top pa10 pr15 pl15 small-header-icons background-white text-gray text11"
       data-test="login-link" data-track="click" data-track-action="login" data-track-category="header" data-track-label="link">
        <span class="icon icon-above icon-login-25x25-black block text-center">
            <span class="block mt6 small-header-hide">Login</span>
        </span>
    </a>




                                
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    

    </div>
    
    

</div>



<div id="content" class="position-relative z-index-1">
    <div class="container cleared container-type-article" data-container-type="article">
        <div class="content position-relative cleared clear mq1200-padded" data-component="article-container">
            <article itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="full-width-print main-column pin-left js-main-column highlighter" role="main">
                    <div class="c-article-header">
                        <header>
                            <ul class="c-article-identifiers" data-test="article-identifier">
                                <li class="c-article-identifiers__item">Review Article</li>
                                
                                <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-category="article body" data-track-label="link">Published: <time datetime="2015-05-27" itemprop="datePublished">27 May 2015</time></a></li>
                            </ul>

                            
                            <h1 class="c-article-title u-h1" data-test="article-title" data-article-title="" itemprop="name headline">Deep learning</h1>
                            <ul class="c-author-list js-list-authors js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-1" data-corresp-id="c1">Yann LeCun<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Facebook AI Research" /><meta itemprop="address" content="grid.453567.6, 0000 0004 0615 529X, Facebook AI Research, 770 Broadway, New York, 10003, New York, USA" /></span>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="New York University" /><meta itemprop="address" content="grid.137628.9, 0000 0004 1936 8753, New York University, 715 Broadway, New York, 10003, New York, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-2">Yoshua Bengio</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Pavillon André-Aisenstadt" /><meta itemprop="address" content="grid.14848.31, 0000 0001 2292 3357, Department of Computer Science and Operations Research Université de Montréal, Pavillon André-Aisenstadt, PO Box 6128 Centre-Ville STN, Montréal, H3C 3J7, Quebec, Canada" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-3">Geoffrey Hinton</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Google" /><meta itemprop="address" content="grid.420451.6, Google, 1600 Amphitheatre Parkway, Mountain View, 94043, California, USA" /></span>,<a href="#Aff5">5</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Toronto" /><meta itemprop="address" content="grid.17063.33, 0000 0001 2157 2938, Department of Computer Science, University of Toronto, 6 King's College Road, Toronto, M5S 3G4, Ontario, Canada" /></span></sup> </li></ul>
                            
                            

                            <p class="c-article-info-details" data-container-section="info">
                                
    <a data-test="journal-link" href="/nature"><i data-test="journal-title">Nature</i></a>

                                <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 521</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">436</span>–<span itemprop="pageEnd">444</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                            </p>
                            
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <h2 class="u-visually-hidden">Article metrics</h2>
            <ul class="c-article-metrics-bar u-list-inline">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">149k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">11376 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">945 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__details"><a href="/articles/nature14539/metrics" data-track="click" data-track-action="view metrics" data-track-category="article body" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                        </li>
                    
                
            </ul>
        </div>
    



                            
                        </header>

                        
    <div class="js-hide" data-component="article-subject-links">
        
            <h3 class="c-article__sub-heading">Subjects</h3>
            <ul class="c-article-subject-list">
                <li class="c-article-subject-list__subject"><a href="/subjects/computer-science" data-track="click" data-track-action="view subject" data-track-category="article body" data-track-label="link" itemprop="about">Computer science</a></li><li class="c-article-subject-list__subject"><a href="/subjects/mathematics-and-computing" data-track="click" data-track-action="view subject" data-track-category="article body" data-track-label="link" itemprop="about">Mathematics and computing</a></li>
            </ul>
        
    </div>

                        
    

                        
                    </div>

                    <div data-article-body="true" data-track-component="article body" class="c-article-body">
                        <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.</p></div></div></section>
                        
                            <noscript>
                                
                                    
<div class="c-card c-card--side c-card--mobile" data-component="entitlement-box">
    
        <div class="js-access-button">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button" data-test="ra21" data-track="click" data-track-action="institution access" data-track-label="button" data-track-category="article body">
                <svg class="u-icon" width="18" height="18"><use href="#global-icon-institution"></use></svg>
                <span class="c-article__button-text">Access through your institution</span>
            </a>
        </div>
         <div class="js-buy-button">
            <a href="#access-options" class="c-article__button c-article__button--inverted" data-test="ra21" data-track="click" data-track-action="buy or subscribe" data-track-label="button" data-track-category="article body">
                <span>Buy or subscribe</span>
            </a>
        </div>
    
</div>

                                
                            </noscript>
                            
                                <div class="c-card c-card--side u-display-none" aria-hidden="true" data-component="entitlement-box" id=entitlement-box-mobile>
    
        <p class="js-text u-display-none" aria-hidden="true"></p>
        <div class="js-access-button u-display-none">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="institution access" data-track-label="button" data-track-category="article body">
                <svg class="u-icon" width="18" height="18"><use xlink:href="#global-icon-institution"></use></svg> 
                <span class="c-article__button-text">Access through your institution</span>
            </a>
        </div>
        <div class="js-change-institution-button u-display-none">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button c-article__button--inverted" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="change institution" data-track-label="button" data-track-category="article body">
                <span class="c-article__button-text">Change institution</span>
            </a>
        </div>
        <div class="js-buy-button u-display-none">
            <a href="#access-options" class="c-article__button c-article__button--inverted" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="buy or subscribe" data-track-label="button" data-track-category="article body">
                <span>Buy or subscribe</span>
            </a>
        </div>
    
</div>

                            
                        

                        
                            
                            <div class="u-mb-24">
                                
<h2 class="c-article-section__title u-h2" id="access-options">Access options</h2>



    <div class="LiveAreaSection-193358632"><style type="text/css">/* style specs start */
style{display:none!important}.LiveAreaSection-193358632 *{align-content:stretch;align-items:stretch;align-self:auto;animation-delay:0s;animation-direction:normal;animation-duration:0s;animation-fill-mode:none;animation-iteration-count:1;animation-name:none;animation-play-state:running;animation-timing-function:ease;azimuth:center;backface-visibility:visible;background-attachment:scroll;background-blend-mode:normal;background-clip:borderBox;background-color:transparent;background-image:none;background-origin:paddingBox;background-position:0 0;background-repeat:repeat;background-size:auto auto;block-size:auto;border-block-end-color:currentcolor;border-block-end-style:none;border-block-end-width:medium;border-block-start-color:currentcolor;border-block-start-style:none;border-block-start-width:medium;border-bottom-color:currentcolor;border-bottom-left-radius:0;border-bottom-right-radius:0;border-bottom-style:none;border-bottom-width:medium;border-collapse:separate;border-image-outset:0s;border-image-repeat:stretch;border-image-slice:100%;border-image-source:none;border-image-width:1;border-inline-end-color:currentcolor;border-inline-end-style:none;border-inline-end-width:medium;border-inline-start-color:currentcolor;border-inline-start-style:none;border-inline-start-width:medium;border-left-color:currentcolor;border-left-style:none;border-left-width:medium;border-right-color:currentcolor;border-right-style:none;border-right-width:medium;border-spacing:0;border-top-color:currentcolor;border-top-left-radius:0;border-top-right-radius:0;border-top-style:none;border-top-width:medium;bottom:auto;box-decoration-break:slice;box-shadow:none;box-sizing:border-box;break-after:auto;break-before:auto;break-inside:auto;caption-side:top;caret-color:auto;clear:none;clip:auto;clip-path:none;color:initial;column-count:auto;column-fill:balance;column-gap:normal;column-rule-color:currentcolor;column-rule-style:none;column-rule-width:medium;column-span:none;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;display:inline;empty-cells:show;filter:none;flex-basis:auto;flex-direction:row;flex-grow:0;flex-shrink:1;flex-wrap:nowrap;float:none;font-family:initial;font-feature-settings:normal;font-kerning:auto;font-language-override:normal;font-size:medium;font-size-adjust:none;font-stretch:normal;font-style:normal;font-synthesis:weight style;font-variant:normal;font-variant-alternates:normal;font-variant-caps:normal;font-variant-east-asian:normal;font-variant-ligatures:normal;font-variant-numeric:normal;font-variant-position:normal;font-weight:400;grid-auto-columns:auto;grid-auto-flow:row;grid-auto-rows:auto;grid-column-end:auto;grid-column-gap:0;grid-column-start:auto;grid-row-end:auto;grid-row-gap:0;grid-row-start:auto;grid-template-areas:none;grid-template-columns:none;grid-template-rows:none;height:auto;hyphens:manual;image-orientation:0deg;image-rendering:auto;image-resolution:1dppx;ime-mode:auto;inline-size:auto;isolation:auto;justify-content:flexStart;left:auto;letter-spacing:normal;line-break:auto;line-height:normal;list-style-image:none;list-style-position:outside;list-style-type:disc;margin-block-end:0;margin-block-start:0;margin-bottom:0;margin-inline-end:0;margin-inline-start:0;margin-left:0;margin-right:0;margin-top:0;mask-clip:borderBox;mask-composite:add;mask-image:none;mask-mode:matchSource;mask-origin:borderBox;mask-position:0% 0%;mask-repeat:repeat;mask-size:auto;mask-type:luminance;max-height:none;max-width:none;min-block-size:0;min-height:0;min-inline-size:0;min-width:0;mix-blend-mode:normal;object-fit:fill;object-position:50% 50%;offset-block-end:auto;offset-block-start:auto;offset-inline-end:auto;offset-inline-start:auto;opacity:1;order:0;orphans:2;outline-color:initial;outline-offset:0;outline-style:none;outline-width:medium;overflow:visible;overflow-wrap:normal;overflow-x:visible;overflow-y:visible;padding-block-end:0;padding-block-start:0;padding-bottom:0;padding-inline-end:0;padding-inline-start:0;padding-left:0;padding-right:0;padding-top:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;perspective:none;perspective-origin:50% 50%;pointer-events:auto;position:static;quotes:initial;resize:none;right:auto;ruby-align:spaceAround;ruby-merge:separate;ruby-position:over;scroll-behavior:auto;scroll-snap-coordinate:none;scroll-snap-destination:0 0;scroll-snap-points-x:none;scroll-snap-points-y:none;scroll-snap-type:none;shape-image-threshold:0;shape-margin:0;shape-outside:none;tab-size:8;table-layout:auto;text-align:initial;text-align-last:auto;text-combine-upright:none;text-decoration-color:currentcolor;text-decoration-line:none;text-decoration-style:solid;text-emphasis-color:currentcolor;text-emphasis-position:over right;text-emphasis-style:none;text-indent:0;text-justify:auto;text-orientation:mixed;text-overflow:clip;text-rendering:auto;text-shadow:none;text-transform:none;text-underline-position:auto;top:auto;touch-action:auto;transform:none;transform-box:borderBox;transform-origin:50% 50% 0;transform-style:flat;transition-delay:0s;transition-duration:0s;transition-property:all;transition-timing-function:ease;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;will-change:auto;word-break:normal;word-spacing:normal;word-wrap:normal;writing-mode:horizontalTb;z-index:auto;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;margin:0}.LiveAreaSection-193358632{width:100%}.LiveAreaSection-193358632 .login-option-buybox{display:block;width:100%;font-size:17px;line-height:30px;color:#222;padding-top:30px;font-family:Lora,Palatino,Times,"Times New Roman",serif}.LiveAreaSection-193358632 .additional-access-options{display:block;font-weight:700;font-size:17px;line-height:30px;color:#222;font-family:Lora,Palatino,Times,"Times New Roman",serif}.LiveAreaSection-193358632 .additional-login>li:not(:first-child)::before{transform:translateY(-50%);content:'';height:1rem;position:absolute;top:50%;left:0;border-left:2px solid #999}.LiveAreaSection-193358632 .additional-login>li:not(:first-child){padding-left:10px}.LiveAreaSection-193358632 .additional-login>li{display:inline-block;position:relative;vertical-align:middle;padding-right:10px}.BuyBoxSection-683559780{display:flex;flex-wrap:wrap;flex:1;flex-direction:row-reverse;margin:-30px -15px 0}.BuyBoxSection-683559780 .box-inner{width:100%;height:100%}.BuyBoxSection-683559780 .readcube-buybox{background-color:rgba(218,229,234,.5);flex-shrink:1;flex-grow:1;flex-basis:255px;background-clip:content-box;padding:0 15px;margin-top:30px}.BuyBoxSection-683559780 .subscribe-buybox{background-color:#dae5ea;flex-shrink:1;flex-grow:4;flex-basis:300px;background-clip:content-box;padding:0 15px;margin-top:30px}.BuyBoxSection-683559780 .title-readcube{display:block;margin:0;margin-right:20%;margin-left:20%;font-size:24px;line-height:32px;color:#222;padding-top:30px;text-align:center;font-family:Lora,Palatino,Times,"Times New Roman",serif}.BuyBoxSection-683559780 .title-buybox{display:block;margin:0;margin-right:29%;margin-left:29%;font-size:24px;line-height:32px;color:#222;padding-top:30px;text-align:center;font-family:Lora,Palatino,Times,"Times New Roman",serif}.BuyBoxSection-683559780 .title-asia-buybox{display:block;margin:0;margin-right:5%;margin-left:5%;font-size:24px;line-height:32px;color:#222;padding-top:30px;text-align:center;font-family:Lora,Palatino,Times,"Times New Roman",serif}.BuyBoxSection-683559780 .asia-link{color:#069;cursor:pointer;text-decoration:none;font-size:1.05em;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:1.05em6}.BuyBoxSection-683559780 .access-readcube{display:block;margin:0;margin-right:10%;margin-left:10%;font-size:14px;color:#222;padding-top:10px;text-align:center;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:20px}.BuyBoxSection-683559780 .access-asia-buybox{display:block;margin:0;margin-right:5%;margin-left:5%;font-size:14px;color:#222;padding-top:10px;text-align:center;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:20px}.BuyBoxSection-683559780 .access-buybox{display:block;margin:0;margin-right:30%;margin-left:30%;font-size:14px;color:#222;opacity:.8px;padding-top:10px;text-align:center;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:20px}.BuyBoxSection-683559780 .price-buybox{display:block;font-size:30px;color:#222;font-family:"Source Sans Pro",helvetica,sans-serif;padding-top:30px;text-align:center}.BuyBoxSection-683559780 .price-from{font-size:14px;padding-right:10px;color:#222;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:20px}.BuyBoxSection-683559780 .issue-buybox{display:block;font-size:13px;text-align:center;color:#222;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:19px}.BuyBoxSection-683559780 .no-price-buybox{display:block;font-size:13px;line-height:18px;text-align:center;padding-right:10%;padding-left:10%;padding-bottom:20px;padding-top:30px;color:#222;font-family:"Source Sans Pro",helvetica,sans-serif}.BuyBoxSection-683559780 .vat-buybox{display:block;margin-top:5px;margin-right:20%;margin-left:20%;font-size:11px;color:#222;padding-top:10px;padding-bottom:15px;text-align:center;font-family:"Source Sans Pro",helvetica,sans-serif;line-height:17px}.BuyBoxSection-683559780 .button-container{display:block;padding-right:20px;padding-left:20px}.BuyBoxSection-683559780 .button-container>a:hover,.Button-505204839:hover,.Button-1078489254:hover{text-decoration:none}.BuyBoxSection-683559780 .readcube-button{background:#fff;margin-top:30px}.BuyBoxSection-683559780 .button-asia{background:#069;border:1px solid #069;border-radius:0;cursor:pointer;display:block;padding:9px;outline:0;text-align:center;text-decoration:none;min-width:80px;margin-top:75px}.BuyBoxSection-683559780 .button-label-asia,.ButtonLabel-3869432492,.ButtonLabel-3296148077{display:block;color:#fff;font-size:17px;line-height:20px;font-family:"Source Sans Pro",helvetica,sans-serif;text-align:center;text-decoration:none;cursor:pointer}.Button-505204839,.Button-1078489254{background:#069;border:1px solid #069;border-radius:0;cursor:pointer;display:block;padding:9px;outline:0;text-align:center;text-decoration:none;min-width:80px;margin-top:10px}.Button-505204839 .readcube-label,.Button-1078489254 .readcube-label{color:#069}
/* style specs end */</style><section class="BuyBoxSection-683559780"><div class="subscribe-buybox"><div class="box-inner"><p class="title-buybox">Subscribe to Journal</p><p class="access-buybox">Get full journal access for 1 year</p><div><p class="price-buybox" id="subscription-price">217,36 €</p><p class="issue-buybox">only 4,26 € per issue</p></div><div class="button-container"><a href="/nature/subscribe" class="Button-505204839" dataTrack="click" dataTrackAction="subscribe" dataTrackLabel="link"><span class="ButtonLabel-3869432492">Subscribe</span></a></div><p class="vat-buybox">All prices include VAT for Italy.</p></div></div><div class="readcube-buybox"><div class="box-inner"><p class="title-readcube">Rent or Buy article</p><p class="access-readcube">Get time limited or full article access on ReadCube.</p><p id="readcube-price" class="price-buybox"><span class="price-from">from</span>$8.99</p><div class="button-container"><a href="//www.nature.com/articles/nature14539.epdf?no_publisher_access=1&amp;r3_referer=nature" class="readcube-button Button-1078489254" dataTrack="click" dataTrackAction="buy/rent now" dataTrackLabel="link"><span class="readcube-label ButtonLabel-3296148077">Rent or Buy</span></a></div><p class="vat-buybox">All prices are NET prices.</p></div></div></section><div></div></div>
  

    <nav class="c-access-options">
        <h3 class="c-access-options__heading">Additional access options:</h3>
        <ul class="c-access-options__list">
            <li>
                <a href="https://idp.nature.com/authorize/natureuser?client_id&#x3D;grover&amp;redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539"
                   data-track="click"
                   data-track-action="login"
                   data-track-category="article body"
                   data-track-label="link">Log in</a>
            </li>
            <li>
                <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539"
                   aria-hidden="true"
                   data-test="ra21"
                   data-track="click"
                   data-track-action="institution access"
                   data-track-category="article body"
                   data-track-label="link">Access through your institution</a>
            </li>
            <li>
                <a href="https://www.springernature.com/gp/librarians/licensing/license-options"
                   data-track="click"
                   data-track-action="learn-subscription"
                   data-track-category="article body"
                   data-track-label="link">Learn about institutional subscriptions</a>
            </li>
        </ul>
    </nav>


                            </div>
                            <div class="u-display-none">
                                <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Multilayer neural networks and backpropagation.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig1_HTML.jpg?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig1_HTML.jpg" alt="" loading="lazy" /></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Inside a convolutional network.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig2_HTML.jpg?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig2_HTML.jpg" alt="" loading="lazy" /></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: From image to text.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig3_HTML.jpg?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig3_HTML.jpg" alt="" loading="lazy" /></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: Visualizing the learned word vectors.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig4_HTML.jpg?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig4_HTML.jpg" alt="" loading="lazy" /></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: A recurrent neural network and the unfolding in time of the computation involved in its forward computation.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig5_HTML.jpg?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fnature14539/MediaObjects/41586_2015_Article_BFnature14539_Fig5_HTML.jpg" alt="" loading="lazy" /></picture></div></div></figure></div>
                            </div>
                        

                        <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">1</span><p class="c-article-references__text" itemprop="headline" id="ref-CR1">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. In <i>Proc. Advances in Neural Information Processing Systems 25</i> 1090–1098 (2012). <b>This report was a breakthrough that used convolutional nets to almost halve the error rate for object recognition, and precipitated the rapid adoption of deep learning by the computer vision community.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2025&amp;pages=1090-1098&amp;publication_year=2012&amp;author=Krizhevsky%2CA&amp;author=Sutskever%2CI&amp;author=Hinton%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">2</span><p class="c-article-references__text" itemprop="headline" id="ref-CR2">Farabet, C., Couprie, C., Najman, L. &amp; LeCun, Y. Learning hierarchical features for scene labeling. <i>IEEE Trans. Pattern Anal. Mach. Intell.</i> <b>35</b>, 1915–1929 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20hierarchical%20features%20for%20scene%20labeling&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.&amp;volume=35&amp;pages=1915-1929&amp;publication_year=2013&amp;author=Farabet%2CC&amp;author=Couprie%2CC&amp;author=Najman%2CL&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">3</span><p class="c-article-references__text" itemprop="headline" id="ref-CR3">Tompson, J., Jain, A., LeCun, Y. &amp; Bregler, C. Joint training of a convolutional network and a graphical model for human pose estimation. In <i>Proc. Advances in Neural Information Processing Systems 27</i> 1799–1807 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2027&amp;pages=1799-1807&amp;publication_year=2014&amp;author=Tompson%2CJ&amp;author=Jain%2CA&amp;author=LeCun%2CY&amp;author=Bregler%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">4</span><p class="c-article-references__text" itemprop="headline" id="ref-CR4">Szegedy, C. et al. Going deeper with convolutions. Preprint at <a href="http://arxiv.org/abs/1409.4842">http://arxiv.org/abs/1409.4842</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">5</span><p class="c-article-references__text" itemprop="headline" id="ref-CR5">Mikolov, T., Deoras, A., Povey, D., Burget, L. &amp; Cernocky, J. Strategies for training large scale neural network language models. In <i>Proc. Automatic Speech Recognition and Understanding</i> 196–201 (2011).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Automatic%20Speech%20Recognition%20and%20Understanding&amp;pages=196-201&amp;publication_year=2011&amp;author=Mikolov%2CT&amp;author=Deoras%2CA&amp;author=Povey%2CD&amp;author=Burget%2CL&amp;author=Cernocky%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">6</span><p class="c-article-references__text" itemprop="headline" id="ref-CR6">Hinton, G. et al. Deep neural networks for acoustic modeling in speech recognition. <i>IEEE Signal Processing Magazine</i> <b>29</b>, 82–97 (2012). <b>This joint paper from the major speech recognition laboratories, summarizing the breakthrough achieved with deep learning on the task of phonetic classification for automatic speech recognition, was the first major industrial application of deep learning.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012ISPM...29...82H" aria-label="View reference 6 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition&amp;journal=IEEE%20Signal%20Processing%20Magazine&amp;volume=29&amp;pages=82-97&amp;publication_year=2012&amp;author=Hinton%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">7</span><p class="c-article-references__text" itemprop="headline" id="ref-CR7">Sainath, T., Mohamed, A.-R., Kingsbury, B. &amp; Ramabhadran, B. Deep convolutional neural networks for LVCSR. In <i>Proc. Acoustics, Speech and Signal Processing</i> 8614–8618 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Acoustics%2C%20Speech%20and%20Signal%20Processing&amp;pages=8614-8618&amp;publication_year=2013&amp;author=Sainath%2CT&amp;author=Mohamed%2CA-R&amp;author=Kingsbury%2CB&amp;author=Ramabhadran%2CB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">8</span><p class="c-article-references__text" itemprop="headline" id="ref-CR8">Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E. &amp; Svetnik, V. Deep neural nets as a method for quantitative structure-activity relationships. <i>J. Chem. Inf. Model.</i> <b>55</b>, 263–274 (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BC2MXhvFGns70%253D" aria-label="View reference 8 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20nets%20as%20a%20method%20for%20quantitative%20structure-activity%20relationships&amp;journal=J.%20Chem.%20Inf.%20Model.&amp;volume=55&amp;pages=263-274&amp;publication_year=2015&amp;author=Ma%2CJ&amp;author=Sheridan%2CRP&amp;author=Liaw%2CA&amp;author=Dahl%2CGE&amp;author=Svetnik%2CV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">9</span><p class="c-article-references__text" itemprop="headline" id="ref-CR9">Ciodaro, T., Deva, D., de Seixas, J. &amp; Damazio, D. Online particle detection with neural networks based on topological calorimetry information. <i>J. Phys. Conf. Series</i> <b>368</b>, 012030 (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Online%20particle%20detection%20with%20neural%20networks%20based%20on%20topological%20calorimetry%20information&amp;journal=J.%20Phys.%20Conf.%20Series&amp;volume=368&amp;publication_year=2012&amp;author=Ciodaro%2CT&amp;author=Deva%2CD&amp;author=de%20Seixas%2CJ&amp;author=Damazio%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">10</span><p class="c-article-references__text" itemprop="headline" id="ref-CR10">Kaggle. Higgs boson machine learning challenge. <i>Kaggle</i> <a href="https://www.kaggle.com/c/higgs-boson">https://www.kaggle.com/c/higgs-boson</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">11</span><p class="c-article-references__text" itemprop="headline" id="ref-CR11">Helmstaedter, M. et al. Connectomic reconstruction of the inner plexiform layer in the mouse retina. <i>Nature</i> <b>500</b>, 168–174 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2013Natur.500..168H" aria-label="View reference 11 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BC3sXht1emtrnJ" aria-label="View reference 11 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Connectomic%20reconstruction%20of%20the%20inner%20plexiform%20layer%20in%20the%20mouse%20retina&amp;journal=Nature&amp;volume=500&amp;pages=168-174&amp;publication_year=2013&amp;author=Helmstaedter%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">12</span><p class="c-article-references__text" itemprop="headline" id="ref-CR12">Leung, M. K., Xiong, H. Y., Lee, L. J. &amp; Frey, B. J. Deep learning of the tissue-regulated splicing code. <i>Bioinformatics</i> <b>30</b>, i121–i129 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BC2cXpvFCqsLg%253D" aria-label="View reference 12 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24931975" aria-label="View reference 12 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4058935" aria-label="View reference 12 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning%20of%20the%20tissue-regulated%20splicing%20code&amp;journal=Bioinformatics&amp;volume=30&amp;pages=i121-i129&amp;publication_year=2014&amp;author=Leung%2CMK&amp;author=Xiong%2CHY&amp;author=Lee%2CLJ&amp;author=Frey%2CBJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">13</span><p class="c-article-references__text" itemprop="headline" id="ref-CR13">Xiong, H. Y. et al. The human splicing code reveals new insights into the genetic determinants of disease. <i>Science</i> <b>347</b>, 6218 (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20human%20splicing%20code%20reveals%20new%20insights%20into%20the%20genetic%20determinants%20of%20disease&amp;journal=Science&amp;volume=347&amp;publication_year=2015&amp;author=Xiong%2CHY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">14</span><p class="c-article-references__text" itemprop="headline" id="ref-CR14">Collobert, R., et al. Natural language processing (almost) from scratch. <i>J. Mach. Learn. Res.</i> <b>12</b>, 2493–2537 (2011).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1280.68161" aria-label="View reference 14 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20language%20processing%20%28almost%29%20from%20scratch&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=12&amp;pages=2493-2537&amp;publication_year=2011&amp;author=Collobert%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">15</span><p class="c-article-references__text" itemprop="headline" id="ref-CR15">Bordes, A., Chopra, S. &amp; Weston, J. Question answering with subgraph embeddings. In <i>Proc. Empirical Methods in Natural Language Processing</i> <a href="http://arxiv.org/abs/1406.3676v3">http://arxiv.org/abs/1406.3676v3</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Empirical%20Methods%20in%20Natural%20Language%20Processing&amp;publication_year=2014&amp;author=Bordes%2CA&amp;author=Chopra%2CS&amp;author=Weston%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">16</span><p class="c-article-references__text" itemprop="headline" id="ref-CR16">Jean, S., Cho, K., Memisevic, R. &amp; Bengio, Y. On using very large target vocabulary for neural machine translation. In <i>Proc. ACL-IJCNLP</i> <a href="http://arxiv.org/abs/1412.2007">http://arxiv.org/abs/1412.2007</a> (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20ACL-IJCNLP&amp;publication_year=2015&amp;author=Jean%2CS&amp;author=Cho%2CK&amp;author=Memisevic%2CR&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">17</span><p class="c-article-references__text" itemprop="headline" id="ref-CR17">Sutskever, I. Vinyals, O. &amp; Le. Q. V. Sequence to sequence learning with neural networks. In <i>Proc. Advances in Neural Information Processing Systems 27</i> 3104–3112 (2014). <b>This paper showed state-of-the-art machine translation results with the architecture introduced in ref. 72, with a recurrent network trained to read a sentence in one language, produce a semantic representation of its meaning, and generate a translation in another language.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2027&amp;pages=3104-3112&amp;publication_year=2014&amp;author=Sutskever%2CI&amp;author=Vinyals%2CO&amp;author=Le%2CQV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">18</span><p class="c-article-references__text" itemprop="headline" id="ref-CR18">Bottou, L. &amp; Bousquet, O. The tradeoffs of large scale learning. In <i>Proc. Advances in Neural Information Processing Systems 20</i> 161–168 (2007).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2020&amp;pages=161-168&amp;publication_year=2007&amp;author=Bottou%2CL&amp;author=Bousquet%2CO">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">19</span><p class="c-article-references__text" itemprop="headline" id="ref-CR19">Duda, R. O. &amp; Hart, P. E. <i>Pattern Classification and Scene Analysis</i> (Wiley, 1973).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pattern%20Classification%20and%20Scene%20Analysis&amp;publication_year=1973&amp;author=Duda%2CRO&amp;author=Hart%2CPE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">20</span><p class="c-article-references__text" itemprop="headline" id="ref-CR20">Schölkopf, B. &amp; Smola, A. <i>Learning with Kernels</i> (MIT Press, 2002).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20Kernels&amp;publication_year=2002&amp;author=Sch%C3%B6lkopf%2CB&amp;author=Smola%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">21</span><p class="c-article-references__text" itemprop="headline" id="ref-CR21">Bengio, Y., Delalleau, O. &amp; Le Roux, N. The curse of highly variable functions for local kernel machines. In <i>Proc. Advances in Neural Information Processing Systems 18</i> 107–114 (2005).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2018&amp;pages=107-114&amp;publication_year=2005&amp;author=Bengio%2CY&amp;author=Delalleau%2CO&amp;author=Le%20Roux%2CN">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">22</span><p class="c-article-references__text" itemprop="headline" id="ref-CR22">Selfridge, O. G. Pandemonium: a paradigm for learning in mechanisation of thought processes. In <i>Proc. Symposium on Mechanisation of Thought Processes</i> 513–526 (1958).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Symposium%20on%20Mechanisation%20of%20Thought%20Processes&amp;pages=513-526&amp;publication_year=1958&amp;author=Selfridge%2COG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">23</span><p class="c-article-references__text" itemprop="headline" id="ref-CR23">Rosenblatt, F. <i>The Perceptron — A Perceiving and Recognizing Automaton</i>. Tech. Rep. 85-460-1 (Cornell Aeronautical Laboratory, 1957).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Perceptron%20%E2%80%94%20A%20Perceiving%20and%20Recognizing%20Automaton&amp;publication_year=1957&amp;author=Rosenblatt%2CF">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">24</span><p class="c-article-references__text" itemprop="headline" id="ref-CR24">Werbos, P. <i>Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences</i>. PhD thesis, Harvard Univ. (1974).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Beyond%20Regression%3A%20New%20Tools%20for%20Prediction%20and%20Analysis%20in%20the%20Behavioral%20Sciences&amp;publication_year=1974&amp;author=Werbos%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">25</span><p class="c-article-references__text" itemprop="headline" id="ref-CR25">Parker, D. B. <i>Learning Logic</i> Report TR–47 (MIT Press, 1985).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20Logic&amp;publication_year=1985&amp;author=Parker%2CDB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">26</span><p class="c-article-references__text" itemprop="headline" id="ref-CR26">LeCun, Y. Une procédure d'apprentissage pour Réseau à seuil assymétrique in <i>Cognitiva 85: a la Frontière de l'Intelligence Artificielle, des Sciences de la Connaissance et des Neurosciences</i> [in French] 599–604 (1985).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitiva%2085%3A%20a%20la%20Fronti%C3%A8re%20de%20l%27Intelligence%20Artificielle%2C%20des%20Sciences%20de%20la%20Connaissance%20et%20des%20Neurosciences&amp;pages=599-604&amp;publication_year=1985&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">27</span><p class="c-article-references__text" itemprop="headline" id="ref-CR27">Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. Learning representations by back-propagating errors. <i>Nature</i> <b>323</b>, 533–536 (1986).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=1986Natur.323..533R" aria-label="View reference 27 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1369.68284" aria-label="View reference 27 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20representations%20by%20back-propagating%20errors&amp;journal=Nature&amp;volume=323&amp;pages=533-536&amp;publication_year=1986&amp;author=Rumelhart%2CDE&amp;author=Hinton%2CGE&amp;author=Williams%2CRJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">28</span><p class="c-article-references__text" itemprop="headline" id="ref-CR28">Glorot, X., Bordes, A. &amp; Bengio. Y. Deep sparse rectifier neural networks. In <i>Proc. 14th International Conference on Artificial Intelligence and Statistics</i> 315–323 (2011). <b>This paper showed that supervised training of very deep neural networks is much faster if the hidden layers are composed of ReLU.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2014th%20International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics&amp;pages=315-323&amp;publication_year=2011&amp;author=Glorot%2CX&amp;author=Bordes%2CA&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">29</span><p class="c-article-references__text" itemprop="headline" id="ref-CR29">Dauphin, Y. et al. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In <i>Proc. Advances in Neural Information Processing Systems 27</i> 2933–2941 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2027&amp;pages=2933-2941&amp;publication_year=2014&amp;author=Dauphin%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">30</span><p class="c-article-references__text" itemprop="headline" id="ref-CR30">Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B. &amp; LeCun, Y. The loss surface of multilayer networks. In <i>Proc. Conference on AI and Statistics</i> <a href="http://arxiv.org/abs/1412.0233">http://arxiv.org/abs/1412.0233</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Conference%20on%20AI%20and%20Statistics&amp;publication_year=2014&amp;author=Choromanska%2CA&amp;author=Henaff%2CM&amp;author=Mathieu%2CM&amp;author=Arous%2CGB&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">31</span><p class="c-article-references__text" itemprop="headline" id="ref-CR31">Hinton, G. E. What kind of graphical model is the brain? In <i>Proc. 19th International Joint Conference on Artificial intelligence</i> 1765–1775 (2005).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2019th%20International%20Joint%20Conference%20on%20Artificial%20intelligence&amp;pages=1765-1775&amp;publication_year=2005&amp;author=Hinton%2CGE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">32</span><p class="c-article-references__text" itemprop="headline" id="ref-CR32">Hinton, G. E., Osindero, S. &amp; Teh, Y.-W. A fast learning algorithm for deep belief nets. <i>Neural Comp.</i> <b>18</b>, 1527–1554 (2006). <b>This paper introduced a novel and effective way of training very deep neural networks by pre-training one hidden layer at a time using the unsupervised learning procedure for restricted Boltzmann machines.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2224485" aria-label="View reference 32 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1106.68094" aria-label="View reference 32 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets&amp;journal=Neural%20Comp.&amp;volume=18&amp;pages=1527-1554&amp;publication_year=2006&amp;author=Hinton%2CGE&amp;author=Osindero%2CS&amp;author=Teh%2CY-W">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">33</span><p class="c-article-references__text" itemprop="headline" id="ref-CR33">Bengio, Y., Lamblin, P., Popovici, D. &amp; Larochelle, H. Greedy layer-wise training of deep networks. In <i>Proc</i>. <i>Advances in Neural Information Processing Systems 19</i> 153–160 (2006). <b>This report demonstrated that the unsupervised pre-training method introduced in ref. 32 significantly improves performance on test data and generalizes the method to other unsupervised representation-learning techniques, such as auto-encoders.</b></p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">34</span><p class="c-article-references__text" itemprop="headline" id="ref-CR34">Ranzato, M., Poultney, C., Chopra, S. &amp; LeCun, Y. Efficient learning of sparse representations with an energy-based model. In <i>Proc. Advances in Neural Information Processing Systems 19</i> 1137–1144 (2006).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2019&amp;pages=1137-1144&amp;publication_year=2006&amp;author=Ranzato%2CM&amp;author=Poultney%2CC&amp;author=Chopra%2CS&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">35</span><p class="c-article-references__text" itemprop="headline" id="ref-CR35">Hinton, G. E. &amp; Salakhutdinov, R. Reducing the dimensionality of data with neural networks. <i>Science</i> <b>313</b>, 504–507 (2006).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2006Sci...313..504H" aria-label="View reference 35 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2242509" aria-label="View reference 35 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BD28Xnt1KntrY%253D" aria-label="View reference 35 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16873662" aria-label="View reference 35 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC16873662" aria-label="View reference 35 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1226.68083" aria-label="View reference 35 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks&amp;journal=Science&amp;volume=313&amp;pages=504-507&amp;publication_year=2006&amp;author=Hinton%2CGE&amp;author=Salakhutdinov%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">36</span><p class="c-article-references__text" itemprop="headline" id="ref-CR36">Sermanet, P., Kavukcuoglu, K., Chintala, S. &amp; LeCun, Y. Pedestrian detection with unsupervised multi-stage feature learning. In <i>Proc. International Conference on Computer Vision and Pattern Recognition</i> <a href="http://arxiv.org/abs/1212.0142">http://arxiv.org/abs/1212.0142</a> (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition&amp;publication_year=2013&amp;author=Sermanet%2CP&amp;author=Kavukcuoglu%2CK&amp;author=Chintala%2CS&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">37</span><p class="c-article-references__text" itemprop="headline" id="ref-CR37">Raina, R., Madhavan, A. &amp; Ng, A. Y. Large-scale deep unsupervised learning using graphics processors. In <i>Proc. 26th Annual International Conference on Machine Learning</i> 873–880 (2009).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2026th%20Annual%20International%20Conference%20on%20Machine%20Learning&amp;pages=873-880&amp;publication_year=2009&amp;author=Raina%2CR&amp;author=Madhavan%2CA&amp;author=Ng%2CAY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">38</span><p class="c-article-references__text" itemprop="headline" id="ref-CR38">Mohamed, A.-R., Dahl, G. E. &amp; Hinton, G. Acoustic modeling using deep belief networks. <i>IEEE Trans. Audio Speech Lang. Process.</i> <b>20</b>, 14–22 (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Acoustic%20modeling%20using%20deep%20belief%20networks&amp;journal=IEEE%20Trans.%20Audio%20Speech%20Lang.%20Process.&amp;volume=20&amp;pages=14-22&amp;publication_year=2012&amp;author=Mohamed%2CA-R&amp;author=Dahl%2CGE&amp;author=Hinton%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">39</span><p class="c-article-references__text" itemprop="headline" id="ref-CR39">Dahl, G. E., Yu, D., Deng, L. &amp; Acero, A. Context-dependent pre-trained deep neural networks for large vocabulary speech recognition. <i>IEEE Trans. Audio Speech Lang. Process.</i> <b>20</b>, 33–42 (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Context-dependent%20pre-trained%20deep%20neural%20networks%20for%20large%20vocabulary%20speech%20recognition&amp;journal=IEEE%20Trans.%20Audio%20Speech%20Lang.%20Process.&amp;volume=20&amp;pages=33-42&amp;publication_year=2012&amp;author=Dahl%2CGE&amp;author=Yu%2CD&amp;author=Deng%2CL&amp;author=Acero%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">40</span><p class="c-article-references__text" itemprop="headline" id="ref-CR40">Bengio, Y., Courville, A. &amp; Vincent, P. Representation learning: a review and new perspectives. <i>IEEE Trans. Pattern Anal. Machine Intell.</i> <b>35</b>, 1798–1828 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Representation%20learning%3A%20a%20review%20and%20new%20perspectives&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Machine%20Intell.&amp;volume=35&amp;pages=1798-1828&amp;publication_year=2013&amp;author=Bengio%2CY&amp;author=Courville%2CA&amp;author=Vincent%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">41</span><p class="c-article-references__text" itemprop="headline" id="ref-CR41">LeCun, Y. et al. Handwritten digit recognition with a back-propagation network. In <i>Proc. Advances in Neural Information Processing Systems</i> 396–404 (1990). <b>This is the first paper on convolutional networks trained by backpropagation for the task of classifying low-resolution images of handwritten digits.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems&amp;pages=396-404&amp;publication_year=1990&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">42</span><p class="c-article-references__text" itemprop="headline" id="ref-CR42">LeCun, Y., Bottou, L., Bengio, Y. &amp; Haffner, P. Gradient-based learning applied to document recognition. <i>Proc. IEEE</i> <b>86</b>, 2278–2324 (1998). <b>This overview paper on the principles of end-to-end training of modular systems such as deep neural networks using gradient-based optimization showed how neural networks (and in particular convolutional nets) can be combined with search or inference mechanisms to model complex outputs that are interdependent, such as sequences of characters associated with the content of a document.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gradient-based%20learning%20applied%20to%20document%20recognition&amp;journal=Proc.%20IEEE&amp;volume=86&amp;pages=2278-2324&amp;publication_year=1998&amp;author=LeCun%2CY&amp;author=Bottou%2CL&amp;author=Bengio%2CY&amp;author=Haffner%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">43</span><p class="c-article-references__text" itemprop="headline" id="ref-CR43">Hubel, D. H. &amp; Wiesel, T. N. Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex. <i>J. Physiol.</i> <b>160</b>, 106–154 (1962).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ASTN%3A280%3ADyaF38%252FltFSisA%253D%253D" aria-label="View reference 43 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=14449617" aria-label="View reference 43 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359523" aria-label="View reference 43 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Receptive%20fields%2C%20binocular%20interaction%2C%20and%20functional%20architecture%20in%20the%20cat%27s%20visual%20cortex&amp;journal=J.%20Physiol.&amp;volume=160&amp;pages=106-154&amp;publication_year=1962&amp;author=Hubel%2CDH&amp;author=Wiesel%2CTN">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">44</span><p class="c-article-references__text" itemprop="headline" id="ref-CR44">Felleman, D. J. &amp; Essen, D. C. V. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ASTN%3A280%3ADyaK38zltlGmsg%253D%253D" aria-label="View reference 44 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1822724" aria-label="View reference 44 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Essen%2CDCV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">45</span><p class="c-article-references__text" itemprop="headline" id="ref-CR45">Cadieu, C. F. et al. Deep neural networks rival the representation of primate it cortex for core visual object recognition. <i>PLoS Comp. Biol.</i> <b>10</b>, e1003963 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20networks%20rival%20the%20representation%20of%20primate%20it%20cortex%20for%20core%20visual%20object%20recognition&amp;journal=PLoS%20Comp.%20Biol.&amp;volume=10&amp;publication_year=2014&amp;author=Cadieu%2CCF">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">46</span><p class="c-article-references__text" itemprop="headline" id="ref-CR46">Fukushima, K. &amp; Miyake, S. Neocognitron: a new algorithm for pattern recognition tolerant of deformations and shifts in position. <i>Pattern Recognition</i> <b>15</b>, 455–469 (1982).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%3A%20a%20new%20algorithm%20for%20pattern%20recognition%20tolerant%20of%20deformations%20and%20shifts%20in%20position&amp;journal=Pattern%20Recognition&amp;volume=15&amp;pages=455-469&amp;publication_year=1982&amp;author=Fukushima%2CK&amp;author=Miyake%2CS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">47</span><p class="c-article-references__text" itemprop="headline" id="ref-CR47">Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K. &amp; Lang, K. Phoneme recognition using time-delay neural networks. <i>IEEE Trans. Acoustics Speech Signal Process.</i> <b>37</b>, 328–339 (1989).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Phoneme%20recognition%20using%20time-delay%20neural%20networks&amp;journal=IEEE%20Trans.%20Acoustics%20Speech%20Signal%20Process.&amp;volume=37&amp;pages=328-339&amp;publication_year=1989&amp;author=Waibel%2CA&amp;author=Hanazawa%2CT&amp;author=Hinton%2CGE&amp;author=Shikano%2CK&amp;author=Lang%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">48</span><p class="c-article-references__text" itemprop="headline" id="ref-CR48">Bottou, L., Fogelman-Soulié, F., Blanchet, P. &amp; Lienard, J. Experiments with time delay networks and dynamic time warping for speaker independent isolated digit recognition. In <i>Proc. EuroSpeech 89</i> 537–540 (1989).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20EuroSpeech%2089&amp;pages=537-540&amp;publication_year=1989&amp;author=Bottou%2CL&amp;author=Fogelman-Souli%C3%A9%2CF&amp;author=Blanchet%2CP&amp;author=Lienard%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">49</span><p class="c-article-references__text" itemprop="headline" id="ref-CR49">Simard, D., Steinkraus, P. Y. &amp; Platt, J. C. Best practices for convolutional neural networks. In <i>Proc. Document Analysis and Recognition</i> 958–963 (2003).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Document%20Analysis%20and%20Recognition&amp;pages=958-963&amp;publication_year=2003&amp;author=Simard%2CD&amp;author=Steinkraus%2CPY&amp;author=Platt%2CJC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">50</span><p class="c-article-references__text" itemprop="headline" id="ref-CR50">Vaillant, R., Monrocq, C. &amp; LeCun, Y. Original approach for the localisation of objects in images. In <i>Proc. Vision, Image, and Signal Processing</i> <b>141</b>, 245–250 (1994).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Vision%2C%20Image%2C%20and%20Signal%20Processing&amp;pages=245-250&amp;publication_year=1994&amp;author=Vaillant%2CR&amp;author=Monrocq%2CC&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">51</span><p class="c-article-references__text" itemprop="headline" id="ref-CR51">Nowlan, S. &amp; Platt, J. in <i>Neural Information Processing Systems</i> 901–908 (1995).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20Information%20Processing%20Systems&amp;pages=901-908&amp;publication_year=1995&amp;author=Nowlan%2CS&amp;author=Platt%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">52</span><p class="c-article-references__text" itemprop="headline" id="ref-CR52">Lawrence, S., Giles, C. L., Tsoi, A. C. &amp; Back, A. D. Face recognition: a convolutional neural-network approach. <i>IEEE Trans. Neural Networks</i> <b>8</b>, 98–113 (1997).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ASTN%3A280%3ADC%252BD1c%252FpvVamug%253D%253D" aria-label="View reference 52 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Face%20recognition%3A%20a%20convolutional%20neural-network%20approach&amp;journal=IEEE%20Trans.%20Neural%20Networks&amp;volume=8&amp;pages=98-113&amp;publication_year=1997&amp;author=Lawrence%2CS&amp;author=Giles%2CCL&amp;author=Tsoi%2CAC&amp;author=Back%2CAD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">53</span><p class="c-article-references__text" itemprop="headline" id="ref-CR53">Ciresan, D., Meier, U. Masci, J. &amp; Schmidhuber, J. Multi-column deep neural network for traffic sign classification. <i>Neural Networks</i> <b>32</b>, 333–338 (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-column%20deep%20neural%20network%20for%20traffic%20sign%20classification&amp;journal=Neural%20Networks&amp;volume=32&amp;pages=333-338&amp;publication_year=2012&amp;author=Ciresan%2CD&amp;author=Meier%2CU&amp;author=Masci%2CJ&amp;author=Schmidhuber%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">54</span><p class="c-article-references__text" itemprop="headline" id="ref-CR54">Ning, F. et al. Toward automatic phenotyping of developing embryos from videos. <i>IEEE Trans. Image Process.</i> <b>14</b>, 1360–1371 (2005).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2005ITIP...14.1360N" aria-label="View reference 54 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Toward%20automatic%20phenotyping%20of%20developing%20embryos%20from%20videos&amp;journal=IEEE%20Trans.%20Image%20Process.&amp;volume=14&amp;pages=1360-1371&amp;publication_year=2005&amp;author=Ning%2CF">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">55</span><p class="c-article-references__text" itemprop="headline" id="ref-CR55">Turaga, S. C. et al. Convolutional networks can learn to generate affinity graphs for image segmentation. <i>Neural Comput.</i> <b>22</b>, 511–538 (2010).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19922289" aria-label="View reference 55 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC19922289" aria-label="View reference 55 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1183.92055" aria-label="View reference 55 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Convolutional%20networks%20can%20learn%20to%20generate%20affinity%20graphs%20for%20image%20segmentation&amp;journal=Neural%20Comput.&amp;volume=22&amp;pages=511-538&amp;publication_year=2010&amp;author=Turaga%2CSC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">56</span><p class="c-article-references__text" itemprop="headline" id="ref-CR56">Garcia, C. &amp; Delakis, M. Convolutional face finder: a neural architecture for fast and robust face detection. <i>IEEE Trans. Pattern Anal. Machine Intell.</i> <b>26</b>, 1408–1423 (2004).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Convolutional%20face%20finder%3A%20a%20neural%20architecture%20for%20fast%20and%20robust%20face%20detection&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Machine%20Intell.&amp;volume=26&amp;pages=1408-1423&amp;publication_year=2004&amp;author=Garcia%2CC&amp;author=Delakis%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">57</span><p class="c-article-references__text" itemprop="headline" id="ref-CR57">Osadchy, M., LeCun, Y. &amp; Miller, M. Synergistic face detection and pose estimation with energy-based models. <i>J. Mach. Learn. Res.</i> <b>8</b>, 1197–1215 (2007).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 57 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Synergistic%20face%20detection%20and%20pose%20estimation%20with%20energy-based%20models&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=8&amp;pages=1197-1215&amp;publication_year=2007&amp;author=Osadchy%2CM&amp;author=LeCun%2CY&amp;author=Miller%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">58</span><p class="c-article-references__text" itemprop="headline" id="ref-CR58">Tompson, J., Goroshin, R. R., Jain, A., LeCun, Y. Y. &amp; Bregler, C. C. Efficient object localization using convolutional networks. In <i>Proc. Conference on Computer Vision and Pattern Recognition</i> <a href="http://arxiv.org/abs/1411.4280">http://arxiv.org/abs/1411.4280</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition&amp;publication_year=2014&amp;author=Tompson%2CJ&amp;author=Goroshin%2CRR&amp;author=Jain%2CA&amp;author=LeCun%2CYY&amp;author=Bregler%2CCC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">59</span><p class="c-article-references__text" itemprop="headline" id="ref-CR59">Taigman, Y., Yang, M., Ranzato, M. &amp; Wolf, L. Deepface: closing the gap to human-level performance in face verification. In <i>Proc. Conference on Computer Vision and Pattern Recognition</i> 1701–1708 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition&amp;pages=1701-1708&amp;publication_year=2014&amp;author=Taigman%2CY&amp;author=Yang%2CM&amp;author=Ranzato%2CM&amp;author=Wolf%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">60</span><p class="c-article-references__text" itemprop="headline" id="ref-CR60">Hadsell, R. et al. Learning long-range vision for autonomous off-road driving. <i>J. Field Robot.</i> <b>26</b>, 120–144 (2009).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 60 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20long-range%20vision%20for%20autonomous%20off-road%20driving&amp;journal=J.%20Field%20Robot.&amp;volume=26&amp;pages=120-144&amp;publication_year=2009&amp;author=Hadsell%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">61</span><p class="c-article-references__text" itemprop="headline" id="ref-CR61">Farabet, C., Couprie, C., Najman, L. &amp; LeCun, Y. Scene parsing with multiscale feature learning, purity trees, and optimal covers. In <i>Proc. International Conference on Machine Learning</i> <a href="http://arxiv.org/abs/1202.2160">http://arxiv.org/abs/1202.2160</a> (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 61 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Machine%20Learning&amp;publication_year=2012&amp;author=Farabet%2CC&amp;author=Couprie%2CC&amp;author=Najman%2CL&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">62</span><p class="c-article-references__text" itemprop="headline" id="ref-CR62">Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. &amp; Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. <i>J. Machine Learning Res.</i> <b>15</b>, 1929–1958 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3231592" aria-label="View reference 62 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1318.68153" aria-label="View reference 62 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting&amp;journal=J.%20Machine%20Learning%20Res.&amp;volume=15&amp;pages=1929-1958&amp;publication_year=2014&amp;author=Srivastava%2CN&amp;author=Hinton%2CG&amp;author=Krizhevsky%2CA&amp;author=Sutskever%2CI&amp;author=Salakhutdinov%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">63</span><p class="c-article-references__text" itemprop="headline" id="ref-CR63">Sermanet, P. et al. Overfeat: integrated recognition, localization and detection using convolutional networks. In <i>Proc. International Conference on Learning Representations</i> <a href="http://arxiv.org/abs/1312.6229">http://arxiv.org/abs/1312.6229</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 63 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Learning%20Representations&amp;publication_year=2014&amp;author=Sermanet%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">64</span><p class="c-article-references__text" itemprop="headline" id="ref-CR64">Girshick, R., Donahue, J., Darrell, T. &amp; Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. In <i>Proc. Conference on Computer Vision and Pattern Recognition</i> 580–587 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 64 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition&amp;pages=580-587&amp;publication_year=2014&amp;author=Girshick%2CR&amp;author=Donahue%2CJ&amp;author=Darrell%2CT&amp;author=Malik%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">65</span><p class="c-article-references__text" itemprop="headline" id="ref-CR65">Simonyan, K. &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition. In <i>Proc. International Conference on Learning Representations</i> <a href="http://arxiv.org/abs/1409.1556">http://arxiv.org/abs/1409.1556</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 65 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Learning%20Representations&amp;publication_year=2014&amp;author=Simonyan%2CK&amp;author=Zisserman%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">66</span><p class="c-article-references__text" itemprop="headline" id="ref-CR66">Boser, B., Sackinger, E., Bromley, J., LeCun, Y. &amp; Jackel, L. An analog neural network processor with programmable topology. <i>J. Solid State Circuits</i> <b>26</b>, 2017–2025 (1991).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=1991IJSSC..26.2017B" aria-label="View reference 66 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 66 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analog%20neural%20network%20processor%20with%20programmable%20topology&amp;journal=J.%20Solid%20State%20Circuits&amp;volume=26&amp;pages=2017-2025&amp;publication_year=1991&amp;author=Boser%2CB&amp;author=Sackinger%2CE&amp;author=Bromley%2CJ&amp;author=LeCun%2CY&amp;author=Jackel%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">67</span><p class="c-article-references__text" itemprop="headline" id="ref-CR67">Farabet, C. et al. Large-scale FPGA-based convolutional networks. In <i>Scaling up Machine Learning: Parallel and Distributed Approaches</i> (eds Bekkerman, R., Bilenko, M. &amp; Langford, J.) 399–419 (Cambridge Univ. Press, 2011).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 67 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Scaling%20up%20Machine%20Learning%3A%20Parallel%20and%20Distributed%20Approaches&amp;pages=399-419&amp;publication_year=2011&amp;author=Farabet%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">68</span><p class="c-article-references__text" itemprop="headline" id="ref-CR68">Bengio, Y. <i>Learning Deep Architectures for AI</i> (Now, 2009).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 68 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20Deep%20Architectures%20for%20AI&amp;publication_year=2009&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">69</span><p class="c-article-references__text" itemprop="headline" id="ref-CR69">Montufar, G. &amp; Morton, J. When does a mixture of products contain a product of mixtures? <i>J. Discrete Math.</i> <b>29</b>, 321–347 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3310972" aria-label="View reference 69 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1328.68170" aria-label="View reference 69 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 69 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20does%20a%20mixture%20of%20products%20contain%20a%20product%20of%20mixtures%3F&amp;journal=J.%20Discrete%20Math.&amp;volume=29&amp;pages=321-347&amp;publication_year=2014&amp;author=Montufar%2CG&amp;author=Morton%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">70</span><p class="c-article-references__text" itemprop="headline" id="ref-CR70">Montufar, G. F., Pascanu, R., Cho, K. &amp; Bengio, Y. On the number of linear regions of deep neural networks. In <i>Proc. Advances in Neural Information Processing Systems 27</i> 2924–2932 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 70 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2027&amp;pages=2924-2932&amp;publication_year=2014&amp;author=Montufar%2CGF&amp;author=Pascanu%2CR&amp;author=Cho%2CK&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">71</span><p class="c-article-references__text" itemprop="headline" id="ref-CR71">Bengio, Y., Ducharme, R. &amp; Vincent, P. A neural probabilistic language model. In <i>Proc. Advances in Neural Information Processing Systems 13</i> 932–938 (2001). <b>This paper introduced neural language models, which learn to convert a word symbol into a word vector or word embedding composed of learned semantic features in order to predict the next word in a sequence.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 71 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2013&amp;pages=932-938&amp;publication_year=2001&amp;author=Bengio%2CY&amp;author=Ducharme%2CR&amp;author=Vincent%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">72</span><p class="c-article-references__text" itemprop="headline" id="ref-CR72">Cho, K. et al. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In <i>Proc. Conference on Empirical Methods in Natural Language Processing</i> 1724–1734 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 72 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing&amp;pages=1724-1734&amp;publication_year=2014&amp;author=Cho%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">73</span><p class="c-article-references__text" itemprop="headline" id="ref-CR73">Schwenk, H. Continuous space language models. <i>Computer Speech Lang.</i> <b>21</b>, 492–518 (2007).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 73 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20space%20language%20models&amp;journal=Computer%20Speech%20Lang.&amp;volume=21&amp;pages=492-518&amp;publication_year=2007&amp;author=Schwenk%2CH">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">74</span><p class="c-article-references__text" itemprop="headline" id="ref-CR74">Socher, R., Lin, C. C-Y., Manning, C. &amp; Ng, A. Y. Parsing natural scenes and natural language with recursive neural networks. In <i>Proc. International Conference on Machine Learning</i> 129–136 (2011).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 74 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Machine%20Learning&amp;pages=129-136&amp;publication_year=2011&amp;author=Socher%2CR&amp;author=Lin%2CCC-Y&amp;author=Manning%2CC&amp;author=Ng%2CAY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">75</span><p class="c-article-references__text" itemprop="headline" id="ref-CR75">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. &amp; Dean, J. Distributed representations of words and phrases and their compositionality. In <i>Proc. Advances in Neural Information Processing Systems 26</i> 3111–3119 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 75 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2026&amp;pages=3111-3119&amp;publication_year=2013&amp;author=Mikolov%2CT&amp;author=Sutskever%2CI&amp;author=Chen%2CK&amp;author=Corrado%2CG&amp;author=Dean%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">76</span><p class="c-article-references__text" itemprop="headline" id="ref-CR76">Bahdanau, D., Cho, K. &amp; Bengio, Y. Neural machine translation by jointly learning to align and translate. In <i>Proc. International Conference on Learning Representations</i> <a href="http://arxiv.org/abs/1409.0473">http://arxiv.org/abs/1409.0473</a> (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 76 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Learning%20Representations&amp;publication_year=2015&amp;author=Bahdanau%2CD&amp;author=Cho%2CK&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">77</span><p class="c-article-references__text" itemprop="headline" id="ref-CR77">Hochreiter, S. Untersuchungen zu dynamischen neuronalen Netzen [in German] Diploma thesis, T.U. Münich (1991).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">78</span><p class="c-article-references__text" itemprop="headline" id="ref-CR78">Bengio, Y., Simard, P. &amp; Frasconi, P. Learning long-term dependencies with gradient descent is difficult. <i>IEEE Trans. Neural Networks</i> <b>5</b>, 157–166 (1994).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ASTN%3A280%3ADC%252BD1c7gvFansQ%253D%253D" aria-label="View reference 78 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 78 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20long-term%20dependencies%20with%20gradient%20descent%20is%20difficult&amp;journal=IEEE%20Trans.%20Neural%20Networks&amp;volume=5&amp;pages=157-166&amp;publication_year=1994&amp;author=Bengio%2CY&amp;author=Simard%2CP&amp;author=Frasconi%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">79</span><p class="c-article-references__text" itemprop="headline" id="ref-CR79">Hochreiter, S. &amp; Schmidhuber, J. Long short-term memory. <i>Neural Comput.</i> <b>9</b>, 1735–1780 (1997). <b>This paper introduced LSTM recurrent networks, which have become a crucial ingredient in recent advances with recurrent networks because they are good at learning long-range dependencies.</b></p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ASTN%3A280%3ADyaK1c%252FhvVahsQ%253D%253D" aria-label="View reference 79 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9377276" aria-label="View reference 79 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 79 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Long%20short-term%20memory&amp;journal=Neural%20Comput.&amp;volume=9&amp;pages=1735-1780&amp;publication_year=1997&amp;author=Hochreiter%2CS&amp;author=Schmidhuber%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">80</span><p class="c-article-references__text" itemprop="headline" id="ref-CR80">ElHihi, S. &amp; Bengio, Y. Hierarchical recurrent neural networks for long-term dependencies. In <i>Proc. Advances in Neural Information Processing Systems 8</i> <a href="http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-long-term-dependencies">http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-long-term-dependencies</a> (1995).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 80 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%208&amp;publication_year=1995&amp;author=ElHihi%2CS&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">81</span><p class="c-article-references__text" itemprop="headline" id="ref-CR81">Sutskever, I. <i>Training Recurrent Neural Networks</i>. PhD thesis, Univ. Toronto (2012).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 81 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20Recurrent%20Neural%20Networks&amp;publication_year=2012&amp;author=Sutskever%2CI">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">82</span><p class="c-article-references__text" itemprop="headline" id="ref-CR82">Pascanu, R., Mikolov, T. &amp; Bengio, Y. On the difficulty of training recurrent neural networks. In <i>Proc. 30th International Conference on Machine Learning</i> 1310–1318 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 82 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2030th%20International%20Conference%20on%20Machine%20Learning&amp;pages=1310-1318&amp;publication_year=2013&amp;author=Pascanu%2CR&amp;author=Mikolov%2CT&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">83</span><p class="c-article-references__text" itemprop="headline" id="ref-CR83">Sutskever, I., Martens, J. &amp; Hinton, G. E. Generating text with recurrent neural networks. In <i>Proc. 28th International Conference on Machine Learning</i> 1017–1024 (2011).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 83 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2028th%20International%20Conference%20on%20Machine%20Learning&amp;pages=1017-1024&amp;publication_year=2011&amp;author=Sutskever%2CI&amp;author=Martens%2CJ&amp;author=Hinton%2CGE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">84</span><p class="c-article-references__text" itemprop="headline" id="ref-CR84">Lakoff, G. &amp; Johnson, M. <i>Metaphors We Live By</i> (Univ. Chicago Press, 2008).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 84 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Metaphors%20We%20Live%20By&amp;publication_year=2008&amp;author=Lakoff%2CG&amp;author=Johnson%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">85</span><p class="c-article-references__text" itemprop="headline" id="ref-CR85">Rogers, T. T. &amp; McClelland, J. L. <i>Semantic Cognition: A Parallel Distributed Processing Approach</i> (MIT Press, 2004).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 85 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semantic%20Cognition%3A%20A%20Parallel%20Distributed%20Processing%20Approach&amp;publication_year=2004&amp;author=Rogers%2CTT&amp;author=McClelland%2CJL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">86</span><p class="c-article-references__text" itemprop="headline" id="ref-CR86">Xu, K. et al. Show, attend and tell: Neural image caption generation with visual attention. In <i>Proc. International Conference on Learning Representations</i> <a href="http://arxiv.org/abs/1502.03044">http://arxiv.org/abs/1502.03044</a> (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 86 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Learning%20Representations&amp;publication_year=2015&amp;author=Xu%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">87</span><p class="c-article-references__text" itemprop="headline" id="ref-CR87">Graves, A., Mohamed, A.-R. &amp; Hinton, G. Speech recognition with deep recurrent neural networks. In <i>Proc. International Conference on Acoustics, Speech and Signal Processing</i> 6645–6649 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 87 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Acoustics%2C%20Speech%20and%20Signal%20Processing&amp;pages=6645-6649&amp;publication_year=2013&amp;author=Graves%2CA&amp;author=Mohamed%2CA-R&amp;author=Hinton%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">88</span><p class="c-article-references__text" itemprop="headline" id="ref-CR88">Graves, A., Wayne, G. &amp; Danihelka, I. Neural Turing machines. <a href="http://arxiv.org/abs/1410.5401">http://arxiv.org/abs/1410.5401</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">89</span><p class="c-article-references__text" itemprop="headline" id="ref-CR89">Weston, J. Chopra, S. &amp; Bordes, A. Memory networks. <a href="http://arxiv.org/abs/1410.3916">http://arxiv.org/abs/1410.3916</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">90</span><p class="c-article-references__text" itemprop="headline" id="ref-CR90">Weston, J., Bordes, A., Chopra, S. &amp; Mikolov, T. Towards AI-complete question answering: a set of prerequisite toy tasks. <a href="http://arxiv.org/abs/1502.05698">http://arxiv.org/abs/1502.05698</a> (2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">91</span><p class="c-article-references__text" itemprop="headline" id="ref-CR91">Hinton, G. E., Dayan, P., Frey, B. J. &amp; Neal, R. M. The wake-sleep algorithm for unsupervised neural networks. <i>Science</i> <b>268</b>, 1558–1161 (1995).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 91 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20wake-sleep%20algorithm%20for%20unsupervised%20neural%20networks&amp;journal=Science&amp;volume=268&amp;pages=1558-1161&amp;publication_year=1995&amp;author=Hinton%2CGE&amp;author=Dayan%2CP&amp;author=Frey%2CBJ&amp;author=Neal%2CRM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">92</span><p class="c-article-references__text" itemprop="headline" id="ref-CR92">Salakhutdinov, R. &amp; Hinton, G. Deep Boltzmann machines. In <i>Proc. International Conference on Artificial Intelligence and Statistics</i> 448–455 (2009).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 92 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics&amp;pages=448-455&amp;publication_year=2009&amp;author=Salakhutdinov%2CR&amp;author=Hinton%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">93</span><p class="c-article-references__text" itemprop="headline" id="ref-CR93">Vincent, P., Larochelle, H., Bengio, Y. &amp; Manzagol, P.-A. Extracting and composing robust features with denoising autoencoders. In <i>Proc. 25th International Conference on Machine Learning</i> 1096–1103 (2008).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 93 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2025th%20International%20Conference%20on%20Machine%20Learning&amp;pages=1096-1103&amp;publication_year=2008&amp;author=Vincent%2CP&amp;author=Larochelle%2CH&amp;author=Bengio%2CY&amp;author=Manzagol%2CP-A">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">94</span><p class="c-article-references__text" itemprop="headline" id="ref-CR94">Kavukcuoglu, K. et al. Learning convolutional feature hierarchies for visual recognition. In <i>Proc. Advances in Neural Information Processing Systems 23</i> 1090–1098 (2010).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 94 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2023&amp;pages=1090-1098&amp;publication_year=2010&amp;author=Kavukcuoglu%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">95</span><p class="c-article-references__text" itemprop="headline" id="ref-CR95">Gregor, K. &amp; LeCun, Y. Learning fast approximations of sparse coding. In <i>Proc. International Conference on Machine Learning</i> 399–406 (2010).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 95 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Machine%20Learning&amp;pages=399-406&amp;publication_year=2010&amp;author=Gregor%2CK&amp;author=LeCun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">96</span><p class="c-article-references__text" itemprop="headline" id="ref-CR96">Ranzato, M., Mnih, V., Susskind, J. M. &amp; Hinton, G. E. Modeling natural images using gated MRFs. <i>IEEE Trans. Pattern Anal. Machine Intell.</i> <b>35</b>, 2206–2222 (2013).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 96 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20natural%20images%20using%20gated%20MRFs&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Machine%20Intell.&amp;volume=35&amp;pages=2206-2222&amp;publication_year=2013&amp;author=Ranzato%2CM&amp;author=Mnih%2CV&amp;author=Susskind%2CJM&amp;author=Hinton%2CGE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">97</span><p class="c-article-references__text" itemprop="headline" id="ref-CR97">Bengio, Y., Thibodeau-Laufer, E., Alain, G. &amp; Yosinski, J. Deep generative stochastic networks trainable by backprop. In <i>Proc. 31st International Conference on Machine Learning</i> 226–234 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 97 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%2031st%20International%20Conference%20on%20Machine%20Learning&amp;pages=226-234&amp;publication_year=2014&amp;author=Bengio%2CY&amp;author=Thibodeau-Laufer%2CE&amp;author=Alain%2CG&amp;author=Yosinski%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">98</span><p class="c-article-references__text" itemprop="headline" id="ref-CR98">Kingma, D., Rezende, D., Mohamed, S. &amp; Welling, M. Semi-supervised learning with deep generative models. In <i>Proc. Advances in Neural Information Processing Systems 27</i> 3581–3589 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 98 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20Advances%20in%20Neural%20Information%20Processing%20Systems%2027&amp;pages=3581-3589&amp;publication_year=2014&amp;author=Kingma%2CD&amp;author=Rezende%2CD&amp;author=Mohamed%2CS&amp;author=Welling%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">99</span><p class="c-article-references__text" itemprop="headline" id="ref-CR99">Ba, J., Mnih, V. &amp; Kavukcuoglu, K. Multiple object recognition with visual attention. In <i>Proc. International Conference on Learning Representations</i> <a href="http://arxiv.org/abs/1412.7755">http://arxiv.org/abs/1412.7755</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 99 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Learning%20Representations&amp;publication_year=2014&amp;author=Ba%2CJ&amp;author=Mnih%2CV&amp;author=Kavukcuoglu%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">100</span><p class="c-article-references__text" itemprop="headline" id="ref-CR100">Mnih, V. et al. Human-level control through deep reinforcement learning. <i>Nature</i> <b>518</b>, 529–533 (2015).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.518..529M" aria-label="View reference 100 on ADS">ADS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BC2MXjsVagur0%253D" aria-label="View reference 100 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25719670" aria-label="View reference 100 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 100 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human-level%20control%20through%20deep%20reinforcement%20learning&amp;journal=Nature&amp;volume=518&amp;pages=529-533&amp;publication_year=2015&amp;author=Mnih%2CV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">101</span><p class="c-article-references__text" itemprop="headline" id="ref-CR101">Bottou, L. From machine learning to machine reasoning. <i>Mach. Learn.</i> <b>94</b>, 133–149 (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3149132" aria-label="View reference 101 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 101 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20machine%20learning%20to%20machine%20reasoning&amp;journal=Mach.%20Learn.&amp;volume=94&amp;pages=133-149&amp;publication_year=2014&amp;author=Bottou%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><span class="c-article-references__counter">102</span><p class="c-article-references__text" itemprop="headline" id="ref-CR102">Vinyals, O., Toshev, A., Bengio, S. &amp; Erhan, D. Show and tell: a neural image caption generator. In <i>Proc. International Conference on Machine Learning</i> <a href="http://arxiv.org/abs/1502.03044">http://arxiv.org/abs/1502.03044</a> (2014).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 102 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proc.%20International%20Conference%20on%20Machine%20Learning&amp;publication_year=2014&amp;author=Vinyals%2CO&amp;author=Toshev%2CA&amp;author=Bengio%2CS&amp;author=Erhan%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><span class="c-article-references__counter">103</span><p class="c-article-references__text" itemprop="headline" id="ref-CR103">van der Maaten, L. &amp; Hinton, G. E. Visualizing data using t-SNE. <i>J. Mach. Learn.Research</i> <b>9</b>, 2579–2605 (2008).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1225.68219" aria-label="View reference 103 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 103 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Visualizing%20data%20using%20t-SNE&amp;journal=J.%20Mach.%20Learn.Research&amp;volume=9&amp;pages=2579-2605&amp;publication_year=2008&amp;author=van%20der%20Maaten%2CL&amp;author=Hinton%2CGE">
                        Google Scholar</a></li></ul></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-category="article body" data-track-label="link" href="/articles/nature14539-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to thank the Natural Sciences and Engineering Research Council of Canada, the Canadian Institute For Advanced Research (CIFAR), the National Science Foundation and Office of Naval Research for support. Y.L. and Y.B. are CIFAR fellows.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article-author-information__subtitle u-h3" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><h4 class="c-article-author-affiliation__address u-h3">Facebook AI Research, 770 Broadway, New York, 10003, New York, USA</h4><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Yann LeCun</li></ul></li><li id="Aff2"><h4 class="c-article-author-affiliation__address u-h3">New York University, 715 Broadway, New York, 10003, New York, USA</h4><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Yann LeCun</li></ul></li><li id="Aff3"><h4 class="c-article-author-affiliation__address u-h3">Department of Computer Science and Operations Research Université de Montréal, Pavillon André-Aisenstadt, PO Box 6128 Centre-Ville STN, Montréal, H3C 3J7, Quebec, Canada</h4><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Yoshua Bengio</li></ul></li><li id="Aff4"><h4 class="c-article-author-affiliation__address u-h3">Google, 1600 Amphitheatre Parkway, Mountain View, 94043, California, USA</h4><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Geoffrey Hinton</li></ul></li><li id="Aff5"><h4 class="c-article-author-affiliation__address u-h3">Department of Computer Science, University of Toronto, 6 King's College Road, Toronto, M5S 3G4, Ontario, Canada</h4><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Geoffrey Hinton</li></ul></li></ol><div class="js-hide u-hide-print" data-test="author-info"><h3 class="c-article-author-information__subtitle u-h3">Authors</h3><ol class="c-article-author-authors-search"><li id="auth-1"><h3 class="c-article-author-authors-search__title u-h3 js-search-name">Search for Yann LeCun in:</h3><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yann+LeCun">PubMed</a><span class="bullet"> • </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yann+LeCun%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li><li id="auth-2"><h3 class="c-article-author-authors-search__title u-h3 js-search-name">Search for Yoshua Bengio in:</h3><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yoshua+Bengio">PubMed</a><span class="bullet"> • </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yoshua+Bengio%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li><li id="auth-3"><h3 class="c-article-author-authors-search__title u-h3 js-search-name">Search for Geoffrey Hinton in:</h3><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Geoffrey+Hinton">PubMed</a><span class="bullet"> • </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Geoffrey+Hinton%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li></ol></div><h3 class="c-article-author-information__subtitle u-h3" id="corresponding-author">Corresponding author</h3><p>Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/articles/nature14539/email/correspondent/c1/new">Yann LeCun</a>.</p></div></div></section><section aria-labelledby="ethics"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading u-h3">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>Reprints and permissions information is available at <a href="http://www.nature.com/reprints">www.nature.com/reprints</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-category="article body" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?imprint=Nature&amp;title=Deep%20learning&amp;author=Yann%20LeCun%20et%20al&amp;contentID=10.1038%2Fnature14539&amp;publication=Nature&amp;publicationDate=2015-05-27&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/nature14539" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/nature14539" data-track="click" data-track-action="Click Crossmark" data-track-category="article body" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning.
                    <i>Nature</i> <b>521, </b>436–444 (2015)  doi:10.1038/nature14539</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-category="article body" data-track-label="link" href="/articles/nature14539.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><h4 class="u-h4">Received</h4><p class="c-bibliographic-information__value"><time datetime="2015-02-25">25 February 2015</time></p></li><li class="c-bibliographic-information__list-item"><h4 class="u-h4">Accepted</h4><p class="c-bibliographic-information__value"><time datetime="2015-05-01">01 May 2015</time></p></li><li class="c-bibliographic-information__list-item"><h4 class="u-h4">Published</h4><p class="c-bibliographic-information__value"><time datetime="2015-05-27">27 May 2015</time></p></li><li class="c-bibliographic-information__list-item"><h4 class="u-h4">Issue Date</h4><p class="c-bibliographic-information__value"><time datetime="2015-05-28">28 May 2015</time></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><h4 class="u-h4"><abbr title="Digital Object Identifier">DOI</abbr></h4><p class="c-bibliographic-information__value"><a href="https://doi.org/10.1038/nature14539" data-track="click" data-track-action="view doi" data-track-category="article body" data-track-label="link" itemprop="sameAs">https://doi.org/10.1038/nature14539</a></p></li></ul><div data-component="share-box"></div><div data-component="article-info-list"></div></div></div></div></div></section>

                        
    <section aria-labelledby="further-reading">
      <div class="c-article-section js-article-section" id="further-reading-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">Further reading</h2>
        <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
        <ul class="c-article-further-reading__list" id="further-reading-list">
          
            <li class="c-article-further-reading__item js-ref-item" id="further-reading-item-1">
              <h3 class="c-article-further-reading__title">
                <a class="print-link"
                   data-track="click"
                   data-track-action="view further reading article"
                   data-track-category="article body"
                   data-track-label="link:Artificial intelligence, machine learning and deep learning: definitions and differences"
                   href="https://doi.org/10.1111/ced.14029"
                   id="title-link-1">
                  Artificial intelligence, machine learning and deep learning: definitions and differences
                </a>
              </h3>
              
                <ul data-test="author-list"
                    class="c-article-further-reading__authors-list js-list-authors-3 js-etal-collapsed"
                    id="authors-1">
                  <li><span
                        class="js-separator"></span><span>D. Jakhar</span></li><li><span
                        class="js-separator">&nbsp;&amp;&nbsp;</span><span>I. Kaur</span></li></ul>
              
              <p class="c-article-further-reading__journal-title" id="journal-name-1">
                <i>Clinical and Experimental Dermatology</i>
                (2020)
              </p>
            </li>
          
            <li class="c-article-further-reading__item js-ref-item" id="further-reading-item-2">
              <h3 class="c-article-further-reading__title">
                <a class="print-link"
                   data-track="click"
                   data-track-action="view further reading article"
                   data-track-category="article body"
                   data-track-label="link:Physics-Driven Regularization of Deep Neural Networks for Enhanced Engineering Design and Analysis"
                   href="https://doi.org/10.1115/1.4044507"
                   id="title-link-2">
                  Physics-Driven Regularization of Deep Neural Networks for Enhanced Engineering Design and Analysis
                </a>
              </h3>
              
                <ul data-test="author-list"
                    class="c-article-further-reading__authors-list js-list-authors-3 js-etal-collapsed"
                    id="authors-2">
                  <li><span
                        class="js-separator"></span><span>Mohammad Amin Nabian</span></li><li><span
                        class="js-separator">&nbsp;&amp;&nbsp;</span><span>Hadi Meidani</span></li></ul>
              
              <p class="c-article-further-reading__journal-title" id="journal-name-2">
                <i>Journal of Computing and Information Science in Engineering</i>
                (2020)
              </p>
            </li>
          
            <li class="c-article-further-reading__item js-ref-item" id="further-reading-item-3">
              <h3 class="c-article-further-reading__title">
                <a class="print-link"
                   data-track="click"
                   data-track-action="view further reading article"
                   data-track-category="article body"
                   data-track-label="link:Knowledge-Assisted Optimization for Large-Scale Design Problems: A Review and Proposition"
                   href="https://doi.org/10.1115/1.4044525"
                   id="title-link-3">
                  Knowledge-Assisted Optimization for Large-Scale Design Problems: A Review and Proposition
                </a>
              </h3>
              
                <ul data-test="author-list"
                    class="c-article-further-reading__authors-list js-list-authors-3 js-etal-collapsed"
                    id="authors-3">
                  <li><span
                        class="js-separator"></span><span>Di Wu</span></li><li><span
                        class="js-separator">&nbsp;&amp;&nbsp;</span><span>G. Gary Wang</span></li></ul>
              
              <p class="c-article-further-reading__journal-title" id="journal-name-3">
                <i>Journal of Mechanical Design</i>
                (2020)
              </p>
            </li>
          
            <li class="c-article-further-reading__item js-ref-item" id="further-reading-item-4">
              <h3 class="c-article-further-reading__title">
                <a class="print-link"
                   data-track="click"
                   data-track-action="view further reading article"
                   data-track-category="article body"
                   data-track-label="link:Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks"
                   href="https://doi.org/10.1115/1.4044097"
                   id="title-link-4">
                  Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks
                </a>
              </h3>
              
                <ul data-test="author-list"
                    class="c-article-further-reading__authors-list js-list-authors-3 js-etal-collapsed"
                    id="authors-4">
                  <li><span
                        class="js-separator"></span><span>Zhenguo Nie</span></li><li><span
                        class="js-separator">, </span><span>Haoliang Jiang</span></li><li><span
                        class="js-separator">&nbsp;&amp;&nbsp;</span><span>Levent Burak Kara</span></li></ul>
              
              <p class="c-article-further-reading__journal-title" id="journal-name-4">
                <i>Journal of Computing and Information Science in Engineering</i>
                (2020)
              </p>
            </li>
          
            <li class="c-article-further-reading__item js-ref-item" id="further-reading-item-5">
              <h3 class="c-article-further-reading__title">
                <a class="print-link"
                   data-track="click"
                   data-track-action="view further reading article"
                   data-track-category="article body"
                   data-track-label="link:Binarized Coherent Optical Receiver Based on Opto-Electronic Neural Network"
                   href="https://doi.org/10.1109/JSTQE.2019.2931251"
                   id="title-link-5">
                  Binarized Coherent Optical Receiver Based on Opto-Electronic Neural Network
                </a>
              </h3>
              
                <ul data-test="author-list"
                    class="c-article-further-reading__authors-list js-list-authors-3 js-etal-collapsed"
                    id="authors-5">
                  <li><span
                        class="js-separator"></span><span>Zhenming Yu</span></li><li><span
                        class="js-separator">, </span><span>Xu Zhao</span></li><li><span
                        class="js-separator">, </span><span>Sigang Yang</span></li><li><span
                        class="js-separator">, </span><span>Hongwei Chen</span></li><li><span
                        class="js-separator">&nbsp;&amp;&nbsp;</span><span>Minghua Chen</span></li></ul>
              
              <p class="c-article-further-reading__journal-title" id="journal-name-5">
                <i>IEEE Journal of Selected Topics in Quantum Electronics</i>
                (2020)
              </p>
            </li>
          
        </ul>
      </div>
    </div>
    </section>
  

                        
                            <section aria-labelledby="article-comments"><div class="c-article-section" id="article-comments-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="article-comments">Comments</h2><div class="c-article-section__content" id="article-comments-content"><p>By submitting a comment you agree to abide by our <a href="/info/tandc.html">Terms</a> and <a href="/info/community-guidelines.html">Community Guidelines</a>. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.</p></div></div></section>
                            <div id="inject-comments">
                                <div class="placeholder" data-replace="true"
                                     data-placeholder="/platform/disqus?doi=10.1038/nature14539 #article-comments-container">
                            </div>
                        </div>
                        

                        <span data-recommended="jobs"></span>
                    </div>
            </div>

            <div class="c-article-extras u-hide-print" role="complementary" data-container-type="reading-companion" data-track-component="reading companion">
                
                    <noscript>
                        
                            
<div class="c-card c-card--side " data-component="entitlement-box">
    
        <div class="js-access-button">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button" data-test="ra21" data-track="click" data-track-action="institution access" data-track-label="button" data-track-category="article body">
                <svg class="u-icon" width="18" height="18"><use href="#global-icon-institution"></use></svg>
                <span class="c-article__button-text">Access through your institution</span>
            </a>
        </div>
         <div class="js-buy-button">
            <a href="#access-options" class="c-article__button c-article__button--inverted" data-test="ra21" data-track="click" data-track-action="buy or subscribe" data-track-label="button" data-track-category="article body">
                <span>Buy or subscribe</span>
            </a>
        </div>
    
</div>

                        
                    </noscript>
                    
                        <div class="c-card c-card--side u-display-none" aria-hidden="true" data-component="entitlement-box" id=entitlement-box-desktop>
    
        <p class="js-text u-display-none" aria-hidden="true"></p>
        <div class="js-access-button u-display-none">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="institution access" data-track-label="button" data-track-category="article body">
                <svg class="u-icon" width="18" height="18"><use xlink:href="#global-icon-institution"></use></svg> 
                <span class="c-article__button-text">Access through your institution</span>
            </a>
        </div>
        <div class="js-change-institution-button u-display-none">
            <a href="https://wayf.springernature.com?redirect_uri&#x3D;http%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14539" class="c-article__button c-article__button--inverted" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="change institution" data-track-label="button" data-track-category="article body">
                <span class="c-article__button-text">Change institution</span>
            </a>
        </div>
        <div class="js-buy-button u-display-none">
            <a href="#access-options" class="c-article__button c-article__button--inverted" aria-hidden="true" data-test="ra21" data-track="click" data-track-action="buy or subscribe" data-track-label="button" data-track-category="article body">
                <span>Buy or subscribe</span>
            </a>
        </div>
    
</div>

                    
                

                
                    
                

                
        
            <aside>
                <div class="c-article-associated-content__container">
                    <h1 class="c-article-associated-content__title u-h3">Associated Content</h1>
                    
                        <div class="c-article-associated-content__collection collection">
                            <section>
                                <p class="c-article-associated-content__collection-label">Collection</p>
                                <h3 class="c-article-associated-content__collection-title u-h3" itemprop="name headline"><a
                                        href="/collections/csgqqsrfxh"
                                        data-track="click"
                                        data-track-action="view collection"
                                        data-track-label="link">
                                     The multidisciplinary nature of machine intelligence
                                </a></h3>
                            </section>
                        </div>
                    
                        <div class="c-article-associated-content__collection special">
                            <section>
                                <p class="c-article-associated-content__collection-label">Special</p>
                                <h3 class="c-article-associated-content__collection-title u-h3" itemprop="name headline"><a
                                        href="/collections/hqwpvkfhrr"
                                        data-track="click"
                                        data-track-action="view special"
                                        data-track-label="link">
                                    The Go Files
                                </a></h3>
                            </section>
                        </div>
                    
                    
                    
                </div>
            </aside>
        
    

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-gpt-unitpath="/285/nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nature14539;doi=10.1038/nature14539;subjmeta=117,639,705;kwrd=Computer science,Mathematics and computing">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=300x250&amp;c=775466315&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature14539%26doi%3D10.1038/nature14539%26subjmeta%3D117,639,705%26kwrd%3DComputer science,Mathematics and computing">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=300x250&amp;c=775466315&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature14539%26doi%3D10.1038/nature14539%26subjmeta%3D117,639,705%26kwrd%3DComputer science,Mathematics and computing"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </div>
        </article>
    </div>
</div>
</div>


<div class="hide-print js-header-menu menu mb20 z-index-50 composite-layer background-white border-bottom-2 border-gray-medium tighten-line-height" id="menu" data-track-component="menu">
    <div class="menu-inner content js-hide">
        <nav>
            <div class="cleared border-bottom-1 border-gray-medium ml20 mr20">
                <div class="grid-ng grid-1of4 mq875-grid-12">
                    <h3 class="h3 pa20 mq875-pa0 mq875-mt20">
                        Nature<span class="visually-hidden"> menu</span>
                    </h3>
                </div>
                
    
        
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <ul class="clean-list mb0">
                
                <li class="mb4 pr10"><a href="/nature/research" data-track="click" data-track-action="research" data-track-label="link">Research</a></li>
                
                <li class="mb4 pr10"><a href="/news" data-track="click" data-track-action="news" data-track-label="link">News</a></li>
                
                <li class="mb4 pr10"><a href="/opinion" data-track="click" data-track-action="opinion" data-track-label="link">Opinion</a></li>
                
                <li class="mb4 pr10"><a href="/research-analysis" data-track="click" data-track-action="research analysis" data-track-label="link">Research Analysis</a></li>
                
                <li class="mb4 pr10"><a href="/careers" data-track="click" data-track-action="careers" data-track-label="link">Careers</a></li>
                
                <li class="mb4 pr10"><a href="/books-culture" data-track="click" data-track-action="books and culture" data-track-label="link">Books and Culture</a></li>
                
                <li class="mb4 pr10"><a href="/nature/podcast" data-track="click" data-track-action="podcasts" data-track-label="link">Podcasts</a></li>
                
                <li class="mb4 pr10"><a href="/nature/videoarchive" data-track="click" data-track-action="videos" data-track-label="link">Videos</a></li>
                
            </ul>
        </div>
        

        
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <ul class="clean-list mb0">
                
                <li class="mb4 pr10"><a href="/nature/current-issue" data-track="click" data-track-action="current issue" data-track-label="link">Current Issue</a></li>
                
                <li class="mb4 pr10"><a href="/nature/browse-issues" data-track="click" data-track-action="browse issues" data-track-label="link">Browse Issues</a></li>
                
                <li class="mb4 pr10"><a href="/nature/articles" data-track="click" data-track-action="browse articles" data-track-label="link">Browse Articles</a></li>
                
                <li class="mb4 pr10"><a href="/nature/collections" data-track="click" data-track-action="browse collections" data-track-label="link">Browse Collections</a></li>
                
                <li class="mb4 pr10"><a href="/nature/browse-subjects" data-track="click" data-track-action="browse subjects" data-track-label="link">Browse Subjects</a></li>
                
            </ul>
        </div>
        

        
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <ul class="clean-list mb0">
                
                <li class="mb4 pr10"><a href="/nature/about" data-track="click" data-track-action="about the journal" data-track-label="link">About the Journal</a></li>
                
                <li class="mb4 pr10"><a href="/nature/for-authors" data-track="click" data-track-action="for authors" data-track-label="link">For Authors</a></li>
                
                <li class="mb4 pr10"><a href="/nature/for-referees" data-track="click" data-track-action="for referees" data-track-label="link">For Referees</a></li>
                
                <li class="mb4 pr10"><a href="/nature/awards" data-track="click" data-track-action="awards" data-track-label="link">Awards</a></li>
                
                <li class="mb4 pr10"><a href="/nature/subscribe" data-track="click" data-track-action="subscribe" data-track-label="link">Subscribe</a></li>
                
                <li class="mb4 pr10"><a href="/nature/e-alert" data-track="click" data-track-action="e-alert" data-track-label="link">E-alert</a></li>
                
                <li class="mb4 pr10"><a href="/nature/submit-online" data-track="click" data-track-action="submit" data-track-label="link">Submit</a></li>
                
            </ul>
        </div>
        
    

            </div>
            <div class="cleared ml20 mr20">
                
    <div class="cleared pb10">
        <div class="grid-ng grid-1of4 mq875-grid-12">
            <h3 class="serif pa20 mq875-pa0 mq875-mt20">Nature Research<span class="visually-hidden"> menu</span></h3>
        </div>
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <h4 class="mb4">Our Journals</h4>
            <ul class="clean-list mb0">
                <li class="mb4 pr10"><a href="/nature" data-track="click" data-track-action="nature" data-track-label="link">Nature</a></li>
                <li class="mb4 pr10"><a href="/ncomms" data-track="click" data-track-action="nature communications" data-track-label="link">Nature Communications</a></li>
                <li class="mb4 pr10"><a href="/nprot" data-track="click" data-track-action="nature protocols" data-track-label="link">Nature Protocols</a></li>
                <li class="mb4 pr10"><a href="/srep" data-track="click" data-track-action="scientific reports" data-track-label="link">Scientific Reports</a></li>
                <li class="mb4 pr10"><a href="/siteindex" data-track="click" data-track-action="journal a-z view all" data-track-label="link">View all journals</a></li>
            </ul>
        </div>
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <h4 class="mb4">Subjects</h4>
            <ul class="clean-list mb0">
                <li class="mb4 pr10"><a href="/subjects/biological-sciences" data-track="click" data-track-action="biological sciences" data-track-label="link">Biological Sciences</a></li>
                <li class="mb4 pr10"><a href="/subjects/scientific-community-and-society" data-track="click" data-track-action="scientific community and society" data-track-label="link">Scientific Community &amp; Society</a></li>
                <li class="mb4 pr10"><a href="/subjects/earth-and-environmental-sciences" data-track="click" data-track-action="earth and environmental sciences" data-track-label="link">Earth &amp; Environmental Sciences</a></li>
                <li class="mb4 pr10"><a href="/subjects/health-sciences" data-track="click" data-track-action="health sciences" data-track-label="link">Health Sciences</a></li>
                <li class="mb4 pr10"><a href="/subjects/physical-sciences" data-track="click" data-track-action="physical sciences" data-track-label="link">Physical Sciences</a></li>
                <li class="mb4 pr10"><a href="/subjects" data-track="click" data-track-action="subjects view all" data-track-label="link">View all subjects</a></li>
            </ul>
        </div>
        <div class="grid-ng grid-1of4 text14 pa20 mq875-grid-4 mq640-grid-12">
            <h4 class="mb4">More</h4>
            <ul class="clean-list mb0">
                <li class="mb4 pr10"><a href="https://support.nature.com/support/home" data-track="click" data-track-action="subscriptions" data-track-label="link">Contact us</a></li>
                <li class="mb4 pr10"><a href="/authors/index.html" data-track="click" data-track-action="authors and referees" data-track-label="link">Authors &amp; Referees</a></li>
                <li class="mb4 pr10"><a href="/libraries/index.html" data-track="click" data-track-action="librarians" data-track-label="link">Librarians</a></li>
                <li class="mb4 pr10"><a href="/advertising/index.html" data-track="click" data-track-action="advertisers" data-track-label="link">Advertisers</a></li>
                <li class="mb4 pr10"><a href="/npg_/press_room/index.html" data-track="click" data-track-action="press" data-track-label="link">Press</a></li>
                <li class="mb4 pr10"><a href="/npg_/index_npg.html" data-track="click" data-track-action="about" data-track-label="link">About Nature Research</a></li>
            </ul>
        </div>
    </div>



            </div>
        </nav>
    </div>
</div>



    <div id="search-menu" class="menu pt20 mb20 z-index-50 composite-layer background-white border-gray-medium border-bottom-2" data-component="tray" data-track-component="header">
        <div class="menu-inner js-hide">
            <section>
                <h2 class="visually-hidden">Search</h2>
                <div class="hide-print content mb40 mq1200-padded position-relative" data-test="inline-search">
                    <div class="pt30 cleared background-white sans-serif">
                        <div class="grid grid-8 grid-left-2 mq875-grid-12 mq875-ml0 mq640-pb30">
                            <form action="/search" method="get" role="search" autocomplete="off" class="standard-space-below" data-track="submit" data-track-action="search" data-track-label="form">
                                <label for="keywords" class="block strong">Article search</label>
                                <div class="position-relative">
                                    <input type="search" id="keywords" class="border-gray border-all-1 equalize-line-height pa10 pr40 box-sizing grid-12" name="q" value="" placeholder="Search by keywords or author" data-test="search-keywords">
                                    <div class="position-absolute position-right position-top mt1 mr1">
                                        <button type="submit" class="icon icon-center search-btn kill-border" data-test="search-submit">
                                            Search
                                        </button>
                                    </div>
                                    <p class="mb0 mt4 text14"><a href="/search/advanced" data-track="click" data-track-action="advanced search" data-track-label="link">Advanced search</a></p>
                                </div>
                            </form>
                            <h3 class="h3 strong mb4 border-gray-medium border-bottom-1 sans-serif">Quick links</h3>
                            <ul class="clean-list mb0 text14">
                                <li class="grid-ng grid-1of2 mb6 mt6"><a href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
                                <li class="grid-ng grid-1of2 mb6 mt6"><a href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
                                <li class="grid-ng grid-1of2"><a href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
                                <li class="grid-ng grid-1of2"><a href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </section>
        </div>
    </div>




<footer role="contentinfo">
    
        
    <div class="content pl30 pr30 text14 text-gray-light">
        <p class="c-meta u-ma-0 u-mr-24">
            
        </p>
    </div>


    

    <div itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        
            <div class="container-footer mt40 cleared container-footer-full">
                
                    <div class="content pt20 pr30 pl30">
                        <div class="grid grid-12 last clear-float cleared mb15 text-gray-light text13 flex-box flex-wrap-reverse">
                            <h2 aria-level="2" class="text13 strong emphasis ma0 sans-serif" itemprop="name">Nature</h2>
                            <p class="pt0 pr10 pb0 pl10 ma0"><abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="issn">1476-4687</span> (online)</p>
                        </div>
                    </div>
                

                
    <div class="grid grid-12 pl30 pr30 last" id="footer">
        <h2 aria-level="2" class="hide">nature.com sitemap</h2>
    </div>

    <div class="pl30 pr30 content" data-track-component="footer">

        <div class="grid grid-12 last clear-float cleared mb5 pt20 text-gray-light flex-wrap">
            <div class="grid grid-3 mq875-grid-12 just-mq640-last just-mq875-last mb20"><img alt="Nature Research" src="/static/images/natureresearch-logo.2fe351a520.svg" loading="lazy" width="255" height="33"></div>
            <ul class="grid grid-7 mq875-grid-8 mq640-grid-12 just-mq640-last clean-list mb10 mt10 text15 u-hide-print">
                <li class="grid grid-3 mq875-grid-3 mq640-grid-6 mq480-grid-12"><a href="https://www.nature.com/npg_/company_info/index.html" data-track="click" data-track-action="about us" class="text-gray-light" data-track-label="link">About us</a></li>
                <li class="grid grid-3 mq875-grid-3 mq640-grid-6 mq480-grid-12 just-mq640-last just-mq480-last"><a href="https://www.nature.com/npg_/press_room/press_releases.html" data-track="click" data-track-action="press releases" data-track-label="link" class="text-gray-light">Press releases</a></li>
                <li class="grid grid-3 mq875-grid-3 mq640-grid-6 mq480-grid-12"><a href="https://press.nature.com/" data-track="click" data-track-action="press office" data-track-label="link" class="text-gray-light">Press office</a></li>
                <li class="grid grid-3 mq875-grid-3 mq640-grid-6 mq480-grid-12 last"><a href="https://support.nature.com/support/home" data-track="click" data-track-action="contact us" class="text-gray-light" data-track-label="link">Contact us</a></li>
            </ul>
            <ul class="grid grid-2 mq875-grid-4 mq640-grid-12 last clean-list mb10 mt4 u-hide-print">
                <li class="grid grid-4 mq875-grid-3"><a href="https://www.facebook.com/nature/" data-track="click" data-track-action="facebook" data-track-label="link" class="text-gray-light"><img src="/static/images/fb.49ba391f15.svg" class="cleared text-footer-img" alt="Facebook"/></a></li>
                <li class="grid grid-4 mq875-grid-3"><a href="https://twitter.com/nresearchnews?lang=en" data-track="click" data-track-action="twitter" data-track-label="link" class="text-gray-light"><img src="/static/images/twitter.a90dbeb03a.svg" class="cleared text-footer-img" alt="Twitter"/></a></li>
                <li class="grid grid-4 mq875-grid-3 last"><a href="https://www.youtube.com/channel/UCvCLdSgYdSTpWcOgEJgi-ng" data-track="click" data-track-action="youtube" data-track-label="link" class="text-gray-light"><img src="/static/images/youtube.6071f6012c.svg" class="cleared text-footer-img" alt="Youtube"/></a></li>
            </ul>
        </div>

        <div class="cleared z-index-1 pt30 pb20 border-top-1 border-gray text-footer-mobile-bottom hide-print u-hide-print">
            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12">
                <h3 class="text-footer-heading">Discover content</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://www.nature.com/siteindex/" data-track="click" data-track-action="journals a-z" data-track-label="link" class="text-gray-light">Journals A-Z</a></li>
                    <li class="pb4"><a href="https://www.nature.com/subjects/" data-track="click" data-track-action="article by subject" data-track-label="link" class="text-gray-light">Articles by subject</a></li>
                    <li class="pb4"><a href="https://nano.nature.com/" data-track="click" data-track-action="nano" data-track-label="link" class="text-gray-light">Nano</a></li>
                    <li class="pb4"><a href="https://www.nature.com/protocolexchange/" data-track="click" data-track-action="protocol exchange" data-track-label="link" class="text-gray-light">Protocol Exchange</a></li>
                    <li class="pb4"><a href="https://www.natureindex.com/" data-track="click" data-track-action="nature index" data-track-label="link" class="text-gray-light">Nature Index</a></li>
                </ul>
            </div>

            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12 just-mq640-last">
                <h3 class="text-footer-heading">Publish with us</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://www.nature.com/authors/author_resources/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link" class="text-gray-light" >Guide to Authors</a></li>
                    <li class="pb4"><a href="https://www.nature.com/authors/peer_review/" data-track="click" data-track-action="guide to referees" data-track-label="link" class="text-gray-light">Guide to Referees</a></li>
                    <li class="pb4"><a href="https://www.nature.com/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link" class="text-gray-light">Editorial policies</a></li>
                    <li class="pb4"><a href="http://www.nature.com/openresearch/publishing-with-npg/" data-track="click" data-track-action="open access" data-track-label="link" class="text-gray-light">Open access</a></li>
                    <li class="pb4" ><a href="https://www.nature.com/reprints/" data-track="click" data-track-action="reprints and permissions" data-track-label="link" class="text-gray-light">Reprints &amp; permissions</a></li>
                </ul>
            </div>

            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12 just-mq875-last">
                <h3 class="text-footer-heading">Researcher services</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://www.springernature.com/gp/authors/research-data" data-track="click" data-track-action="data research service" data-track-label="link" class="text-gray-light">Research data</a></li>
                    <li class="pb4"><a href="https://authorservices.springernature.com/go/nr" data-track="click" data-track-action="language editing" data-track-label="link" class="text-gray-light">Language editing</a></li>
                    <li class="pb4"><a href="https://authorservices.springernature.com/scientific-editing/" data-track="click" data-track-action="scientific editing" data-track-label="link" class="text-gray-light">Scientific editing</a></li>
                    <li class="pb4"><a href="https://masterclasses.nature.com/" data-track="click" data-track-action="nature masterclasses" data-track-label="link" class="text-gray-light">Nature Masterclasses</a></li>
                    <li class="pb4"><a href="https://partnerships.nature.com/product/researcher-training/" data-track="click" data-track-action="nature research academies" data-track-label="link" class="text-gray-light">Nature Research Academies</a></li>
                </ul>
            </div>

            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12 just-mq875-clear just-mq640-last full-size-last just-mq1200-last just-mq875-last just-mq480-last">
                <h3 class="text-footer-heading">Libraries &amp; institutions</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://www.springernature.com/gp/librarians/tools-services" data-track="click" data-track-action="librarian service and tools" data-track-label="link" class="text-gray-light">Librarian service &amp; tools</a></li>
                    <li class="pb4"><a href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal" data-track="click" data-track-action="librarian portal" data-track-label="link" class="text-gray-light">Librarian portal</a></li>
                    <li class="pb4"><a href="http://www.nature.com/openresearch/about-open-access/information-for-institutions/" data-track="click" data-track-action="open research" data-track-label="link" class="text-gray-light">Open research</a></li>
                </ul>
            </div>
        </div>

        <div class="cleared z-index-1 pt30 pb20 border-top-1 border-gray text-footer-mobile-top hide-print u-hide-print">
            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12">
                <h3 class="text-footer-heading">Advertising &amp; partnerships</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://partnerships.nature.com/product/digital-advertising/" data-track="click" data-track-action="advertising" data-track-label="link" class="text-gray-light">Advertising</a></li>
                    <li class="pb4"><a href="https://partnerships.nature.com/" data-track="click" data-track-action="partnerships and services" data-track-label="link" class="text-gray-light">Partnerships &amp; Services</a></li>
                    <li class="pb4"><a href="https://partnerships.nature.com/media-kits/" data-track="click" data-track-action="media kits" data-track-label="link" class="text-gray-light">Media kits</a></li>
                    <li class="pb4"><a href="https://partnerships.nature.com/product/branded-content-native-advertising/" data-track-action="branded content" data-track-label="link" class="text-gray-light">Branded content</a></li>
                </ul>
            </div>

            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12 just-mq640-last just-mq875-last">
                <h3 class="text-footer-heading">Career development</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="https://www.nature.com/naturecareers" data-track="click" data-track-action="nature careers" data-track-label="link" class="text-gray-light">Nature Careers</a></li>
                    <li class="pb4"><a href="https://www.nature.com/natureconferences/" data-track="click" data-track-action="nature conferences" data-track-label="link" class="text-gray-light">Nature<span class="visually-hidden"> </span> Conferences</a></li>
                    <li class="pb4"><a href="https://www.nature.com/natureevents/" data-track="click" data-track-action="nature events" data-track-label="link" class="text-gray-light">Nature<span class="visually-hidden"> </span> events</a></li>
                </ul>
            </div>

            <div class="grid grid-3 mq875-grid-4 mq640-grid-6 mq480-grid-12">
                <h3 class="text-footer-heading">Regional websites</h3>
                <ul class="clean-list ma0 mb6 text15">
                    <li class="pb4"><a href="http://www.naturechina.com" data-track="click" data-track-action="nature china" data-track-label="link" class="text-gray-light">Nature China</a></li>
                    <li class="pb4"><a href="https://www.nature.com/nindia" data-track="click" data-track-action="nature india" data-track-label="link" class="text-gray-light">Nature India</a></li>
                    <li class="pb4"><a href="https://www.natureasia.com/ja-jp/" data-track="click" data-track-action="nature japan" data-track-label="link" class="text-gray-light">Nature Japan</a></li>
                    <li class="pb4"><a href="https://www.natureasia.com/ko-kr/" data-track="click" data-track-action="nature korea" data-track-label="link" class="text-gray-light">Nature Korea</a></li>
                    <li class="pb4"><a href="https://www.nature.com/nmiddleeast/" data-track="click" data-track-action="nature middle east" data-track-label="link" class="text-gray-light">Nature Middle East</a></li>
                </ul>
            </div>
        </div>
    </div>


            </div>
        
    </div>

    
    <div class="container-footer-box cleared text14 border-gray-medium border-top-1">
        <div class="content">
            <img src="/static/images/sn-logo.4368f3b177.svg" alt="Springer Nature" loading="lazy" width="140" height="14" class="cleared"/>
            <p class="mb10 text-gray-light">© 2019 Springer Nature Limited</p>
            <ul class="ma0 clean-list grid grid-12 hide-print u-hide-print">
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 just-mq480-last"><a href="https://www.nature.com/info/privacy.html" data-track="click" data-track-action="privacy policy" data-track-label="link" class="text-gray-light">Privacy Policy</a></li>
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 just-mq640-last just-mq480-last"><a href="https://www.nature.com/info/cookies.html" data-track="click" data-track-action="use of cookies" data-track-label="link" class="text-gray-light">Use of cookies</a></li>
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 just-mq875-last just-mq480-last"><a href="javascript:;" class="optanon-toggle-display text-gray-light" data-track="click" data-track-action="manage cookies" data-track-label="link">Manage cookies</a></li>
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 just-mq640-last just-mq480-last"><a href="https://www.nature.com/info/legal_notice.html" data-track="click" data-track-action="legal notice" data-track-label="link" class="text-gray-light">Legal notice</a></li>
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 just-mq480-last"><a href="https://www.nature.com/info/accessibility_statement.html" data-track="click" data-track-action="accessibility statement" data-track-label="link" class="text-gray-light">Accessibility statement</a></li>
                <li class="grid grid-2 mq875-grid-4 mq640-grid-6 mq480-grid-12 mb10 last"><a href="https://www.nature.com/info/tandc.html" data-track="click" data-track-action="terms and conditions" data-track-label="link" class="text-gray-light">Terms &amp; Conditions</a></li>
            </ul>
        </div>
    </div>



    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
    </svg>

</footer>




    
        
            <div class="c-site-messages message hide c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant serif"
    data-component-id="nature-briefing-banner"
    data-component-expirydays="30"
    data-component-trigger-scroll-percentage="15"
    data-track="in-view"
    data-track-action="in-view"
    data-track-category="nature briefing"
    data-track-label="banner visible">

    <div class="content mq1200-padded">

        
        <div class="c-site-messages__banner-large">

            <div class="c-site-messages__close-container">
                <button class="c-site-messages__close"
                    data-track="click"
                    data-track-category="nature briefing"
                    data-track-label="nature briefing banner dismiss">
                    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                    <?xml version="1.0" encoding="UTF-8"?>
                    <svg width="24px" height="24px" focusable="false" aria-hidden="true" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                        <title>Close banner</title>
                        <defs></defs>
                        <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                            <g id="Icon-/-close">
                                <g id="Close">
                                    <rect opacity="0" x="0" y="0" width="24" height="24"></rect>
                                    <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#006699"></path>
                                </g>
                            </g>
                        </g>
                    </svg>
                    <span class="visually-hidden">Close</span>
                </button>
            </div>

            <div class="c-site-messages__form-container">
                <form action="/briefing/signup/formfeedback" method="post" class="nature-briefing-banner__form box-sizing grid grid-12 last" data-location="banner" data-track="submit" data-track-action="transmit-form">
                    <div class="grid grid-6">
                        <div class="text13 grid grid-7">
                            <span class="block strong extra-tight-line-height sans-serif">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</span>
                        </div>

                        <div class="grid grid-5 last">
                            <label for="box-EmailAddressInput" class="visually-hidden">Enter your email address</label>
                            <input class="nature-briefing-banner__email-input border-gray border-all-1 equalize-line-height pa10 box-sizing text13" type="email" id="box-EmailAddressInput" name="email_field" value="" placeholder="Enter your email address" required="true" aria-required="true" data-track="click" data-track-category="briefing-banner-form-input" data-track-label="briefing-banner-form-input">
                        </div>
                    </div>

                    <div class="grid grid-6 last">
                        <div class="grid grid-9">
                            <div class="grid grid-12 last">
                                <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="1" required>
                                <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                            </div>
                        </div>

                        <div class="grid grid-3 last">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing" data-track="click" data-track-category="signup-form-button" data-track-action="transmit-form" data-track-label="briefing-banner-form-submit-button">Sign up</button>
                        </div>
                    </div>
                </form>
            </div>

        </div>

        
        <div class="c-site-messages__banner-small">

            <div class="c-site-messages__content text14">
                <span class="strong">Get the most important science stories of the day, free in your inbox.</span>
                <a class="nature-briefing__link text14 sans-serif"
                    data-track="click"
                    data-track-category="nature briefing"
                    data-track-label="nature briefing banner subscribe"
                    target="_blank" rel="noreferrer noopener"
                    href="https://www.nature.com/briefing/signup/">Sign up for Nature Briefing
                </a>
            </div>
            <div class="c-site-messages__close-container pin-right">
                <button class="c-site-messages__close"
                    data-track="click"
                    data-track-category="nature briefing"
                    data-track-label="nature briefing banner dismiss">
                    <span class="icon--inline inline-block"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
                        <?xml version="1.0" encoding="UTF-8"?>
                        <svg width="24px" height="24px" focusable="false" aria-hidden="true" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <title>Close banner</title>
                            <defs></defs>
                            <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="Icon-/-close">
                                    <g id="Close">
                                        <rect opacity="0" x="0" y="0" width="24" height="24"></rect>
                                        <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#006699"></path>
                                    </g>
                                </g>
                            </g>
                        </svg>
                    </span>
                    <span class="visually-hidden">Close</span>
                </button>
            </div>

        </div>

    </div>

</div>

        
    




 
    <script src="https://cdn.ravenjs.com/3.12.0/raven.min.js" crossorigin="anonymous"></script>
    <script>
        if (Raven) {
            Raven.config('https://46e8b5cbb6a34c8ab1888c41c7f86c61@sentry.dc.springernature.pe/388').install();
        }
    </script>


<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" border="0" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nature14539&amp;format=js&amp;last_modified=2015-05-28" async></script>
<img src="/platform/track/preview/nature14539" width="1" height="1" alt="" class="visually-hidden"/>

</body>
</html>
