abstract: 'The highest accuracy object detectors to date are based on a two-stage
  approach popularized by R-CNN, where a classifier is applied to a sparse set of
  candidate object locations. In contrast, one-stage detectors that are applied over
  a regular, dense sampling of possible object locations have the potential to be
  faster and simpler, but have trailed the accuracy of two-stage detectors thus far.
  In this paper, we investigate why this is the case. We discover that the extreme
  foreground-background class imbalance encountered during training of dense detectors
  is the central cause. We propose to address this class imbalance by reshaping the
  standard cross entropy loss such that it down-weights the loss assigned to well-classified
  examples. Our novel Focal Loss focuses training on a sparse set of hard examples
  and prevents the vast number of easy negatives from overwhelming the detector during
  training. To evaluate the effectiveness of our loss, we design and train a simple
  dense detector we call RetinaNet. Our results show that when trained with the focal
  loss, RetinaNet is able to match the speed of previous one-stage detectors while
  surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code
  is at: https://github.com/facebookresearch/Detectron.'
archiveprefix: arXiv
author: Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár,
  Piotr
author_list:
- family: Lin
  given: Tsung-Yi
- family: Goyal
  given: Priya
- family: Girshick
  given: Ross
- family: He
  given: Kaiming
- family: Dollár
  given: Piotr
eprint: 1708.02002v2
file: 1708.02002v2.pdf
files:
- lin-tsung-yi-and-goyal-priya-and-girshick-ross-and-he-kaiming-and-dollar-piotrfocal-loss-for-dense-object-detection2017.pdf
month: Aug
primaryclass: cs.CV
ref: 1708.02002v2
time-added: 2020-06-05-22:38:05
title: Focal Loss for Dense Object Detection
type: article
url: http://arxiv.org/abs/1708.02002v2
year: '2017'
