<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="No">
    

    <meta name="journal_id" content="11750"/>

    <meta name="dc.title" content="A survey of recent results on continuous-time Markov decision processes"/>

    <meta name="dc.source" content="TOP 2006 14:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="This paper is a survey of recent results on continuous-time Markov decision processes (MDPs) withunbounded transition rates, and reward rates that may beunbounded from above and from below. These results pertain to discounted and average reward optimality criteria, which are the most commonly used criteria, and also to more selective concepts, such as bias optimality and sensitive discount criteria. For concreteness, we consider only MDPs with a countable state space, but we indicate how the results can be extended to more general MDPs or to Markov games."/>

    <meta name="prism.issn" content="1863-8279"/>

    <meta name="prism.publicationName" content="TOP"/>

    <meta name="prism.volume" content="14"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="177"/>

    <meta name="prism.endingPage" content="261"/>

    <meta name="prism.copyright" content="2006 Springer"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/BF02837562"/>

    <meta name="prism.doi" content="doi:10.1007/BF02837562"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/BF02837562.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/BF02837562"/>

    <meta name="citation_journal_title" content="TOP"/>

    <meta name="citation_journal_abbrev" content="TOP"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1863-8279"/>

    <meta name="citation_title" content="A survey of recent results on continuous-time Markov decision processes"/>

    <meta name="citation_volume" content="14"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2006/12"/>

    <meta name="citation_firstpage" content="177"/>

    <meta name="citation_lastpage" content="261"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/BF02837562"/>

    <meta name="DOI" content="10.1007/BF02837562"/>

    <meta name="citation_doi" content="10.1007/BF02837562"/>

    <meta name="description" content="This paper is a survey of recent results on continuous-time Markov decision processes (MDPs) withunbounded transition rates, and reward rates that may beun"/>

    <meta name="dc.creator" content="Xianping Guo"/>

    <meta name="dc.creator" content="On&#233;simo Hern&#225;ndez-Lerma"/>

    <meta name="dc.creator" content="Tom&#225;s Prieto-Rumeau"/>

    <meta name="dc.creator" content="Xi-Ren Cao"/>

    <meta name="dc.creator" content="Junyu Zhang"/>

    <meta name="dc.creator" content="Qiying Hu"/>

    <meta name="dc.creator" content="Mark E. Lewis"/>

    <meta name="dc.creator" content="Ricardo V&#233;lez"/>

    <meta name="dc.subject" content="Operations Research/Decision Theory"/>

    <meta name="dc.subject" content="Optimization"/>

    <meta name="dc.subject" content="Statistics for Business, Management, Economics, Finance, Insurance"/>

    <meta name="dc.subject" content="Industrial and Production Engineering"/>

    <meta name="dc.subject" content="Economic Theory/Quantitative Economics/Mathematical Methods"/>

    <meta name="citation_reference" content="citation_journal_title=Advances in Applied Probability; citation_title=A Birth-Death Model of Advertising and Pricing; citation_author=S.C. Albright, W. Winston; citation_volume=11; citation_publication_date=1979; citation_pages=134-152; citation_doi=10.2307/1426772; citation_id=CR1"/>

    <meta name="citation_reference" content="Allen L.J.S. (2003).An Introduction to Stochastic Processes with Applications to Biology. Pearson Education."/>

    <meta name="citation_reference" content="Anderson W.J. (1991).Continuous-Time Markov Chains. Springer."/>

    <meta name="citation_reference" content="Bailey N.T.J. (1975).The Mathematical Theory of Infectious Diseases and Its Applications. Griffin."/>

    <meta name="citation_reference" content="Bartholomew D.J. (1973).Stochastic Models for Social Processes, 2nd Edition. Wiley."/>

    <meta name="citation_reference" content="Bellman R. (1957).Dynamic Programming. Princeton University Press."/>

    <meta name="citation_reference" content="Berge C. (1963).Topological Spaces. Macmillan."/>

    <meta name="citation_reference" content="Bertsekas D.P. (2001).,Dynamic Programming and Optimal Control, Vol. II, 2nd. Edition. Athena Scientific."/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Mathematical Statistics; citation_title=Discrete Dynamic Programming; citation_author=D. Blackwell; citation_volume=33; citation_publication_date=1962; citation_pages=719-726; citation_doi=10.1214/aoms/1177704593; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Discrete Event Dynamic Systems: Theory and Applications; citation_title=Basic Ideals for Event-Based Optimality of Markov, Systems; citation_author=X.R. Cao; citation_volume=15; citation_publication_date=2005; citation_pages=169-197; citation_doi=10.1007/s10626-004-6211-4; citation_id=CR10"/>

    <meta name="citation_reference" content="Cao X.R. and Guo X.P. (2006). Continuous-Time Markov Decision Processes withn-Potential Optimality Criteria. Preprint."/>

    <meta name="citation_reference" content="Cao X.R. and Zhang J.Y. (2007). Then-th Order Bias Optimality for Multi-Chain Markov Decsiion Processes.IEEE Transactions on Automatic Control. In press."/>

    <meta name="citation_reference" content="citation_journal_title=Mathematics of Operations Research; citation_title=Average, Sensitive and Blackwell Optimal Policies in Denumerable Markov Decision Chains with Unbounded Rewards; citation_author=R. Dekker, A. Hordijk; citation_volume=13; citation_publication_date=1988; citation_pages=395-420; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematics of Operations Research; citation_title=Recurrence Conditions for Average and Black-well Optimality in Denumerable State Markov Decision Chains; citation_author=R. Dekker, A. Hordijk; citation_volume=17; citation_publication_date=1992; citation_pages=271-289; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Statistics; citation_title=Continuous-Time Control of Markov Processes on an Arbitrary State Space: Discounted Rewards; citation_author=B.T. Doshi; citation_volume=4; citation_publication_date=1976; citation_pages=1219-1235; citation_doi=10.1214/aos/1176343653; citation_id=CR15"/>

    <meta name="citation_reference" content="Dynkin E.B. and Yushkevich A.A. (1979).Controlled Markov Processes. Springer."/>

    <meta name="citation_reference" content="Feinberg E.A. and Shwartz A. (2002).Handbook of Markov Decision Processes. Kluwer."/>

    <meta name="citation_reference" content="citation_journal_title=Transactions of the American Mathematical Society; citation_title=On the Integro-Differential Equations of Purely Discontinuous Markoff Processes; citation_author=W. Feller; citation_volume=48; citation_publication_date=1940; citation_pages=488-515; citation_doi=10.2307/1990095; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Mathematical Statistics; citation_title=On the Recurrent Denumerable Decision Process; citation_author=L. Fisher; citation_volume=39; citation_publication_date=1968; citation_pages=424-434; citation_doi=10.1214/aoms/1177698406; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Review of Economic Studies; citation_title=On Optimal Development in a Multi-Sector Economy; citation_author=D. Gale; citation_volume=34; citation_publication_date=1967; citation_pages=1-19; citation_doi=10.2307/2296567; citation_id=CR20"/>

    <meta name="citation_reference" content="Guo X.P. (2006). Continuous-Time Markov Decision Processes with Discounted Rewards: The Case of Polish Spaces.Mathematics of Operations Research (to appear)."/>

    <meta name="citation_reference" content="citation_journal_title=SIAM Journal on Control and Optimization; citation_title=Optimal Control of Ergodic Continuous-Time Markov Chains with Average Sample-Path Rewards; citation_author=X.P. Guo, X.R. Cao; citation_volume=44; citation_publication_date=2005; citation_pages=29-48; citation_doi=10.1137/S0363012903420875; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Applied Probability; citation_title=Continuous-Time Controlled Markov Chains; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=13; citation_publication_date=2003; citation_pages=363-388; citation_doi=10.1214/aoap/1042765671; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Applicandae Mathematicae; citation_title=Continuous-Time Controlled Markov Chains with Discounted Rewards; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=79; citation_publication_date=2003; citation_pages=195-216; citation_doi=10.1023/B:ACAP.0000003675.06200.45; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Automatic Control; citation_title=Drift and Monotonicity Conditions for Continuous-Time Controlled Markov Chains with an Average Criterion; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=48; citation_publication_date=2003; citation_pages=236-245; citation_doi=10.1109/TAC.2002.808469; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=Zero-Sum Games for Continuous-Time Markov Chains with Unbounded Transition and Average Payoff Rates; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=40; citation_publication_date=2003; citation_pages=327-345; citation_doi=10.1239/jap/1053003547; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=Nonzero-Sum Games for Continuous-Time Markov Chains with Unbounded Discounted Payoffs; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=42; citation_publication_date=2005; citation_pages=302-320; citation_doi=10.1239/jap/1110381391; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Bernoulli; citation_title=Zero-Sum Continuous-Time Markov Games with Unbounded Transition and Discounted Payoff Rates; citation_author=X.P. Guo, O. Hern&#225;ndez-Lerma; citation_volume=16; citation_publication_date=2005; citation_pages=1009-1029; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Automatic Control; citation_title=A Note on Optimality Conditions for Continuous-Time Markov Decision Processes with Average Cost Criterion; citation_author=X.P. Guo, K. Liu; citation_volume=46; citation_publication_date=2001; citation_pages=1984-1989; citation_doi=10.1109/9.975505; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Applied Probability; citation_title=Average Optimality for Continuous-Time Markov Decision Processes in Polish Spaces; citation_author=X.P. Guo, U. Rieder; citation_volume=16; citation_publication_date=2006; citation_pages=730-756; citation_doi=10.1214/105051606000000105; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost and Transition Rates Under the Discounted Criterion; citation_author=X.P. Guo, W.P. Zhu; citation_volume=39; citation_publication_date=2002; citation_pages=233-250; citation_doi=10.1239/jap/1025131422; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=ANZIAM Journal; citation_title=Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost and Transition Rates Under Average Criterion; citation_author=X.P. Guo, W.P. Zhu; citation_volume=43; citation_publication_date=2002; citation_pages=541-557; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=Bias Optimality in Controlled Queuing Systems; citation_author=M. Haviv, M.L. Puterman; citation_volume=35; citation_publication_date=1998; citation_pages=136-150; citation_doi=10.1239/jap/1032192558; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_title=Lectures on Continuous-Time Markov Control Processes; citation_publication_date=1994; citation_id=CR34; citation_author=O. Hern&#225;ndez-Lerma; citation_publisher=Sociedad Matem&#225;tica Mexicana"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Applicandae Mathematicae; citation_title=Nonstationary Continuous-Time Markov Control Processes with Discounted Costs on Infinite Horizon; citation_author=O. Hern&#225;ndez-Lerma, T.E. Govindan; citation_volume=67; citation_publication_date=2001; citation_pages=277-293; citation_doi=10.1023/A:1011970418845; citation_id=CR35"/>

    <meta name="citation_reference" content="Hern&#225;ndez-Lerma O. and Lasserre J.B. (1996).Discrete-Time Markov Control Processes: Basic Optimality Criteria. Springer."/>

    <meta name="citation_reference" content="Hern&#225;ndez-Lerma O. and Lasserre J.B. (1999).Further Topics on Discrete-Time Markov Control Processes. Springer."/>

    <meta name="citation_reference" content="citation_journal_title=Applied Mathematics and Optimization; citation_title=The Scalarization Approach to Multi-objective Markov Control Problems: Why Does it Work?; citation_author=O. Hern&#225;ndez-Lerma, R. Romera; citation_volume=50; citation_publication_date=2004; citation_pages=279-293; citation_doi=10.1007/s00245-004-0804-4; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Applicandae Mathematicae; citation_title=Bias Optimality Versus Strong 0-Discount Optimality in Markov Control Processes with Unbounded Costs; citation_author=N. Hilgert, O. Hern&#225;ndez-Lerma; citation_volume=76; citation_publication_date=2003; citation_pages=215-235; citation_doi=10.1023/A:1024996308133; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=Blackwell Optimality in the Class of Stationary Policies in Markov Decision Chains with a Borel State and Unbounded Rewards; citation_author=A. Hordijk, A.A. Yushkevich; citation_volume=49; citation_publication_date=1999; citation_pages=1-39; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=Blackwell Optimality in the Class of All Policies in Markov Decision Chains with a Borel State and Unbounded Rewards; citation_author=A. Hordijk, A.A. Yushkevich; citation_volume=50; citation_publication_date=1999; citation_pages=421-448; citation_doi=10.1007/s001860050079; citation_id=CR41"/>

    <meta name="citation_reference" content="Hordijk A. and Yushkevich A.A. (2002). Blackwell Optimality. In: Feinberg E.A. and Shwartz A. (eds.),Handbook of Markov Decision Processes. Kluwer, 231&#8211;267."/>

    <meta name="citation_reference" content="citation_title=Markov Decision Processes; citation_publication_date=1998; citation_id=CR43; citation_author=Z.T. Hou; citation_author=X.P. Guo; citation_publisher=Science and Technology Press of Human"/>

    <meta name="citation_reference" content="Howard R.A. (1960).Dynamic Programming and Markov Processes, Wiley."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Mathematical Analysis and Applications; citation_title=Discounted and Average Markov Decision Processes with Unbounded Rewards: New Conditions; citation_author=Q. Hu; citation_volume=171; citation_publication_date=1992; citation_pages=111-124; citation_doi=10.1016/0022-247X(92)90379-R; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Mathematical Analysis and Applications; citation_title=Continuous Time Markov Decision Processes with Discounted Moment Criterion; citation_author=Q. Hu; citation_volume=203; citation_publication_date=1996; citation_pages=1-12; citation_doi=10.1006/jmaa.1996.9999; citation_id=CR46"/>

    <meta name="citation_reference" content="Iosifescu M. and Tautu P. (1973).Stochastic Processes and Applications in Biology and Medicine, Vol. II: Models. Springer."/>

    <meta name="citation_reference" content="citation_journal_title=Mathematics of Operations Research; citation_title=On the Equivalence of Two Expected Average Cost Criteria for Semi-Markov Control Processes; citation_author=A. Jaskiewicz; citation_volume=29; citation_publication_date=2004; citation_pages=326-338; citation_doi=10.1287/moor.1030.0060; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Mathematical Statistics; citation_title=Continuously Discounted Markov Decision Models with Countable State and Action Spaces; citation_author=P. Kakumanu; citation_volume=42; citation_publication_date=1971; citation_pages=919-926; citation_doi=10.1214/aoms/1177693321; citation_id=CR49"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM Journal on Control; citation_title=Nondiscounted Continuous-Time Markov Decision Processes with Countable State and Action Spaces; citation_author=P. Kakumanu; citation_volume=10; citation_publication_date=1972; citation_pages=210-220; citation_doi=10.1137/0310016; citation_id=CR50"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Mathematical Analysis and Applications; citation_title=Continuous Time Markov Decision Processes with Average Return Criterion; citation_author=P. Kakumanu; citation_volume=52; citation_publication_date=1975; citation_pages=173-188; citation_doi=10.1016/0022-247X(75)90063-3; citation_id=CR51"/>

    <meta name="citation_reference" content="citation_journal_title=Naval Research Logistics Quarterly; citation_title=Relation Between Continuous and Discrete Markovian Decision Problems; citation_author=P. Kakumanu; citation_volume=24; citation_publication_date=1977; citation_pages=431-439; citation_doi=10.1002/nav.3800240306; citation_id=CR52"/>

    <meta name="citation_reference" content="Kato T. (1966).Perturbation Theory for Linear Operators. Springer."/>

    <meta name="citation_reference" content="citation_journal_title=Proceedings of the Royal Statistical Society; citation_title=Contributions to the Mathematical Theory of Epidemics; citation_author=W.O. Kermack, A.G. McKendrick; citation_volume=115; citation_publication_date=1927; citation_pages=700-721; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and its Applications; citation_title=Semi-Markov and Jump Markov Controlled Models: Average Cost Criterion; citation_author=M.Yu. Kitayev; citation_volume=30; citation_publication_date=1985; citation_pages=272-288; citation_doi=10.1137/1130036; citation_id=CR55"/>

    <meta name="citation_reference" content="Kitayev M.Yu. and Rykov V.V. (1995).Controlled Queueing Systems. CRC Press."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Mathematical Analysis and Applications; citation_title=Conditions for the Existence of Average and Blackwell Optimal Stationary Policies in Denumerable Markov Decision Processes; citation_author=J.B. Lasserre; citation_volume=136; citation_publication_date=1988; citation_pages=479-490; citation_doi=10.1016/0022-247X(88)90098-4; citation_id=CR57"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Biosciences; citation_title=Optimal Control of the Simple Stochastic Epidemic with Variable Recovery Rates; citation_author=C. Lef&#232;vre; citation_volume=44; citation_publication_date=1979; citation_pages=209-219; citation_doi=10.1016/0025-5564(79)90082-8; citation_id=CR58"/>

    <meta name="citation_reference" content="citation_journal_title=Operations Research; citation_title=Optimal Control of a Birth and Death Epidemic Process; citation_author=C. Lef&#232;vre; citation_volume=29; citation_publication_date=1981; citation_pages=971-982; citation_id=CR59"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematics of Operations Research; citation_title=Overtaking and Almost-Sure Optimality for Infinite Horizon Markov Decision Processes; citation_author=A. Leizarowitz; citation_volume=21; citation_publication_date=1996; citation_pages=158-181; citation_doi=10.1287/moor.21.1.158; citation_id=CR60"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Statistics; citation_title=On Maximal Rewards and &#8712;-Optimal Policies in Continuous Time Markov Chains; citation_author=M.R. Lembersky; citation_volume=2; citation_publication_date=1974; citation_pages=159-169; citation_doi=10.1214/aos/1176342621; citation_id=CR61"/>

    <meta name="citation_reference" content="citation_journal_title=Probability in the Engineering and Informational Sciences; citation_title=Bias Optimality in a Queue with Admission Control; citation_author=M.E. Lewis, H. Ayhan, R.D. Foley; citation_volume=13; citation_publication_date=1999; citation_pages=309-327; citation_doi=10.1017/S0269964899133047; citation_id=CR62"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=Bias Optimal Admission Policies for a Noustationary Multiclass Queueing System; citation_author=M.E. Lewis, H. Ayhan, R.D. Foley; citation_volume=39; citation_publication_date=2002; citation_pages=20-37; citation_doi=10.1239/jap/1019737985; citation_id=CR63"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Probability; citation_title=A Note on Bias Optimality in Controlled Queueing Systems; citation_author=M.E. Lewis, M.L. Puterman; citation_volume=37; citation_publication_date=2001; citation_pages=300-305; citation_id=CR64"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Automatic Control; citation_title=A Probabilistic Analysis of Bias Optimality in Unichain Markov Decision Processes; citation_author=M.E. Lewis, M.L. Puterman; citation_volume=46; citation_publication_date=2002; citation_pages=96-100; citation_doi=10.1109/9.898698; citation_id=CR65"/>

    <meta name="citation_reference" content="citation_journal_title=Operations Research; citation_title=Applying a New Device in the Optimization of Exponential Queueing Systems; citation_author=S.A. Lippman; citation_volume=23; citation_publication_date=1975; citation_pages=667-710; citation_id=CR66"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Applied Probability; citation_title=Computable Exponential Convergence Rates for Stochastically Ordered Markov Processes; citation_author=R.B. Lund, S.P. Meyn, R.L. Tweedie; citation_volume=6; citation_publication_date=1996; citation_pages=218-237; citation_doi=10.1214/aoap/1034968072; citation_id=CR67"/>

    <meta name="citation_reference" content="Mangel M. (1985).Decision and Control in Uncertain Resource Systems. Academic Press."/>

    <meta name="citation_reference" content="Massy W.F., Montgomery D.B. and Morrison D.G. (1970).Stochastic Models of Buying Behavior. MIT Press."/>

    <meta name="citation_reference" content="citation_journal_title=Advances in Applied Probability; citation_title=Stability of Markovian Processes III: Foster-Lyapunov Criteria for Continuous-Time Processes; citation_author=S.P. Meyn, R.L. Tweedie; citation_volume=25; citation_publication_date=1993; citation_pages=518-548; citation_doi=10.2307/1427522; citation_id=CR70"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Mathematical Analysis and Applications; citation_title=Finite State Continuous Time Markov Decision Processes with an Infinite Planning Horizon; citation_author=B.L. Miller; citation_volume=22; citation_publication_date=1968; citation_pages=552-569; citation_doi=10.1016/0022-247X(68)90194-7; citation_id=CR71"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Mathematical Statistics; citation_title=Discrete Dynamic Programming with a Small Interest Rate; citation_author=B.L. Miller, A.F. Veinott; citation_volume=40; citation_publication_date=1969; citation_pages=366-370; citation_doi=10.1214/aoms/1177697700; citation_id=CR72"/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and Its Applications; citation_title=A Controlled Jump Discounted Model with Constraints; citation_author=A.B. Piunovskii; citation_volume=42; citation_publication_date=1998; citation_pages=51-72; citation_doi=10.1137/S0040585X97975964; citation_id=CR73"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=Multicriteria Impulsive Control of Jump Markov Processes; citation_author=A.B. Piunovskii; citation_volume=60; citation_publication_date=2004; citation_pages=125-144; citation_id=CR74"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Applicandae Mathematicae; citation_title=Blackwell Optimality in the Class of Markov Policies for Continuous-Time Controlled Markov Chains; citation_author=T. Prieto-Rumeau; citation_volume=92; citation_publication_date=2006; citation_pages=77-96; citation_doi=10.1007/s10440-006-9060-3; citation_id=CR75"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=The Laurent Series, Sensitive Discount and Blackwell Optimality for Continuous-Time Controlled Markov Chains; citation_author=T. Prieto-Rumeau, O. Hern&#225;ndez-Lerma; citation_volume=61; citation_publication_date=2005; citation_pages=123-145; citation_doi=10.1007/s001860400393; citation_id=CR76"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=Bias and Overtaking Equilibria for Zero-Sum Continuous-Time Markov Games; citation_author=T. Prieto-Rumeau, O. Hern&#225;ndez-Lerma; citation_volume=61; citation_publication_date=2005; citation_pages=437-454; citation_doi=10.1007/s001860400392; citation_id=CR77"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM Journal on Control and Optimization; citation_title=Bias Optimality for Continuous-Time Controlled Markov Chains; citation_author=T. Prieto-Rumeau, O. Hern&#225;ndez-Lerma; citation_volume=45; citation_publication_date=2006; citation_pages=51-73; citation_doi=10.1137/S036301290343432; citation_id=CR78"/>

    <meta name="citation_reference" content="Prieto-Rumeau T. and Hern&#225;ndez-Lerma O (2006b). A Unified Approach to Continuous-Time Discounted Markov Control Processes.Morfismos 10 (to appear)."/>

    <meta name="citation_reference" content="Prieto-Rumeau T. and Hern&#225;ndez-Lerma O. (2006c). Ergodic Control of Continuous-Time Markov Chains with Pathwise Constraints. Preprint."/>

    <meta name="citation_reference" content="Prieto-Rumeau T. and Hern&#225;ndez-Lerma O. (2006d). Variance Minimization and the Overtaking Optimality Approach to Continuous-Time Markov Control Chains. Preprint."/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Probability; citation_title=Sensitive Discount Optimality in Controlled One-Dimensional Diffusions; citation_author=M.L. Puterman; citation_volume=2; citation_publication_date=1974; citation_pages=408-419; citation_doi=10.1214/aop/1176996656; citation_id=CR82"/>

    <meta name="citation_reference" content="Puterman M.L. (1994).Markov Decision Processes. Wiley."/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Computer Aided Design; citation_title=Stochastic Modeling of a Power-Managed System: Construction and Optimization; citation_author=Q. Qiu, Q. Wu, M. Pedram; citation_volume=20; citation_publication_date=2001; citation_pages=1200-1217; citation_doi=10.1109/43.952737; citation_id=CR84"/>

    <meta name="citation_reference" content="citation_journal_title=Econometrics Journal; citation_title=A Mathematical Theory of Savings; citation_author=F.P. Ramsey; citation_volume=38; citation_publication_date=1928; citation_pages=543-559; citation_id=CR85"/>

    <meta name="citation_reference" content="Ross S.M. (1970).Applied Probability Models with Optimization Applications. Holden-Day."/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and Its Applications; citation_title=Markov Sequential Decision Processes with Finite State and Decision Space; citation_author=V.V. Roykov; citation_volume=11; citation_publication_date=1966; citation_pages=302-311; citation_doi=10.1137/1111027; citation_id=CR87"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematics of Operations Research; citation_title=On the Second Optimality Equation for Semi-Markov Decision Models; citation_author=M. Sch&#228;l; citation_volume=17; citation_publication_date=1992; citation_pages=470-486; citation_doi=10.1287/moor.17.2.470; citation_id=CR88"/>

    <meta name="citation_reference" content="Sennott L.I. (1999).Stochastic Dynamic Programming and the Control of Queueing Systems. Wiley."/>

    <meta name="citation_reference" content="citation_journal_title=Operations Research; citation_title=An Equivalence Between Continuous and Discrete Time Markov Decision Processes; citation_author=R.F. Serfozo; citation_volume=27; citation_publication_date=1979; citation_pages=616-620; citation_id=CR90"/>

    <meta name="citation_reference" content="citation_journal_title=Transactions of the Eighth Prague Conference on Information Theory Statistical Decision Functions and Random Processes (Prague, 1978); citation_title=Sensitive Optimality Criteria for Continuous Time Markov Processes; citation_author=K. Sladk&#253;; citation_volume=B; citation_publication_date=1978; citation_pages=221-225; citation_id=CR91"/>

    <meta name="citation_reference" content="citation_journal_title=Scientia Sinica; citation_title=Continuous-Time Markov Decision Programming with Non-Uniformly Bounded Transition Rates; citation_author=J.S. Song; citation_volume=12; citation_publication_date=1987; citation_pages=1258-1267; citation_id=CR92"/>

    <meta name="citation_reference" content="citation_journal_title=TOP; citation_title=Optimal Design and Control of Queues; citation_author=L Tadj, G. Choudhury; citation_volume=13; citation_publication_date=2005; citation_pages=359-412; citation_doi=10.1007/BF02579061; citation_id=CR93"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Programming Study; citation_title=A Laurent Series for the Resolvent of a Strongly Continuous Stochastic Semi-Group; citation_author=H.M. Taylor; citation_volume=6; citation_publication_date=1976; citation_pages=258-263; citation_id=CR94"/>

    <meta name="citation_reference" content="citation_journal_title=annals of Mathematical Statistics; citation_title=On Finding Optimal Policies in Discrete Dynamic Programming with no Discounting; citation_author=A.F. Veinott; citation_volume=37; citation_publication_date=1966; citation_pages=1284-1294; citation_doi=10.1214/aoms/1177699272; citation_id=CR95"/>

    <meta name="citation_reference" content="citation_journal_title=Annals of Mathematical Statistics; citation_title=Discrete Dynamic Programming with Sensitive Discount Optimality Criteria; citation_author=A.F. Veinott; citation_volume=40; citation_publication_date=1969; citation_pages=1635-1660; citation_doi=10.1214/aoms/1177697379; citation_id=CR96"/>

    <meta name="citation_reference" content="citation_journal_title=Operations Research; citation_title=An Operations Research Study of Sales Response to Advertising; citation_author=M.L Vidale, H.B. Wolfe; citation_volume=5; citation_publication_date=1957; citation_pages=370-381; citation_id=CR97"/>

    <meta name="citation_reference" content="citation_journal_title=Review of Economic Studies; citation_title=Existence of Optimal Programs of Accumulation for an Infinite Horizon; citation_author=C.C. Weizs&#228;cker; citation_volume=32; citation_publication_date=1965; citation_pages=85-104; citation_doi=10.2307/2296054; citation_id=CR98"/>

    <meta name="citation_reference" content="citation_journal_title=Theoretical Population Biology; citation_title=Mathematical Models for the Control of Pests and Infectious Diseases: A Survey; citation_author=K. Wickwire; citation_volume=11; citation_publication_date=1977; citation_pages=182-238; citation_doi=10.1016/0040-5809(77)90025-9; citation_id=CR99"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Mathematicae Applicandae Sinica; citation_title=Continuous Time Markov Decision Processes with Unbounded Reward and Non-Uniformly Bounded Transition Rate Under Discounted Criterion; citation_author=C.B. Wu; citation_volume=20; citation_publication_date=1997; citation_pages=196-208; citation_id=CR100"/>

    <meta name="citation_reference" content="Ye L., Guo X.P. and Hern&#225;ndez-Lerma O. (2006). Existence and Regularity of NonhomogeneousQ(t)-Processes under Measurability Conditions. Preprint."/>

    <meta name="citation_reference" content="Yosida K. (1980).Functional Analysis, Sixth Edition. Springer."/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and Its Applications; citation_title=On a Class of Strategies in General Markov Decision Models; citation_author=A.A. Yushkevich; citation_volume=18; citation_publication_date=1973; citation_pages=777-779; citation_doi=10.1137/1118099; citation_id=CR103"/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and its Applications; citation_title=Controlled Markov Models with Countable State and Continuous Time; citation_author=A.A. Yushkevich; citation_volume=22; citation_publication_date=1977; citation_pages=215-235; citation_doi=10.1137/1122029; citation_id=CR104"/>

    <meta name="citation_reference" content="citation_journal_title=Mathematical Methods of Operations Research; citation_title=Blackwell Optimal Policies in a Markov Decision Process with a Borel State Space; citation_author=A.A. Yushkevich; citation_volume=40; citation_publication_date=1994; citation_pages=253-288; citation_doi=10.1007/BF01432969; citation_id=CR105"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM Journal on Control and Optimization; citation_title=Blackwell Optimality in Continuous in Action Markov Decision Processes; citation_author=A.A. Yushkevich; citation_volume=35; citation_publication_date=1997; citation_pages=2157-2182; citation_doi=10.1137/S0363012995292469; citation_id=CR106"/>

    <meta name="citation_reference" content="citation_journal_title=Theory of Probability and its Applications; citation_title=On Homogeneous Markov Model with Continuous Time and Finite or Countable State Space; citation_author=A.A. Yushkevich, E.A. Feinberg; citation_volume=24; citation_publication_date=1979; citation_pages=156-161; citation_doi=10.1137/1124014; citation_id=CR107"/>

    <meta name="citation_author" content="Xianping Guo"/>

    <meta name="citation_author_email" content="mcsgxp@mail.sysu.edu.cn"/>

    <meta name="citation_author_institution" content="Zhongshan University, P.R. China"/>

    <meta name="citation_author" content="On&#233;simo Hern&#225;ndez-Lerma"/>

    <meta name="citation_author_email" content="ohernand@math.cinvestav.mx"/>

    <meta name="citation_author_institution" content="CINVESTAV-IPN, Mexico"/>

    <meta name="citation_author" content="Tom&#225;s Prieto-Rumeau"/>

    <meta name="citation_author_email" content="tprieto@ccia.uned.es"/>

    <meta name="citation_author_institution" content="Universidad Nacional de Educaci&#243;n a Distancia, Spain"/>

    <meta name="citation_author" content="Xi-Ren Cao"/>

    <meta name="citation_author_institution" content="Hong Kong University of Science and Technology, Hong Kong"/>

    <meta name="citation_author" content="Junyu Zhang"/>

    <meta name="citation_author_institution" content="Hong Kong University of Science and Technology, Hong Kong"/>

    <meta name="citation_author" content="Qiying Hu"/>

    <meta name="citation_author_institution" content="Shanghai University, China"/>

    <meta name="citation_author" content="Mark E. Lewis"/>

    <meta name="citation_author_institution" content="Cornell University, USA"/>

    <meta name="citation_author" content="Ricardo V&#233;lez"/>

    <meta name="citation_author_institution" content="Universidad Nacinal de Educaci&#243;n a Distancia, Spain"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A survey of recent results on continuous-time Markov decision processe"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="This paper is a survey of recent results on continuous-time Markov decision processes (MDPs) withunbounded transition rates, and reward rates that may beunbounded from above and from below. These results pertain to discounted and average reward optimality criteria, which are the most commonly used criteria, and also to more selective concepts, such as bias optimality and sensitive discount criteria. For concreteness, we consider only MDPs with a countable state space, but we indicate how the results can be extended to more general MDPs or to Markov games."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/11750/14/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/BF02837562&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/BF02837562"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="TOP"/>
        <meta property="og:title" content="A survey of recent results on continuous-time Markov decision processes"/>
        <meta property="og:description" content="This paper is a survey of recent results on continuous-time Markov decision processes (MDPs) withunbounded transition rates, and reward rates that may beunbounded from above and from below. These results pertain to discounted and average reward optimality criteria, which are the most commonly used criteria, and also to more selective concepts, such as bias optimality and sensitive discount criteria. For concreteness, we consider only MDPs with a countable state space, but we indicate how the results can be extended to more general MDPs or to Markov games."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/11750.jpg"/>
    
    <title>A survey of recent results on continuous-time Markov decision processes | SpringerLink</title>
        <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
    <link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
    <link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
    <link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
    <link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
    <link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
    <link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
    <link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
    <link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
    <link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
    <link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
    <link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
    <link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-2e8ab716a5.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-1af6c9bc14.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"IT","doi":"10.1007-BF02837562","Journal Title":"TOP","Journal Id":11750,"Keywords":"Continuous-time Markov decision processes (also known as controlled Markov chains), unbounded reward and transition rates, discounted reward, average reward, bias optimality, sensitive discount criteria, 90C40, 93E20, 60J27","kwrd":["Continuous-time_Markov_decision_processes_(also_known_as_controlled_Markov_chains)","unbounded_reward_and_transition_rates","discounted_reward","average_reward","bias_optimality","sensitive_discount_criteria","90C40","93E20","60J27"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"N","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"no-access","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-BF02837562","Full HTML":"N","Subject Codes":["SC5","SC521000","SCM26008","SCS17010","SCT22008","SCW29000"],"pmc":["5","521000","M26008","S17010","T22008","W29000"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1863-8279","pissn":"1134-5764"},"type":"Article","category":{"pmc":{"primarySubject":"Business and Management","primarySubjectCode":"5","secondarySubjects":{"1":"Operations Research/Decision Theory","2":"Optimization","3":"Statistics for Business, Management, Economics, Finance, Insurance","4":"Industrial and Production Engineering","5":"Economic Theory/Quantitative Economics/Mathematical Methods"},"secondarySubjectCodes":{"1":"521000","2":"M26008","3":"S17010","4":"T22008","5":"W29000"}},"sucode":"SC16"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/BF02837562","Page":"article"}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>






</head>
<body class="shared-article-renderer">
    <div class="u-vh-full">
        <div class="c-ad c-ad--LB1" data-test="springer-doubleclick-ad">
    <div class="c-ad c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/11750/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=BF02837562;"></div>
    </div>
</div>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="true"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu" data-enhanced-menu>
                
                    <li class="c-header__item u-hide-at-lt-lg">
                        <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2FBF02837562">Log in</a>
                    </li>
                




                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">

            <main class="c-article-main-column u-float-left js-main-column">
                
                <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                    <div class="c-article-header">
                        <header>
                            <ul class="c-article-identifiers" data-test="article-identifier">
                                
    
    
    

                                <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-category="article body" data-track-label="link">Published: <time datetime="2006-12" itemprop="datePublished">December 2006</time></a></li>
                            </ul>

                            
                            <h1 class="c-article-title u-h1" data-test="article-title" data-article-title="" itemprop="name headline">A survey of recent results on continuous-time Markov decision processes</h1>
                            <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-1">Xianping Guo</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Zhongshan University" /><meta itemprop="address" content="grid.12981.33, 000000012360039X, Zhongshan University, P.R. China" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-2">Onésimo Hernández-Lerma</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CINVESTAV-IPN" /><meta itemprop="address" content="grid.418275.d, 0000000121658782, CINVESTAV-IPN, Mexico" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-3">Tomás Prieto-Rumeau</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidad Nacional de Educación a Distancia" /><meta itemprop="address" content="grid.10702.34, 0000000123088920, Universidad Nacional de Educación a Distancia, Spain" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-4">Xi-Ren Cao</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Hong Kong University of Science and Technology" /><meta itemprop="address" content="grid.24515.37, 0000000419371450, Hong Kong University of Science and Technology, Hong Kong" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-5">Junyu Zhang</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Hong Kong University of Science and Technology" /><meta itemprop="address" content="grid.24515.37, 0000000419371450, Hong Kong University of Science and Technology, Hong Kong" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-6">Qiying Hu</a></span><sup class="u-js-hide"><a href="#Aff5">5</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Shanghai University" /><meta itemprop="address" content="grid.39436.3b, 0000000123235732, Shanghai University, China" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-7">Mark E. Lewis</a></span><sup class="u-js-hide"><a href="#Aff6">6</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Cornell University" /><meta itemprop="address" content="grid.5386.8, 000000041936877X, Cornell University, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-8">Ricardo Vélez</a></span><sup class="u-js-hide"><a href="#Aff7">7</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidad Nacinal de Educación a Distancia" /><meta itemprop="address" content="Universidad Nacinal de Educación a Distancia, Spain" /></span></sup> </li></ul>
                            <p class="c-article-info-details" data-container-section="info">
                                
    <a data-test="journal-link" href="/journal/11750"><i data-test="journal-title">TOP</i></a>

                                <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 14</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">177</span>–<span itemprop="pageEnd">261</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                            </p>
                            
    

                            <div data-test="article-metrics">
                                <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-inline">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">617 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">55 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2FBF02837562/metrics" data-track="click" data-track-action="view metrics" data-track-category="article body" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                            </div>
                            
                            
                            
                        </header>
                    </div>

                    <div data-article-body="true" data-track-component="article body" class="c-article-body">
                        <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This paper is a survey of recent results on continuous-time Markov decision processes (MDPs) with<i>unbounded</i> transition rates, and reward rates that may be<i>unbounded</i> from above and from below. These results pertain to discounted and average reward optimality criteria, which are the most commonly used criteria, and also to more selective concepts, such as bias optimality and sensitive discount criteria. For concreteness, we consider only MDPs with a countable state space, but we indicate how the results can be extended to more general MDPs or to Markov games.</p></div></div></section>
                        
    


                        
                            
                                <div class="c-notes">
                                    <p class="c-notes__text">This is a preview of subscription content, <a id="test-login-banner-link" href="//link.springer.com/signup-login?previousUrl&#x3D;https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2FBF02837562" data-track="click" data-track-action="login" data-track-label="link">log in</a> to check access.</p>
                                </div>
                            
                            
                                <div class="c-article-buy-box c-article-buy-box--article">
                                    <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">37,40 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/BF02837562">
     <input type="hidden" name="isxn" value="1863-8279">
     <input type="hidden" name="contenttitle" value="A survey of recent results on continuous-time Markov decision processes">
     <input type="hidden" name="copyrightyear" value="2006">
     <input type="hidden" name="year" value="">
     <input type="hidden" name="authors" value="Xianping Guo, et al.">
     <input type="hidden" name="title" value="TOP">
     <input type="hidden" name="mac" value="37E2A931385D5AD3D8C22140AD7ECD00">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action, new buybox" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">81 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="TOP">
     <input type="hidden" name="journalnumber" value="11750">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/BF02837562&journal=1863-8279&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                                </div>
                            
                            <div class="u-display-none">
                                
                            </div>
                        

                        

                        

                        <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S.C.. Albright, W.. Winston, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Albright S.C. and Winston W. (1979). A Birth-Death Model of Advertising and Pricing.Advances in Applied Probab" /><p class="c-article-references__text" id="ref-CR1">Albright S.C. and Winston W. (1979). A Birth-Death Model of Advertising and Pricing.<i>Advances in Applied Probability</i> 11, 134–152.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.2307%2F1426772" aria-label="View reference 1">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Birth-Death%20Model%20of%20Advertising%20and%20Pricing&amp;journal=Advances%20in%20Applied%20Probability&amp;volume=11&amp;pages=134-152&amp;publication_year=1979&amp;author=Albright%2CS.C.&amp;author=Winston%2CW.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Allen L.J.S. (2003).An Introduction to Stochastic Processes with Applications to Biology. Pearson Education." /><p class="c-article-references__text" id="ref-CR2">Allen L.J.S. (2003).<i>An Introduction to Stochastic Processes with Applications to Biology</i>. Pearson Education.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Anderson W.J. (1991).Continuous-Time Markov Chains. Springer." /><p class="c-article-references__text" id="ref-CR3">Anderson W.J. (1991).<i>Continuous-Time Markov Chains</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bailey N.T.J. (1975).The Mathematical Theory of Infectious Diseases and Its Applications. Griffin." /><p class="c-article-references__text" id="ref-CR4">Bailey N.T.J. (1975).<i>The Mathematical Theory of Infectious Diseases and Its Applications</i>. Griffin.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bartholomew D.J. (1973).Stochastic Models for Social Processes, 2nd Edition. Wiley." /><p class="c-article-references__text" id="ref-CR5">Bartholomew D.J. (1973).<i>Stochastic Models for Social Processes, 2nd Edition</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bellman R. (1957).Dynamic Programming. Princeton University Press." /><p class="c-article-references__text" id="ref-CR6">Bellman R. (1957).<i>Dynamic Programming</i>. Princeton University Press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Berge C. (1963).Topological Spaces. Macmillan." /><p class="c-article-references__text" id="ref-CR7">Berge C. (1963).<i>Topological Spaces</i>. Macmillan.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bertsekas D.P. (2001).,Dynamic Programming and Optimal Control, Vol. II, 2nd. Edition. Athena Scientific." /><p class="c-article-references__text" id="ref-CR8">Bertsekas D.P. (2001).,<i>Dynamic Programming and Optimal Control, Vol. II, 2nd. Edition</i>. Athena Scientific.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D.. Blackwell, " /><meta itemprop="datePublished" content="1962" /><meta itemprop="headline" content="Blackwell D. (1962). Discrete Dynamic Programming.Annals of Mathematical Statistics 33, 719–726." /><p class="c-article-references__text" id="ref-CR9">Blackwell D. (1962). Discrete Dynamic Programming.<i>Annals of Mathematical Statistics</i> 33, 719–726.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177704593" aria-label="View reference 9">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discrete%20Dynamic%20Programming&amp;journal=Annals%20of%20Mathematical%20Statistics&amp;volume=33&amp;pages=719-726&amp;publication_year=1962&amp;author=Blackwell%2CD.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.R.. Cao, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Cao X.R. (2005). Basic Ideals for Event-Based Optimality of Markov, Systems.Discrete Event Dynamic Systems: Th" /><p class="c-article-references__text" id="ref-CR10">Cao X.R. (2005). Basic Ideals for Event-Based Optimality of Markov, Systems.<i>Discrete Event Dynamic Systems: Theory and Applications</i> 15, 169–197.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs10626-004-6211-4" aria-label="View reference 10">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Basic%20Ideals%20for%20Event-Based%20Optimality%20of%20Markov%2C%20Systems&amp;journal=Discrete%20Event%20Dynamic%20Systems%3A%20Theory%20and%20Applications&amp;volume=15&amp;pages=169-197&amp;publication_year=2005&amp;author=Cao%2CX.R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cao X.R. and Guo X.P. (2006). Continuous-Time Markov Decision Processes withn-Potential Optimality Criteria. P" /><p class="c-article-references__text" id="ref-CR11">Cao X.R. and Guo X.P. (2006). Continuous-Time Markov Decision Processes with<i>n</i>-Potential Optimality Criteria. Preprint.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cao X.R. and Zhang J.Y. (2007). Then-th Order Bias Optimality for Multi-Chain Markov Decsiion Processes.IEEE T" /><p class="c-article-references__text" id="ref-CR12">Cao X.R. and Zhang J.Y. (2007). The<i>n</i>-th Order Bias Optimality for Multi-Chain Markov Decsiion Processes.<i>IEEE Transactions on Automatic Control</i>. In press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R.. Dekker, A.. Hordijk, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Dekker R. and Hordijk A. (1988). Average, Sensitive and Blackwell Optimal Policies in Denumerable Markov Decis" /><p class="c-article-references__text" id="ref-CR13">Dekker R. and Hordijk A. (1988). Average, Sensitive and Blackwell Optimal Policies in Denumerable Markov Decision Chains with Unbounded Rewards.<i>Mathematics of Operations Research</i> 13, 395–420.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Average%2C%20Sensitive%20and%20Blackwell%20Optimal%20Policies%20in%20Denumerable%20Markov%20Decision%20Chains%20with%20Unbounded%20Rewards&amp;journal=Mathematics%20of%20Operations%20Research&amp;volume=13&amp;pages=395-420&amp;publication_year=1988&amp;author=Dekker%2CR.&amp;author=Hordijk%2CA.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R.. Dekker, A.. Hordijk, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Dekker R. and Hordijk A. (1992). Recurrence Conditions for Average and Black-well Optimality in Denumerable St" /><p class="c-article-references__text" id="ref-CR14">Dekker R. and Hordijk A. (1992). Recurrence Conditions for Average and Black-well Optimality in Denumerable State Markov Decision Chains.<i>Mathematics of Operations Research</i> 17, 271–289.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Recurrence%20Conditions%20for%20Average%20and%20Black-well%20Optimality%20in%20Denumerable%20State%20Markov%20Decision%20Chains&amp;journal=Mathematics%20of%20Operations%20Research&amp;volume=17&amp;pages=271-289&amp;publication_year=1992&amp;author=Dekker%2CR.&amp;author=Hordijk%2CA.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B.T.. Doshi, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Doshi B.T. (1976). Continuous-Time Control of Markov Processes on an Arbitrary State Space: Discounted Rewards" /><p class="c-article-references__text" id="ref-CR15">Doshi B.T. (1976). Continuous-Time Control of Markov Processes on an Arbitrary State Space: Discounted Rewards.<i>Annals of Statistics</i> 4, 1219–1235.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176343653" aria-label="View reference 15">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous-Time%20Control%20of%20Markov%20Processes%20on%20an%20Arbitrary%20State%20Space%3A%20Discounted%20Rewards&amp;journal=Annals%20of%20Statistics&amp;volume=4&amp;pages=1219-1235&amp;publication_year=1976&amp;author=Doshi%2CB.T.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dynkin E.B. and Yushkevich A.A. (1979).Controlled Markov Processes. Springer." /><p class="c-article-references__text" id="ref-CR16">Dynkin E.B. and Yushkevich A.A. (1979).<i>Controlled Markov Processes</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Feinberg E.A. and Shwartz A. (2002).Handbook of Markov Decision Processes. Kluwer." /><p class="c-article-references__text" id="ref-CR17">Feinberg E.A. and Shwartz A. (2002).<i>Handbook of Markov Decision Processes</i>. Kluwer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W.. Feller, " /><meta itemprop="datePublished" content="1940" /><meta itemprop="headline" content="Feller W. (1940). On the Integro-Differential Equations of Purely Discontinuous Markoff Processes.Transactions" /><p class="c-article-references__text" id="ref-CR18">Feller W. (1940). On the Integro-Differential Equations of Purely Discontinuous Markoff Processes.<i>Transactions of the American Mathematical Society</i> 48, 488–515.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.2307%2F1990095" aria-label="View reference 18">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20Integro-Differential%20Equations%20of%20Purely%20Discontinuous%20Markoff%20Processes&amp;journal=Transactions%20of%20the%20American%20Mathematical%20Society&amp;volume=48&amp;pages=488-515&amp;publication_year=1940&amp;author=Feller%2CW.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L.. Fisher, " /><meta itemprop="datePublished" content="1968" /><meta itemprop="headline" content="Fisher L. (1968). On the Recurrent Denumerable Decision Process.Annals of Mathematical Statistics 39, 424–434." /><p class="c-article-references__text" id="ref-CR19">Fisher L. (1968). On the Recurrent Denumerable Decision Process.<i>Annals of Mathematical Statistics</i> 39, 424–434.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177698406" aria-label="View reference 19">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20Recurrent%20Denumerable%20Decision%20Process&amp;journal=Annals%20of%20Mathematical%20Statistics&amp;volume=39&amp;pages=424-434&amp;publication_year=1968&amp;author=Fisher%2CL.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D.. Gale, " /><meta itemprop="datePublished" content="1967" /><meta itemprop="headline" content="Gale D. (1967). On Optimal Development in a Multi-Sector Economy.Review of Economic Studies 34, 1–19." /><p class="c-article-references__text" id="ref-CR20">Gale D. (1967). On Optimal Development in a Multi-Sector Economy.<i>Review of Economic Studies</i> 34, 1–19.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.2307%2F2296567" aria-label="View reference 20">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20Optimal%20Development%20in%20a%20Multi-Sector%20Economy&amp;journal=Review%20of%20Economic%20Studies&amp;volume=34&amp;pages=1-19&amp;publication_year=1967&amp;author=Gale%2CD.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Guo X.P. (2006). Continuous-Time Markov Decision Processes with Discounted Rewards: The Case of Polish Spaces." /><p class="c-article-references__text" id="ref-CR21">Guo X.P. (2006). Continuous-Time Markov Decision Processes with Discounted Rewards: The Case of Polish Spaces.<i>Mathematics of Operations Research</i> (to appear).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, X.R.. Cao, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Guo X.P. and Cao X.R. (2005). Optimal Control of Ergodic Continuous-Time Markov Chains with Average Sample-Pat" /><p class="c-article-references__text" id="ref-CR22">Guo X.P. and Cao X.R. (2005). Optimal Control of Ergodic Continuous-Time Markov Chains with Average Sample-Path Rewards.<i>SIAM Journal on Control and Optimization</i> 44, 29–48.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2FS0363012903420875" aria-label="View reference 22">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20Control%20of%20Ergodic%20Continuous-Time%20Markov%20Chains%20with%20Average%20Sample-Path%20Rewards&amp;journal=SIAM%20Journal%20on%20Control%20and%20Optimization&amp;volume=44&amp;pages=29-48&amp;publication_year=2005&amp;author=Guo%2CX.P.&amp;author=Cao%2CX.R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2003a). Continuous-Time Controlled Markov Chains.Annals of Applied Probabilit" /><p class="c-article-references__text" id="ref-CR23">Guo X.P. and Hernández-Lerma O. (2003a). Continuous-Time Controlled Markov Chains.<i>Annals of Applied Probability</i> 13, 363–388.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoap%2F1042765671" aria-label="View reference 23">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous-Time%20Controlled%20Markov%20Chains&amp;journal=Annals%20of%20Applied%20Probability&amp;volume=13&amp;pages=363-388&amp;publication_year=2003&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2003b). Continuous-Time Controlled Markov Chains with Discounted Rewards.Acta" /><p class="c-article-references__text" id="ref-CR24">Guo X.P. and Hernández-Lerma O. (2003b). Continuous-Time Controlled Markov Chains with Discounted Rewards.<i>Acta Applicandae Mathematicae</i> 79, 195–216.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1023%2FB%3AACAP.0000003675.06200.45" aria-label="View reference 24">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous-Time%20Controlled%20Markov%20Chains%20with%20Discounted%20Rewards&amp;journal=Acta%20Applicandae%20Mathematicae&amp;volume=79&amp;pages=195-216&amp;publication_year=2003&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2003c). Drift and Monotonicity Conditions for Continuous-Time Controlled Mark" /><p class="c-article-references__text" id="ref-CR25">Guo X.P. and Hernández-Lerma O. (2003c). Drift and Monotonicity Conditions for Continuous-Time Controlled Markov Chains with an Average Criterion.<i>IEEE Transactions on Automatic Control</i> 48, 236–245.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTAC.2002.808469" aria-label="View reference 25">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Drift%20and%20Monotonicity%20Conditions%20for%20Continuous-Time%20Controlled%20Markov%20Chains%20with%20an%20Average%20Criterion&amp;journal=IEEE%20Transactions%20on%20Automatic%20Control&amp;volume=48&amp;pages=236-245&amp;publication_year=2003&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2003d). Zero-Sum Games for Continuous-Time Markov Chains with Unbounded Trans" /><p class="c-article-references__text" id="ref-CR26">Guo X.P. and Hernández-Lerma O. (2003d). Zero-Sum Games for Continuous-Time Markov Chains with Unbounded Transition and Average Payoff Rates.<i>Journal of Applied Probability</i> 40, 327–345.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1053003547" aria-label="View reference 26">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Zero-Sum%20Games%20for%20Continuous-Time%20Markov%20Chains%20with%20Unbounded%20Transition%20and%20Average%20Payoff%20Rates&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=40&amp;pages=327-345&amp;publication_year=2003&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2005a). Nonzero-Sum Games for Continuous-Time Markov Chains with Unbounded Di" /><p class="c-article-references__text" id="ref-CR27">Guo X.P. and Hernández-Lerma O. (2005a). Nonzero-Sum Games for Continuous-Time Markov Chains with Unbounded Discounted Payoffs.<i>Journal of Applied Probability</i> 42, 302–320.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1110381391" aria-label="View reference 27">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonzero-Sum%20Games%20for%20Continuous-Time%20Markov%20Chains%20with%20Unbounded%20Discounted%20Payoffs&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=42&amp;pages=302-320&amp;publication_year=2005&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Guo X.P. and Hernández-Lerma O. (2005b). Zero-Sum Continuous-Time Markov Games with Unbounded Transition and D" /><p class="c-article-references__text" id="ref-CR28">Guo X.P. and Hernández-Lerma O. (2005b). Zero-Sum Continuous-Time Markov Games with Unbounded Transition and Discounted Payoff Rates.<i>Bernoulli</i> 16, 1009–1029.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Zero-Sum%20Continuous-Time%20Markov%20Games%20with%20Unbounded%20Transition%20and%20Discounted%20Payoff%20Rates&amp;journal=Bernoulli&amp;volume=16&amp;pages=1009-1029&amp;publication_year=2005&amp;author=Guo%2CX.P.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, K.. Liu, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Guo X.P. and Liu K. (2001). A Note on Optimality Conditions for Continuous-Time Markov Decision Processes with" /><p class="c-article-references__text" id="ref-CR29">Guo X.P. and Liu K. (2001). A Note on Optimality Conditions for Continuous-Time Markov Decision Processes with Average Cost Criterion.<i>IEEE Transactions on Automatic Control</i> 46, 1984–1989.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2F9.975505" aria-label="View reference 29">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Note%20on%20Optimality%20Conditions%20for%20Continuous-Time%20Markov%20Decision%20Processes%20with%20Average%20Cost%20Criterion&amp;journal=IEEE%20Transactions%20on%20Automatic%20Control&amp;volume=46&amp;pages=1984-1989&amp;publication_year=2001&amp;author=Guo%2CX.P.&amp;author=Liu%2CK.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, U.. Rieder, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Guo X.P. and Rieder U. (2006). Average Optimality for Continuous-Time Markov Decision Processes in Polish Spac" /><p class="c-article-references__text" id="ref-CR30">Guo X.P. and Rieder U. (2006). Average Optimality for Continuous-Time Markov Decision Processes in Polish Spaces.<i>Annals of Applied Probability</i> 16, 730–756.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2F105051606000000105" aria-label="View reference 30">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Average%20Optimality%20for%20Continuous-Time%20Markov%20Decision%20Processes%20in%20Polish%20Spaces&amp;journal=Annals%20of%20Applied%20Probability&amp;volume=16&amp;pages=730-756&amp;publication_year=2006&amp;author=Guo%2CX.P.&amp;author=Rieder%2CU.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, W.P.. Zhu, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Guo X.P. and Zhu W.P. (2002a). Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost" /><p class="c-article-references__text" id="ref-CR31">Guo X.P. and Zhu W.P. (2002a). Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost and Transition Rates Under the Discounted Criterion.<i>Journal of Applied Probability</i> 39, 233–250.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1025131422" aria-label="View reference 31">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Denumerable%20State%20Continuous-Time%20Markov%20Decision%20Processes%20with%20Unbounded%20Cost%20and%20Transition%20Rates%20Under%20the%20Discounted%20Criterion&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=39&amp;pages=233-250&amp;publication_year=2002&amp;author=Guo%2CX.P.&amp;author=Zhu%2CW.P.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.P.. Guo, W.P.. Zhu, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Guo X.P. and Zhu W.P. (2002b). Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost" /><p class="c-article-references__text" id="ref-CR32">Guo X.P. and Zhu W.P. (2002b). Denumerable State Continuous-Time Markov Decision Processes with Unbounded Cost and Transition Rates Under Average Criterion.<i>ANZIAM Journal</i> 43, 541–557.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Denumerable%20State%20Continuous-Time%20Markov%20Decision%20Processes%20with%20Unbounded%20Cost%20and%20Transition%20Rates%20Under%20Average%20Criterion&amp;journal=ANZIAM%20Journal&amp;volume=43&amp;pages=541-557&amp;publication_year=2002&amp;author=Guo%2CX.P.&amp;author=Zhu%2CW.P.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.. Haviv, M.L.. Puterman, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Haviv M. and Puterman M.L. (1998). Bias Optimality in Controlled Queuing Systems.Journal of Applied Probabilit" /><p class="c-article-references__text" id="ref-CR33">Haviv M. and Puterman M.L. (1998). Bias Optimality in Controlled Queuing Systems.<i>Journal of Applied Probability</i> 35, 136–150.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1032192558" aria-label="View reference 33">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20in%20Controlled%20Queuing%20Systems&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=35&amp;pages=136-150&amp;publication_year=1998&amp;author=Haviv%2CM.&amp;author=Puterman%2CM.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Hernández-Lerma O. (1994).Lectures on Continuous-Time Markov Control Processes. Aportaciones Matemáticas, Vol." /><p class="c-article-references__text" id="ref-CR34">Hernández-Lerma O. (1994).<i>Lectures on Continuous-Time Markov Control Processes</i>. Aportaciones Matemáticas, Vol. 3, Sociedad Matemática Mexicana, Mexico City.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Lectures%20on%20Continuous-Time%20Markov%20Control%20Processes&amp;publication_year=1994&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O.. Hernández-Lerma, T.E.. Govindan, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Hernández-Lerma O. and Govindan T.E. (2001). Nonstationary Continuous-Time Markov Control Processes with Disco" /><p class="c-article-references__text" id="ref-CR35">Hernández-Lerma O. and Govindan T.E. (2001). Nonstationary Continuous-Time Markov Control Processes with Discounted Costs on Infinite Horizon.,<i>Acta Applicandae Mathematicae</i> 67, 277–293.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1011970418845" aria-label="View reference 35">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonstationary%20Continuous-Time%20Markov%20Control%20Processes%20with%20Discounted%20Costs%20on%20Infinite%20Horizon&amp;journal=Acta%20Applicandae%20Mathematicae&amp;volume=67&amp;pages=277-293&amp;publication_year=2001&amp;author=Hern%C3%A1ndez-Lerma%2CO.&amp;author=Govindan%2CT.E.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Lerma O. and Lasserre J.B. (1996).Discrete-Time Markov Control Processes: Basic Optimality Criteria." /><p class="c-article-references__text" id="ref-CR36">Hernández-Lerma O. and Lasserre J.B. (1996).<i>Discrete-Time Markov Control Processes: Basic Optimality Criteria</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Lerma O. and Lasserre J.B. (1999).Further Topics on Discrete-Time Markov Control Processes. Springer" /><p class="c-article-references__text" id="ref-CR37">Hernández-Lerma O. and Lasserre J.B. (1999).<i>Further Topics on Discrete-Time Markov Control Processes</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O.. Hernández-Lerma, R.. Romera, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hernández-Lerma O. and Romera R. (2004). The Scalarization Approach to Multi-objective Markov Control Problems" /><p class="c-article-references__text" id="ref-CR38">Hernández-Lerma O. and Romera R. (2004). The Scalarization Approach to Multi-objective Markov Control Problems: Why Does it Work?<i>Applied Mathematics and Optimization</i> 50, 279–293.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs00245-004-0804-4" aria-label="View reference 38">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Scalarization%20Approach%20to%20Multi-objective%20Markov%20Control%20Problems%3A%20Why%20Does%20it%20Work%3F&amp;journal=Applied%20Mathematics%20and%20Optimization&amp;volume=50&amp;pages=279-293&amp;publication_year=2004&amp;author=Hern%C3%A1ndez-Lerma%2CO.&amp;author=Romera%2CR.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N.. Hilgert, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Hilgert N. and Hernández-Lerma O. (2003). Bias Optimality Versus Strong 0-Discount Optimality in Markov Contro" /><p class="c-article-references__text" id="ref-CR39">Hilgert N. and Hernández-Lerma O. (2003). Bias Optimality Versus Strong 0-Discount Optimality in Markov Control Processes with Unbounded Costs.<i>Acta Applicandae Mathematicae</i> 76, 215–235.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1024996308133" aria-label="View reference 39">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20Versus%20Strong%200-Discount%20Optimality%20in%20Markov%20Control%20Processes%20with%20Unbounded%20Costs&amp;journal=Acta%20Applicandae%20Mathematicae&amp;volume=76&amp;pages=215-235&amp;publication_year=2003&amp;author=Hilgert%2CN.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.. Hordijk, A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Hordijk A. and Yushkevich A.A. (1999a). Blackwell Optimality in the Class of Stationary Policies in Markov Dec" /><p class="c-article-references__text" id="ref-CR40">Hordijk A. and Yushkevich A.A. (1999a). Blackwell Optimality in the Class of Stationary Policies in Markov Decision Chains with a Borel State and Unbounded Rewards.<i>Mathematical Methods of Operations Research</i> 49, 1–39.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Blackwell%20Optimality%20in%20the%20Class%20of%20Stationary%20Policies%20in%20Markov%20Decision%20Chains%20with%20a%20Borel%20State%20and%20Unbounded%20Rewards&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=49&amp;pages=1-39&amp;publication_year=1999&amp;author=Hordijk%2CA.&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.. Hordijk, A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Hordijk A. and Yushkevich A.A. (1999b). Blackwell Optimality in the Class of All Policies in Markov Decision C" /><p class="c-article-references__text" id="ref-CR41">Hordijk A. and Yushkevich A.A. (1999b). Blackwell Optimality in the Class of All Policies in Markov Decision Chains with a Borel State and Unbounded Rewards.<i>Mathematical Methods of Operations Research</i> 50, 421–448.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs001860050079" aria-label="View reference 41">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Blackwell%20Optimality%20in%20the%20Class%20of%20All%20Policies%20in%20Markov%20Decision%20Chains%20with%20a%20Borel%20State%20and%20Unbounded%20Rewards&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=50&amp;pages=421-448&amp;publication_year=1999&amp;author=Hordijk%2CA.&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hordijk A. and Yushkevich A.A. (2002). Blackwell Optimality. In: Feinberg E.A. and Shwartz A. (eds.),Handbook " /><p class="c-article-references__text" id="ref-CR42">Hordijk A. and Yushkevich A.A. (2002). Blackwell Optimality. In: Feinberg E.A. and Shwartz A. (eds.),<i>Handbook of Markov Decision Processes</i>. Kluwer, 231–267.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Z.T.. Hou, X.P.. Guo, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hou Z.T. and Guo X.P. (1998).Markov Decision Processes. Science and Technology Press of Human, Changsha, China" /><p class="c-article-references__text" id="ref-CR43">Hou Z.T. and Guo X.P. (1998).<i>Markov Decision Processes</i>. Science and Technology Press of Human, Changsha, China. (In Chinese.)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Markov%20Decision%20Processes&amp;publication_year=1998&amp;author=Hou%2CZ.T.&amp;author=Guo%2CX.P.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Howard R.A. (1960).Dynamic Programming and Markov Processes, Wiley." /><p class="c-article-references__text" id="ref-CR44">Howard R.A. (1960).<i>Dynamic Programming and Markov Processes</i>, Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Hu Q. (1992). Discounted and Average Markov Decision Processes with Unbounded Rewards: New Conditions.Journal " /><p class="c-article-references__text" id="ref-CR45">Hu Q. (1992). Discounted and Average Markov Decision Processes with Unbounded Rewards: New Conditions.<i>Journal of Mathematical Analysis and Applications</i> 171, 111–124.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2892%2990379-R" aria-label="View reference 45">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discounted%20and%20Average%20Markov%20Decision%20Processes%20with%20Unbounded%20Rewards%3A%20New%20Conditions&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=171&amp;pages=111-124&amp;publication_year=1992&amp;author=Hu%2CQ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Hu Q. (1996). Continuous Time Markov Decision Processes with Discounted Moment Criterion.Journal of Mathematic" /><p class="c-article-references__text" id="ref-CR46">Hu Q. (1996). Continuous Time Markov Decision Processes with Discounted Moment Criterion.<i>Journal of Mathematical Analysis and Applications</i> 203, 1–12.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1006%2Fjmaa.1996.9999" aria-label="View reference 46">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%20with%20Discounted%20Moment%20Criterion&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=203&amp;pages=1-12&amp;publication_year=1996&amp;author=Hu%2CQ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Iosifescu M. and Tautu P. (1973).Stochastic Processes and Applications in Biology and Medicine, Vol. II: Model" /><p class="c-article-references__text" id="ref-CR47">Iosifescu M. and Tautu P. (1973).<i>Stochastic Processes and Applications in Biology and Medicine, Vol. II: Models</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.. Jaskiewicz, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Jaskiewicz A. (2004). On the Equivalence of Two Expected Average Cost Criteria for Semi-Markov Control Process" /><p class="c-article-references__text" id="ref-CR48">Jaskiewicz A. (2004). On the Equivalence of Two Expected Average Cost Criteria for Semi-Markov Control Processes.<i>Mathematics of Operations Research</i> 29, 326–338.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1287%2Fmoor.1030.0060" aria-label="View reference 48">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20Equivalence%20of%20Two%20Expected%20Average%20Cost%20Criteria%20for%20Semi-Markov%20Control%20Processes&amp;journal=Mathematics%20of%20Operations%20Research&amp;volume=29&amp;pages=326-338&amp;publication_year=2004&amp;author=Jaskiewicz%2CA.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P.. Kakumanu, " /><meta itemprop="datePublished" content="1971" /><meta itemprop="headline" content="Kakumanu P. (1971). Continuously Discounted Markov Decision Models with Countable State and Action Spaces.Anna" /><p class="c-article-references__text" id="ref-CR49">Kakumanu P. (1971). Continuously Discounted Markov Decision Models with Countable State and Action Spaces.<i>Annals of Mathematical Statistics</i> 42, 919–926.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177693321" aria-label="View reference 49">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuously%20Discounted%20Markov%20Decision%20Models%20with%20Countable%20State%20and%20Action%20Spaces&amp;journal=Annals%20of%20Mathematical%20Statistics&amp;volume=42&amp;pages=919-926&amp;publication_year=1971&amp;author=Kakumanu%2CP.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P.. Kakumanu, " /><meta itemprop="datePublished" content="1972" /><meta itemprop="headline" content="Kakumanu P. (1972). Nondiscounted Continuous-Time Markov Decision Processes with Countable State and Action Sp" /><p class="c-article-references__text" id="ref-CR50">Kakumanu P. (1972). Nondiscounted Continuous-Time Markov Decision Processes with Countable State and Action Spaces.<i>SIAM Journal on Control</i> 10, 210–220.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F0310016" aria-label="View reference 50">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nondiscounted%20Continuous-Time%20Markov%20Decision%20Processes%20with%20Countable%20State%20and%20Action%20Spaces&amp;journal=SIAM%20Journal%20on%20Control&amp;volume=10&amp;pages=210-220&amp;publication_year=1972&amp;author=Kakumanu%2CP.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P.. Kakumanu, " /><meta itemprop="datePublished" content="1975" /><meta itemprop="headline" content="Kakumanu P. (1975). Continuous Time Markov Decision Processes with Average Return Criterion.Journal of Mathema" /><p class="c-article-references__text" id="ref-CR51">Kakumanu P. (1975). Continuous Time Markov Decision Processes with Average Return Criterion.<i>Journal of Mathematical Analysis and Applications</i> 52, 173–188.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2875%2990063-3" aria-label="View reference 51">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%20with%20Average%20Return%20Criterion&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=52&amp;pages=173-188&amp;publication_year=1975&amp;author=Kakumanu%2CP.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P.. Kakumanu, " /><meta itemprop="datePublished" content="1977" /><meta itemprop="headline" content="Kakumanu P. (1977). Relation Between Continuous and Discrete Markovian Decision Problems.Naval Research Logist" /><p class="c-article-references__text" id="ref-CR52">Kakumanu P. (1977). Relation Between Continuous and Discrete Markovian Decision Problems.<i>Naval Research Logistics Quarterly</i> 24, 431–439.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fnav.3800240306" aria-label="View reference 52">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Relation%20Between%20Continuous%20and%20Discrete%20Markovian%20Decision%20Problems&amp;journal=Naval%20Research%20Logistics%20Quarterly&amp;volume=24&amp;pages=431-439&amp;publication_year=1977&amp;author=Kakumanu%2CP.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kato T. (1966).Perturbation Theory for Linear Operators. Springer." /><p class="c-article-references__text" id="ref-CR53">Kato T. (1966).<i>Perturbation Theory for Linear Operators</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W.O.. Kermack, A.G.. McKendrick, " /><meta itemprop="datePublished" content="1927" /><meta itemprop="headline" content="Kermack W.O. and McKendrick A.G. (1927). Contributions to the Mathematical Theory of Epidemics.Proceedings of " /><p class="c-article-references__text" id="ref-CR54">Kermack W.O. and McKendrick A.G. (1927). Contributions to the Mathematical Theory of Epidemics.<i>Proceedings of the Royal Statistical Society</i> A115, 700–721.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Contributions%20to%20the%20Mathematical%20Theory%20of%20Epidemics&amp;journal=Proceedings%20of%20the%20Royal%20Statistical%20Society&amp;volume=115&amp;pages=700-721&amp;publication_year=1927&amp;author=Kermack%2CW.O.&amp;author=McKendrick%2CA.G.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.Yu.. Kitayev, " /><meta itemprop="datePublished" content="1985" /><meta itemprop="headline" content="Kitayev M.Yu. (1985). Semi-Markov and Jump Markov Controlled Models: Average Cost Criterion.Theory of Probabil" /><p class="c-article-references__text" id="ref-CR55">Kitayev M.Yu. (1985). Semi-Markov and Jump Markov Controlled Models: Average Cost Criterion.<i>Theory of Probability and its Applications</i> 30, 272–288.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F1130036" aria-label="View reference 55">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semi-Markov%20and%20Jump%20Markov%20Controlled%20Models%3A%20Average%20Cost%20Criterion&amp;journal=Theory%20of%20Probability%20and%20its%20Applications&amp;volume=30&amp;pages=272-288&amp;publication_year=1985&amp;author=Kitayev%2CM.Yu.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kitayev M.Yu. and Rykov V.V. (1995).Controlled Queueing Systems. CRC Press." /><p class="c-article-references__text" id="ref-CR56">Kitayev M.Yu. and Rykov V.V. (1995).<i>Controlled Queueing Systems</i>. CRC Press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J.B.. Lasserre, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Lasserre J.B. (1988). Conditions for the Existence of Average and Blackwell Optimal Stationary Policies in Den" /><p class="c-article-references__text" id="ref-CR57">Lasserre J.B. (1988). Conditions for the Existence of Average and Blackwell Optimal Stationary Policies in Denumerable Markov Decision Processes.<i>Journal of Mathematical Analysis and Applications</i> 136, 479–490.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2888%2990098-4" aria-label="View reference 57">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 57 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Conditions%20for%20the%20Existence%20of%20Average%20and%20Blackwell%20Optimal%20Stationary%20Policies%20in%20Denumerable%20Markov%20Decision%20Processes&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=136&amp;pages=479-490&amp;publication_year=1988&amp;author=Lasserre%2CJ.B.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C.. Lefèvre, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Lefèvre C. (1979). Optimal Control of the Simple Stochastic Epidemic with Variable Recovery Rates.Mathematical" /><p class="c-article-references__text" id="ref-CR58">Lefèvre C. (1979). Optimal Control of the Simple Stochastic Epidemic with Variable Recovery Rates.<i>Mathematical Biosciences</i> 44, 209–219.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0025-5564%2879%2990082-8" aria-label="View reference 58">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20Control%20of%20the%20Simple%20Stochastic%20Epidemic%20with%20Variable%20Recovery%20Rates&amp;journal=Mathematical%20Biosciences&amp;volume=44&amp;pages=209-219&amp;publication_year=1979&amp;author=Lef%C3%A8vre%2CC.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C.. Lefèvre, " /><meta itemprop="datePublished" content="1981" /><meta itemprop="headline" content="Lefèvre C. (1981). Optimal Control of a Birth and Death Epidemic Process.Operations Research 29, 971–982." /><p class="c-article-references__text" id="ref-CR59">Lefèvre C. (1981). Optimal Control of a Birth and Death Epidemic Process.<i>Operations Research</i> 29, 971–982.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20Control%20of%20a%20Birth%20and%20Death%20Epidemic%20Process&amp;journal=Operations%20Research&amp;volume=29&amp;pages=971-982&amp;publication_year=1981&amp;author=Lef%C3%A8vre%2CC.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.. Leizarowitz, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Leizarowitz A. (1996). Overtaking and Almost-Sure Optimality for Infinite Horizon Markov Decision Processes.Ma" /><p class="c-article-references__text" id="ref-CR60">Leizarowitz A. (1996). Overtaking and Almost-Sure Optimality for Infinite Horizon Markov Decision Processes.<i>Mathematics of Operations Research</i> 21, 158–181.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1287%2Fmoor.21.1.158" aria-label="View reference 60">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 60 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Overtaking%20and%20Almost-Sure%20Optimality%20for%20Infinite%20Horizon%20Markov%20Decision%20Processes&amp;journal=Mathematics%20of%20Operations%20Research&amp;volume=21&amp;pages=158-181&amp;publication_year=1996&amp;author=Leizarowitz%2CA.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.R.. Lembersky, " /><meta itemprop="datePublished" content="1974" /><meta itemprop="headline" content="Lembersky M.R. (1974). On Maximal Rewards and ∈-Optimal Policies in Continuous Time Markov Chains.Annals of St" /><p class="c-article-references__text" id="ref-CR61">Lembersky M.R. (1974). On Maximal Rewards and ∈-Optimal Policies in Continuous Time Markov Chains.<i>Annals of Statistics</i> 2, 159–169.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176342621" aria-label="View reference 61">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 61 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20Maximal%20Rewards%20and%20%E2%88%88-Optimal%20Policies%20in%20Continuous%20Time%20Markov%20Chains&amp;journal=Annals%20of%20Statistics&amp;volume=2&amp;pages=159-169&amp;publication_year=1974&amp;author=Lembersky%2CM.R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, H.. Ayhan, R.D.. Foley, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Lewis M.E., Ayhan H. and Foley R.D. (1999). Bias Optimality in a Queue with Admission Control.Probability in t" /><p class="c-article-references__text" id="ref-CR62">Lewis M.E., Ayhan H. and Foley R.D. (1999). Bias Optimality in a Queue with Admission Control.<i>Probability in the Engineering and Informational Sciences</i> 13, 309–327.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1017%2FS0269964899133047" aria-label="View reference 62">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20in%20a%20Queue%20with%20Admission%20Control&amp;journal=Probability%20in%20the%20Engineering%20and%20Informational%20Sciences&amp;volume=13&amp;pages=309-327&amp;publication_year=1999&amp;author=Lewis%2CM.E.&amp;author=Ayhan%2CH.&amp;author=Foley%2CR.D.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, H.. Ayhan, R.D.. Foley, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Lewis M.E., Ayhan H. and Foley R.D. (2002). Bias Optimal Admission Policies for a Noustationary Multiclass Que" /><p class="c-article-references__text" id="ref-CR63">Lewis M.E., Ayhan H. and Foley R.D. (2002). Bias Optimal Admission Policies for a Noustationary Multiclass Queueing System.<i>Journal of Applied Probability</i> 39, 20–37.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1019737985" aria-label="View reference 63">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 63 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimal%20Admission%20Policies%20for%20a%20Noustationary%20Multiclass%20Queueing%20System&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=39&amp;pages=20-37&amp;publication_year=2002&amp;author=Lewis%2CM.E.&amp;author=Ayhan%2CH.&amp;author=Foley%2CR.D.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, M.L.. Puterman, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Lewis M.E. and Puterman M.L. (2001). A Note on Bias Optimality in Controlled Queueing Systems.Journal of Appli" /><p class="c-article-references__text" id="ref-CR64">Lewis M.E. and Puterman M.L. (2001). A Note on Bias Optimality in Controlled Queueing Systems.<i>Journal of Applied Probability</i> 37, 300–305.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 64 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Note%20on%20Bias%20Optimality%20in%20Controlled%20Queueing%20Systems&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=37&amp;pages=300-305&amp;publication_year=2001&amp;author=Lewis%2CM.E.&amp;author=Puterman%2CM.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, M.L.. Puterman, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Lewis M.E. and Puterman M.L. (2002). A Probabilistic Analysis of Bias Optimality in Unichain Markov Decision P" /><p class="c-article-references__text" id="ref-CR65">Lewis M.E. and Puterman M.L. (2002). A Probabilistic Analysis of Bias Optimality in Unichain Markov Decision Processes.<i>IEEE Transactions on Automatic Control</i> 46, 96–100.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2F9.898698" aria-label="View reference 65">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 65 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Probabilistic%20Analysis%20of%20Bias%20Optimality%20in%20Unichain%20Markov%20Decision%20Processes&amp;journal=IEEE%20Transactions%20on%20Automatic%20Control&amp;volume=46&amp;pages=96-100&amp;publication_year=2002&amp;author=Lewis%2CM.E.&amp;author=Puterman%2CM.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S.A.. Lippman, " /><meta itemprop="datePublished" content="1975" /><meta itemprop="headline" content="Lippman S.A. (1975). Applying a New Device in the Optimization of Exponential Queueing Systems.Operations Rese" /><p class="c-article-references__text" id="ref-CR66">Lippman S.A. (1975). Applying a New Device in the Optimization of Exponential Queueing Systems.<i>Operations Research</i> 23, 667–710.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 66 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Applying%20a%20New%20Device%20in%20the%20Optimization%20of%20Exponential%20Queueing%20Systems&amp;journal=Operations%20Research&amp;volume=23&amp;pages=667-710&amp;publication_year=1975&amp;author=Lippman%2CS.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R.B.. Lund, S.P.. Meyn, R.L.. Tweedie, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Lund R.B., Meyn S.P. and Tweedie R.L. (1996). Computable Exponential Convergence Rates for Stochastically Orde" /><p class="c-article-references__text" id="ref-CR67">Lund R.B., Meyn S.P. and Tweedie R.L. (1996). Computable Exponential Convergence Rates for Stochastically Ordered Markov Processes.<i>Annals of Applied Probability</i> 6, 218–237.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoap%2F1034968072" aria-label="View reference 67">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 67 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computable%20Exponential%20Convergence%20Rates%20for%20Stochastically%20Ordered%20Markov%20Processes&amp;journal=Annals%20of%20Applied%20Probability&amp;volume=6&amp;pages=218-237&amp;publication_year=1996&amp;author=Lund%2CR.B.&amp;author=Meyn%2CS.P.&amp;author=Tweedie%2CR.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mangel M. (1985).Decision and Control in Uncertain Resource Systems. Academic Press." /><p class="c-article-references__text" id="ref-CR68">Mangel M. (1985).<i>Decision and Control in Uncertain Resource Systems</i>. Academic Press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Massy W.F., Montgomery D.B. and Morrison D.G. (1970).Stochastic Models of Buying Behavior. MIT Press." /><p class="c-article-references__text" id="ref-CR69">Massy W.F., Montgomery D.B. and Morrison D.G. (1970).<i>Stochastic Models of Buying Behavior</i>. MIT Press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S.P.. Meyn, R.L.. Tweedie, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Meyn S.P. and Tweedie R.L. (1993). Stability of Markovian Processes III: Foster-Lyapunov Criteria for Continuo" /><p class="c-article-references__text" id="ref-CR70">Meyn S.P. and Tweedie R.L. (1993). Stability of Markovian Processes III: Foster-Lyapunov Criteria for Continuous-Time Processes.<i>Advances in Applied Probability</i>, 25, 518–548.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.2307%2F1427522" aria-label="View reference 70">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 70 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stability%20of%20Markovian%20Processes%20III%3A%20Foster-Lyapunov%20Criteria%20for%20Continuous-Time%20Processes&amp;journal=Advances%20in%20Applied%20Probability&amp;volume=25&amp;pages=518-548&amp;publication_year=1993&amp;author=Meyn%2CS.P.&amp;author=Tweedie%2CR.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B.L.. Miller, " /><meta itemprop="datePublished" content="1968" /><meta itemprop="headline" content="Miller B.L. (1968). Finite State Continuous Time Markov Decision Processes with an Infinite Planning Horizon.J" /><p class="c-article-references__text" id="ref-CR71">Miller B.L. (1968). Finite State Continuous Time Markov Decision Processes with an Infinite Planning Horizon.<i>Journal of Mathematical Analysis and Applications</i> 22, 552–569.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2868%2990194-7" aria-label="View reference 71">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 71 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Finite%20State%20Continuous%20Time%20Markov%20Decision%20Processes%20with%20an%20Infinite%20Planning%20Horizon&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=22&amp;pages=552-569&amp;publication_year=1968&amp;author=Miller%2CB.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B.L.. Miller, A.F.. Veinott, " /><meta itemprop="datePublished" content="1969" /><meta itemprop="headline" content="Miller B.L. and Veinott A.F. (1969). Discrete Dynamic Programming with a Small Interest Rate.Annals of Mathema" /><p class="c-article-references__text" id="ref-CR72">Miller B.L. and Veinott A.F. (1969). Discrete Dynamic Programming with a Small Interest Rate.<i>Annals of Mathematical Statistics</i> 40, 366–370.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177697700" aria-label="View reference 72">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 72 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discrete%20Dynamic%20Programming%20with%20a%20Small%20Interest%20Rate&amp;journal=Annals%20of%20Mathematical%20Statistics&amp;volume=40&amp;pages=366-370&amp;publication_year=1969&amp;author=Miller%2CB.L.&amp;author=Veinott%2CA.F.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.B.. Piunovskii, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Piunovskii A.B. (1998). A Controlled Jump Discounted Model with Constraints.Theory of Probability and Its Appl" /><p class="c-article-references__text" id="ref-CR73">Piunovskii A.B. (1998). A Controlled Jump Discounted Model with Constraints.<i>Theory of Probability and Its Applications</i> 42, 51–72.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2FS0040585X97975964" aria-label="View reference 73">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 73 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Controlled%20Jump%20Discounted%20Model%20with%20Constraints&amp;journal=Theory%20of%20Probability%20and%20Its%20Applications&amp;volume=42&amp;pages=51-72&amp;publication_year=1998&amp;author=Piunovskii%2CA.B.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.B.. Piunovskii, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Piunovskii A.B. (2004). Multicriteria Impulsive Control of Jump Markov Processes.Mathematical Methods of Opera" /><p class="c-article-references__text" id="ref-CR74">Piunovskii A.B. (2004). Multicriteria Impulsive Control of Jump Markov Processes.<i>Mathematical Methods of Operations Research</i> 60, 125–144.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 74 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multicriteria%20Impulsive%20Control%20of%20Jump%20Markov%20Processes&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=60&amp;pages=125-144&amp;publication_year=2004&amp;author=Piunovskii%2CA.B.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T.. Prieto-Rumeau, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Prieto-Rumeau T. (2006). Blackwell Optimality in the Class of Markov Policies for Continuous-Time Controlled M" /><p class="c-article-references__text" id="ref-CR75">Prieto-Rumeau T. (2006). Blackwell Optimality in the Class of Markov Policies for Continuous-Time Controlled Markov Chains.<i>Acta Applicandae Mathematicae</i> 92, 77–96.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs10440-006-9060-3" aria-label="View reference 75">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 75 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Blackwell%20Optimality%20in%20the%20Class%20of%20Markov%20Policies%20for%20Continuous-Time%20Controlled%20Markov%20Chains&amp;journal=Acta%20Applicandae%20Mathematicae&amp;volume=92&amp;pages=77-96&amp;publication_year=2006&amp;author=Prieto-Rumeau%2CT.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T.. Prieto-Rumeau, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O. (2005a). The Laurent Series, Sensitive Discount and Blackwell Optimali" /><p class="c-article-references__text" id="ref-CR76">Prieto-Rumeau T. and Hernández-Lerma O. (2005a). The Laurent Series, Sensitive Discount and Blackwell Optimality for Continuous-Time Controlled Markov Chains.<i>Mathematical Methods of Operations Research</i> 61, 123–145.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs001860400393" aria-label="View reference 76">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 76 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Laurent%20Series%2C%20Sensitive%20Discount%20and%20Blackwell%20Optimality%20for%20Continuous-Time%20Controlled%20Markov%20Chains&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=61&amp;pages=123-145&amp;publication_year=2005&amp;author=Prieto-Rumeau%2CT.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T.. Prieto-Rumeau, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O. (2005b). Bias and Overtaking Equilibria for Zero-Sum Continuous-Time M" /><p class="c-article-references__text" id="ref-CR77">Prieto-Rumeau T. and Hernández-Lerma O. (2005b). Bias and Overtaking Equilibria for Zero-Sum Continuous-Time Markov Games.<i>Mathematical Methods of Operations Research</i> 61, 437–454.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs001860400392" aria-label="View reference 77">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 77 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20and%20Overtaking%20Equilibria%20for%20Zero-Sum%20Continuous-Time%20Markov%20Games&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=61&amp;pages=437-454&amp;publication_year=2005&amp;author=Prieto-Rumeau%2CT.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T.. Prieto-Rumeau, O.. Hernández-Lerma, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O. (2006a). Bias Optimality for Continuous-Time Controlled Markov Chains." /><p class="c-article-references__text" id="ref-CR78">Prieto-Rumeau T. and Hernández-Lerma O. (2006a). Bias Optimality for Continuous-Time Controlled Markov Chains.<i>SIAM Journal on Control and Optimization</i> 45, 51–73.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2FS036301290343432" aria-label="View reference 78">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 78 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20for%20Continuous-Time%20Controlled%20Markov%20Chains&amp;journal=SIAM%20Journal%20on%20Control%20and%20Optimization&amp;volume=45&amp;pages=51-73&amp;publication_year=2006&amp;author=Prieto-Rumeau%2CT.&amp;author=Hern%C3%A1ndez-Lerma%2CO.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O (2006b). A Unified Approach to Continuous-Time Discounted Markov Contro" /><p class="c-article-references__text" id="ref-CR79">Prieto-Rumeau T. and Hernández-Lerma O (2006b). A Unified Approach to Continuous-Time Discounted Markov Control Processes.<i>Morfismos 10</i> (to appear).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O. (2006c). Ergodic Control of Continuous-Time Markov Chains with Pathwis" /><p class="c-article-references__text" id="ref-CR80">Prieto-Rumeau T. and Hernández-Lerma O. (2006c). Ergodic Control of Continuous-Time Markov Chains with Pathwise Constraints. Preprint.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Prieto-Rumeau T. and Hernández-Lerma O. (2006d). Variance Minimization and the Overtaking Optimality Approach " /><p class="c-article-references__text" id="ref-CR81">Prieto-Rumeau T. and Hernández-Lerma O. (2006d). Variance Minimization and the Overtaking Optimality Approach to Continuous-Time Markov Control Chains. Preprint.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.L.. Puterman, " /><meta itemprop="datePublished" content="1974" /><meta itemprop="headline" content="Puterman M.L. (1974). Sensitive Discount Optimality in Controlled One-Dimensional Diffusions.Annals of Probabi" /><p class="c-article-references__text" id="ref-CR82">Puterman M.L. (1974). Sensitive Discount Optimality in Controlled One-Dimensional Diffusions.<i>Annals of Probability</i> 2, 408–419.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faop%2F1176996656" aria-label="View reference 82">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 82 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensitive%20Discount%20Optimality%20in%20Controlled%20One-Dimensional%20Diffusions&amp;journal=Annals%20of%20Probability&amp;volume=2&amp;pages=408-419&amp;publication_year=1974&amp;author=Puterman%2CM.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Puterman M.L. (1994).Markov Decision Processes. Wiley." /><p class="c-article-references__text" id="ref-CR83">Puterman M.L. (1994).<i>Markov Decision Processes</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Qiu, Q.. Wu, M.. Pedram, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Qiu Q., Wu Q. and Pedram M. (2001). Stochastic Modeling of a Power-Managed System: Construction and Optimizati" /><p class="c-article-references__text" id="ref-CR84">Qiu Q., Wu Q. and Pedram M. (2001). Stochastic Modeling of a Power-Managed System: Construction and Optimization.<i>IEEE Transactions on Computer Aided Design</i> 20, 1200–1217.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2F43.952737" aria-label="View reference 84">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 84 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stochastic%20Modeling%20of%20a%20Power-Managed%20System%3A%20Construction%20and%20Optimization&amp;journal=IEEE%20Transactions%20on%20Computer%20Aided%20Design&amp;volume=20&amp;pages=1200-1217&amp;publication_year=2001&amp;author=Qiu%2CQ.&amp;author=Wu%2CQ.&amp;author=Pedram%2CM.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F.P.. Ramsey, " /><meta itemprop="datePublished" content="1928" /><meta itemprop="headline" content="Ramsey F.P. (1928). A Mathematical Theory of Savings.Econometrics Journal 38, 543–559." /><p class="c-article-references__text" id="ref-CR85">Ramsey F.P. (1928). A Mathematical Theory of Savings.<i>Econometrics Journal</i> 38, 543–559.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 85 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Mathematical%20Theory%20of%20Savings&amp;journal=Econometrics%20Journal&amp;volume=38&amp;pages=543-559&amp;publication_year=1928&amp;author=Ramsey%2CF.P.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ross S.M. (1970).Applied Probability Models with Optimization Applications. Holden-Day." /><p class="c-article-references__text" id="ref-CR86">Ross S.M. (1970).<i>Applied Probability Models with Optimization Applications</i>. Holden-Day.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V.V.. Roykov, " /><meta itemprop="datePublished" content="1966" /><meta itemprop="headline" content="Roykov V.V. (1966). Markov Sequential Decision Processes with Finite State and Decision Space.Theory of Probab" /><p class="c-article-references__text" id="ref-CR87">Roykov V.V. (1966). Markov Sequential Decision Processes with Finite State and Decision Space.<i>Theory of Probability and Its Applications</i>, 11, 302–311.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F1111027" aria-label="View reference 87">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 87 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Markov%20Sequential%20Decision%20Processes%20with%20Finite%20State%20and%20Decision%20Space&amp;journal=Theory%20of%20Probability%20and%20Its%20Applications&amp;volume=11&amp;pages=302-311&amp;publication_year=1966&amp;author=Roykov%2CV.V.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.. Schäl, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Schäl M. (1992). On the Second Optimality Equation for Semi-Markov Decision Models.Mathematics of Operations R" /><p class="c-article-references__text" id="ref-CR88">Schäl M. (1992). On the Second Optimality Equation for Semi-Markov Decision Models.<i>Mathematics of Operations Research</i> 17, 470–486.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1287%2Fmoor.17.2.470" aria-label="View reference 88">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 88 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20Second%20Optimality%20Equation%20for%20Semi-Markov%20Decision%20Models&amp;journal=Mathematics%20of%20Operations%20Research&amp;volume=17&amp;pages=470-486&amp;publication_year=1992&amp;author=Sch%C3%A4l%2CM.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sennott L.I. (1999).Stochastic Dynamic Programming and the Control of Queueing Systems. Wiley." /><p class="c-article-references__text" id="ref-CR89">Sennott L.I. (1999).<i>Stochastic Dynamic Programming and the Control of Queueing Systems</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R.F.. Serfozo, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Serfozo R.F. (1979). An Equivalence Between Continuous and Discrete Time Markov Decision Processes.Operations " /><p class="c-article-references__text" id="ref-CR90">Serfozo R.F. (1979). An Equivalence Between Continuous and Discrete Time Markov Decision Processes.<i>Operations Research</i> 27, 616–620.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 90 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20Equivalence%20Between%20Continuous%20and%20Discrete%20Time%20Markov%20Decision%20Processes&amp;journal=Operations%20Research&amp;volume=27&amp;pages=616-620&amp;publication_year=1979&amp;author=Serfozo%2CR.F.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K.. Sladký, " /><meta itemprop="datePublished" content="1978" /><meta itemprop="headline" content="Sladký K. (1978). Sensitive Optimality Criteria for Continuous Time Markov Processes.Transactions of the Eight" /><p class="c-article-references__text" id="ref-CR91">Sladký K. (1978). Sensitive Optimality Criteria for Continuous Time Markov Processes.<i>Transactions of the Eighth Prague Conference on Information Theory Statistical Decision Functions and Random Processes (Prague, 1978)</i>, Vol. B, 221–225.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 91 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensitive%20Optimality%20Criteria%20for%20Continuous%20Time%20Markov%20Processes&amp;journal=Transactions%20of%20the%20Eighth%20Prague%20Conference%20on%20Information%20Theory%20Statistical%20Decision%20Functions%20and%20Random%20Processes%20%28Prague%2C%201978%29&amp;volume=B&amp;pages=221-225&amp;publication_year=1978&amp;author=Sladk%C3%BD%2CK.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J.S.. Song, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Song, J.S. (1987). Continuous-Time Markov Decision Programming with Non-Uniformly Bounded Transition Rates.Sci" /><p class="c-article-references__text" id="ref-CR92">Song, J.S. (1987). Continuous-Time Markov Decision Programming with Non-Uniformly Bounded Transition Rates.<i>Scientia Sinica</i> 12, 1258–1267. (in Chinese).</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 92 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous-Time%20Markov%20Decision%20Programming%20with%20Non-Uniformly%20Bounded%20Transition%20Rates&amp;journal=Scientia%20Sinica&amp;volume=12&amp;pages=1258-1267&amp;publication_year=1987&amp;author=Song%2CJ.S.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Tadj, G.. Choudhury, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Tadj L and Choudhury G. (2005). Optimal Design and Control of Queues.Top 13, 359–412." /><p class="c-article-references__text" id="ref-CR93">Tadj L and Choudhury G. (2005). Optimal Design and Control of Queues.<i>Top</i> 13, 359–412.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2FBF02579061" aria-label="View reference 93">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 93 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20Design%20and%20Control%20of%20Queues&amp;journal=TOP&amp;volume=13&amp;pages=359-412&amp;publication_year=2005&amp;author=Tadj%2CL&amp;author=Choudhury%2CG.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H.M.. Taylor, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Taylor H.M. (1976). A Laurent Series for the Resolvent of a Strongly Continuous Stochastic Semi-Group.Mathemat" /><p class="c-article-references__text" id="ref-CR94">Taylor H.M. (1976). A Laurent Series for the Resolvent of a Strongly Continuous Stochastic Semi-Group.<i>Mathematical Programming Study</i> 6, 258–263.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 94 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Laurent%20Series%20for%20the%20Resolvent%20of%20a%20Strongly%20Continuous%20Stochastic%20Semi-Group&amp;journal=Mathematical%20Programming%20Study&amp;volume=6&amp;pages=258-263&amp;publication_year=1976&amp;author=Taylor%2CH.M.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.F.. Veinott, " /><meta itemprop="datePublished" content="1966" /><meta itemprop="headline" content="Veinott A.F. (1966). On Finding Optimal Policies in Discrete Dynamic Programming with no Discounting.annals of" /><p class="c-article-references__text" id="ref-CR95">Veinott A.F. (1966). On Finding Optimal Policies in Discrete Dynamic Programming with no Discounting.<i>annals of Mathematical Statistics</i> 37, 1284–1294.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177699272" aria-label="View reference 95">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 95 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20Finding%20Optimal%20Policies%20in%20Discrete%20Dynamic%20Programming%20with%20no%20Discounting&amp;journal=annals%20of%20Mathematical%20Statistics&amp;volume=37&amp;pages=1284-1294&amp;publication_year=1966&amp;author=Veinott%2CA.F.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.F.. Veinott, " /><meta itemprop="datePublished" content="1969" /><meta itemprop="headline" content="Veinott A.F. (1969). Discrete Dynamic Programming with Sensitive Discount Optimality Criteria.Annals of Mathem" /><p class="c-article-references__text" id="ref-CR96">Veinott A.F. (1969). Discrete Dynamic Programming with Sensitive Discount Optimality Criteria.<i>Annals of Mathematical Statistics</i> 40, 1635–1660.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177697379" aria-label="View reference 96">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 96 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discrete%20Dynamic%20Programming%20with%20Sensitive%20Discount%20Optimality%20Criteria&amp;journal=Annals%20of%20Mathematical%20Statistics&amp;volume=40&amp;pages=1635-1660&amp;publication_year=1969&amp;author=Veinott%2CA.F.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.L. Vidale, H.B.. Wolfe, " /><meta itemprop="datePublished" content="1957" /><meta itemprop="headline" content="Vidale M.L and Wolfe H.B. (1957). An Operations Research Study of Sales Response to Advertising.Operations Res" /><p class="c-article-references__text" id="ref-CR97">Vidale M.L and Wolfe H.B. (1957). An Operations Research Study of Sales Response to Advertising.<i>Operations Research</i> 5, 370–381.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 97 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20Operations%20Research%20Study%20of%20Sales%20Response%20to%20Advertising&amp;journal=Operations%20Research&amp;volume=5&amp;pages=370-381&amp;publication_year=1957&amp;author=Vidale%2CM.L&amp;author=Wolfe%2CH.B.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C.C.. Weizsäcker, " /><meta itemprop="datePublished" content="1965" /><meta itemprop="headline" content="von Weizsäcker C.C. (1965). Existence of Optimal Programs of Accumulation for an Infinite Horizon.Review of Ec" /><p class="c-article-references__text" id="ref-CR98">von Weizsäcker C.C. (1965). Existence of Optimal Programs of Accumulation for an Infinite Horizon.<i>Review of Economic Studies</i> 32, 85–104.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.2307%2F2296054" aria-label="View reference 98">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 98 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Existence%20of%20Optimal%20Programs%20of%20Accumulation%20for%20an%20Infinite%20Horizon&amp;journal=Review%20of%20Economic%20Studies&amp;volume=32&amp;pages=85-104&amp;publication_year=1965&amp;author=Weizs%C3%A4cker%2CC.C.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K.. Wickwire, " /><meta itemprop="datePublished" content="1977" /><meta itemprop="headline" content="Wickwire K. (1977). Mathematical Models for the Control of Pests and Infectious Diseases: A Survey.Theoretical" /><p class="c-article-references__text" id="ref-CR99">Wickwire K. (1977). Mathematical Models for the Control of Pests and Infectious Diseases: A Survey.<i>Theoretical Population Biology</i> 11, 182–238.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0040-5809%2877%2990025-9" aria-label="View reference 99">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 99 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mathematical%20Models%20for%20the%20Control%20of%20Pests%20and%20Infectious%20Diseases%3A%20A%20Survey&amp;journal=Theoretical%20Population%20Biology&amp;volume=11&amp;pages=182-238&amp;publication_year=1977&amp;author=Wickwire%2CK.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C.B.. Wu, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Wu C.B. (1997). Continuous Time Markov Decision Processes with Unbounded Reward and Non-Uniformly Bounded Tran" /><p class="c-article-references__text" id="ref-CR100">Wu C.B. (1997). Continuous Time Markov Decision Processes with Unbounded Reward and Non-Uniformly Bounded Transition Rate Under Discounted Criterion.<i>Acta Mathematicae Applicandae Sinica</i> 20, 196–208.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 100 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%20with%20Unbounded%20Reward%20and%20Non-Uniformly%20Bounded%20Transition%20Rate%20Under%20Discounted%20Criterion&amp;journal=Acta%20Mathematicae%20Applicandae%20Sinica&amp;volume=20&amp;pages=196-208&amp;publication_year=1997&amp;author=Wu%2CC.B.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ye L., Guo X.P. and Hernández-Lerma O. (2006). Existence and Regularity of NonhomogeneousQ(t)-Processes under " /><p class="c-article-references__text" id="ref-CR101">Ye L., Guo X.P. and Hernández-Lerma O. (2006). Existence and Regularity of Nonhomogeneous<i>Q(t)</i>-Processes under Measurability Conditions. Preprint.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yosida K. (1980).Functional Analysis, Sixth Edition. Springer." /><p class="c-article-references__text" id="ref-CR102">Yosida K. (1980).<i>Functional Analysis, Sixth Edition</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1973" /><meta itemprop="headline" content="Yushkevich A.A. (1973). On a Class of Strategies in General Markov Decision Models.Theory of Probability and I" /><p class="c-article-references__text" id="ref-CR103">Yushkevich A.A. (1973). On a Class of Strategies in General Markov Decision Models.<i>Theory of Probability and Its Applications</i> 18, 777–779.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F1118099" aria-label="View reference 103">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 103 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20a%20Class%20of%20Strategies%20in%20General%20Markov%20Decision%20Models&amp;journal=Theory%20of%20Probability%20and%20Its%20Applications&amp;volume=18&amp;pages=777-779&amp;publication_year=1973&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1977" /><meta itemprop="headline" content="Yushkevich A.A. (1977). Controlled Markov Models with Countable State and Continuous Time.Theory of Probabilit" /><p class="c-article-references__text" id="ref-CR104">Yushkevich A.A. (1977). Controlled Markov Models with Countable State and Continuous Time.<i>Theory of Probability and its Applications</i> 22, 215–235.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F1122029" aria-label="View reference 104">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 104 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Controlled%20Markov%20Models%20with%20Countable%20State%20and%20Continuous%20Time&amp;journal=Theory%20of%20Probability%20and%20its%20Applications&amp;volume=22&amp;pages=215-235&amp;publication_year=1977&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Yushkevich A.A. (1994). Blackwell Optimal Policies in a Markov Decision Process with a Borel State Space.Mathe" /><p class="c-article-references__text" id="ref-CR105">Yushkevich A.A. (1994). Blackwell Optimal Policies in a Markov Decision Process with a Borel State Space.<i>Mathematical Methods of Operations Research</i> 40, 253–288.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2FBF01432969" aria-label="View reference 105">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 105 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Blackwell%20Optimal%20Policies%20in%20a%20Markov%20Decision%20Process%20with%20a%20Borel%20State%20Space&amp;journal=Mathematical%20Methods%20of%20Operations%20Research&amp;volume=40&amp;pages=253-288&amp;publication_year=1994&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.A.. Yushkevich, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Yushkevich A.A. (1997). Blackwell Optimality in Continuous in Action Markov Decision Processes.SIAM Journal on" /><p class="c-article-references__text" id="ref-CR106">Yushkevich A.A. (1997). Blackwell Optimality in Continuous in Action Markov Decision Processes.<i>SIAM Journal on Control and Optimization</i> 35, 2157–2182.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2FS0363012995292469" aria-label="View reference 106">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 106 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Blackwell%20Optimality%20in%20Continuous%20in%20Action%20Markov%20Decision%20Processes&amp;journal=SIAM%20Journal%20on%20Control%20and%20Optimization&amp;volume=35&amp;pages=2157-2182&amp;publication_year=1997&amp;author=Yushkevich%2CA.A.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A.A.. Yushkevich, E.A.. Feinberg, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Yushkevich A.A. and Feinberg E.A. (1979). On Homogeneous Markov Model with Continuous Time and Finite or Count" /><p class="c-article-references__text" id="ref-CR107">Yushkevich A.A. and Feinberg E.A. (1979). On Homogeneous Markov Model with Continuous Time and Finite or Countable State Space.<i>Theory of Probability and its Applications</i> 24, 156–161.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F1124014" aria-label="View reference 107">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 107 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20Homogeneous%20Markov%20Model%20with%20Continuous%20Time%20and%20Finite%20or%20Countable%20State%20Space&amp;journal=Theory%20of%20Probability%20and%20its%20Applications&amp;volume=24&amp;pages=156-161&amp;publication_year=1979&amp;author=Yushkevich%2CA.A.&amp;author=Feinberg%2CE.A.">
                        Google Scholar</a></li></ul></li></ol><h3 class="c-article-references__heading u-h3">References</h3><ol class="c-article-references" data-test="references-list-section"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J.. Bather, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Bather J. (1976). Optimal Stationary Policies for Denumerable Markov Chains in Continuous Time.Advances in App" /><p class="c-article-references__text" id="ref-CR108">Bather J. (1976). Optimal Stationary Policies for Denumerable Markov Chains in Continuous Time.<i>Advances in Applied Probability</i> 8, 148–155.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20Stationary%20Policies%20for%20Denumerable%20Markov%20Chains%20in%20Continuous%20Time&amp;journal=Advances%20in%20Applied%20Probability&amp;volume=8&amp;pages=148-155&amp;publication_year=1976&amp;author=Bather%2CJ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.-R.. Cao, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Cao X.-R. (2003a). Semi-Markov Decision Problems and Performance Sensitivity Analysis.IEEE Transactions on Aut" /><p class="c-article-references__text" id="ref-CR109">Cao X.-R. (2003a). Semi-Markov Decision Problems and Performance Sensitivity Analysis.<i>IEEE Transactions on Automatic Control</i> 48, 758–769.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTAC.2003.811252" aria-label="View reference 2">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semi-Markov%20Decision%20Problems%20and%20Performance%20Sensitivity%20Analysis&amp;journal=IEEE%20Transactions%20on%20Automatic%20Control&amp;volume=48&amp;pages=758-769&amp;publication_year=2003&amp;author=Cao%2CX.-R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cao X.-R. (2003b) A Sensitivity View of Markov Decision Processes and Reinforcement Learning. In: Gong W. and " /><p class="c-article-references__text" id="ref-CR110">Cao X.-R. (2003b) A Sensitivity View of Markov Decision Processes and Reinforcement Learning. In: Gong W. and Shi L. (eds.),<i>Modeling, Control and Optimization of Complex systems</i>, Kluwer, 261–283.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.-R.. Cao, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Cao X.-R. (2003c). From Perturbation Analysis to Markov Decision Processes and Reinforcement Learning.Discrete" /><p class="c-article-references__text" id="ref-CR111">Cao X.-R. (2003c). From Perturbation Analysis to Markov Decision Processes and Reinforcement Learning.<i>Discrete Event Dynamic Systems</i> 13, 9–39.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1022188803039" aria-label="View reference 4">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20Perturbation%20Analysis%20to%20Markov%20Decision%20Processes%20and%20Reinforcement%20Learning&amp;journal=Discrete%20Event%20Dynamic%20Systems&amp;volume=13&amp;pages=9-39&amp;publication_year=2003&amp;author=Cao%2CX.-R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.-R.. Cao, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Cao X.-R. (2004). The Potential Structure of Sample Paths and Performance Sensitivities of Markov Systems.IEEE" /><p class="c-article-references__text" id="ref-CR112">Cao X.-R. (2004). The Potential Structure of Sample Paths and Performance Sensitivities of Markov Systems.<i>IEEE Transactions on Automatic Control</i> 49, 2129–2142.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTAC.2004.838494" aria-label="View reference 5">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Potential%20Structure%20of%20Sample%20Paths%20and%20Performance%20Sensitivities%20of%20Markov%20Systems&amp;journal=IEEE%20Transactions%20on%20Automatic%20Control&amp;volume=49&amp;pages=2129-2142&amp;publication_year=2004&amp;author=Cao%2CX.-R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X.-R.. Cao, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Cao X.-R. (2005). Basic Ideas for Event-Based Optimality of Markov Systems.Discrete Event Dynamic Systems: The" /><p class="c-article-references__text" id="ref-CR113">Cao X.-R. (2005). Basic Ideas for Event-Based Optimality of Markov Systems.<i>Discrete Event Dynamic Systems: Theory and Applications</i> 15, 169–197.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs10626-004-6211-4" aria-label="View reference 6">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Basic%20Ideas%20for%20Event-Based%20Optimality%20of%20Markov%20Systems&amp;journal=Discrete%20Event%20Dynamic%20Systems%3A%20Theory%20and%20Applications&amp;volume=15&amp;pages=169-197&amp;publication_year=2005&amp;author=Cao%2CX.-R.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cao X.-R. and Zhang J.Y. (2007). Thenth-Order Bias Optimality for Multichain Markov Decision Process.IEEE Tran" /><p class="c-article-references__text" id="ref-CR114">Cao X.-R. and Zhang J.Y. (2007). The<i>n</i>th-Order Bias Optimality for Multichain Markov Decision Process.<i>IEEE Transactions on Automatic Control</i> (to appear).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dijk N.V. (1993).Queueing Networks and Product Forms: A System Approach. Wiley." /><p class="c-article-references__text" id="ref-CR115">Dijk N.V. (1993).<i>Queueing Networks and Product Forms: A System Approach</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dynkin E.B. and Yushkevich A.A. (1979).Controlled markov Processes. Springer." /><p class="c-article-references__text" id="ref-CR116">Dynkin E.B. and Yushkevich A.A. (1979).<i>Controlled markov Processes</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Puterman M.L. (1994).Markov Decision Processes. Wiley." /><p class="c-article-references__text" id="ref-CR117">Puterman M.L. (1994).<i>Markov Decision Processes</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sennott L.I. (1999).Stochastic Dynamic Programming and the Control of Queueing Systems. Wiley." /><p class="c-article-references__text" id="ref-CR118">Sennott L.I. (1999).<i>Stochastic Dynamic Programming and the Control of Queueing Systems</i>. Wiley.</p></li></ol><h3 class="c-article-references__heading u-h3">References</h3><ol class="c-article-references" data-test="references-list-section"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Hu Q. (1990). CTMDP and Its Relationship with DTMDP.Chinese Science Bulletin 35, 710–714." /><p class="c-article-references__text" id="ref-CR119">Hu Q. (1990). CTMDP and Its Relationship with DTMDP.<i>Chinese Science Bulletin</i> 35, 710–714.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=CTMDP%20and%20Its%20Relationship%20with%20DTMDP&amp;journal=Chinese%20Science%20Bulletin&amp;volume=35&amp;pages=710-714&amp;publication_year=1990&amp;author=Hu%2CQ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Hu Q. (1992). Discounted and Average Markov Decision Processes with Unbounded Rewards: New Conditions.Journal " /><p class="c-article-references__text" id="ref-CR120">Hu Q. (1992). Discounted and Average Markov Decision Processes with Unbounded Rewards: New Conditions.<i>Journal of Mathematical Analysis and Applications</i> 171, 111–124.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2892%2990379-R" aria-label="View reference 2">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discounted%20and%20Average%20Markov%20Decision%20Processes%20with%20Unbounded%20Rewards%3A%20New%20Conditions&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=171&amp;pages=111-124&amp;publication_year=1992&amp;author=Hu%2CQ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Hu Q. (1996). Continuous Time Markov Decision Processes with Discounted Moment Criterion.Journal of Mathematic" /><p class="c-article-references__text" id="ref-CR121">Hu Q. (1996). Continuous Time Markov Decision Processes with Discounted Moment Criterion.<i>Journal of Mathematical Analysis and Applications</i> 203, 1–12.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1006%2Fjmaa.1996.9999" aria-label="View reference 3">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%20with%20Discounted%20Moment%20Criterion&amp;journal=Journal%20of%20Mathematical%20Analysis%20and%20Applications&amp;volume=203&amp;pages=1-12&amp;publication_year=1996&amp;author=Hu%2CQ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, J.. Liu, W.. Yue, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Hu Q., Liu J. and Yue W. (2003). Continuous Time Markov Decision Processes: Discounted Total Reward.Internatio" /><p class="c-article-references__text" id="ref-CR122">Hu Q., Liu J. and Yue W. (2003). Continuous Time Markov Decision Processes: Discounted Total Reward.<i>International Journal of Pure and Applied Mathematics</i> 7, 147–175.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%3A%20Discounted%20Total%20Reward&amp;journal=International%20Journal%20of%20Pure%20and%20Applied%20Mathematics&amp;volume=7&amp;pages=147-175&amp;publication_year=2003&amp;author=Hu%2CQ.&amp;author=Liu%2CJ.&amp;author=Yue%2CW.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q.. Hu, J.. Wang, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hu Q. and Wang J. (1998). Continuous Time Markov Decision Processes with Nonuniformly Bounded Rate: Expected T" /><p class="c-article-references__text" id="ref-CR123">Hu Q. and Wang J. (1998). Continuous Time Markov Decision Processes with Nonuniformly Bounded Rate: Expected Total Rewards.<i>Optimization</i> 43, 219–233.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1080%2F02331939808844385" aria-label="View reference 5">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20Time%20Markov%20Decision%20Processes%20with%20Nonuniformly%20Bounded%20Rate%3A%20Expected%20Total%20Rewards&amp;journal=Optimization&amp;volume=43&amp;pages=219-233&amp;publication_year=1998&amp;author=Hu%2CQ.&amp;author=Wang%2CJ.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R.F.. Serfozo, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Serfozo R.F. (1979). An Equivalence Between Continuous and Discrete Time Markov Decision Processes.Operations " /><p class="c-article-references__text" id="ref-CR124">Serfozo R.F. (1979). An Equivalence Between Continuous and Discrete Time Markov Decision Processes.<i>Operations Research</i> 27, 616–620.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20Equivalence%20Between%20Continuous%20and%20Discrete%20Time%20Markov%20Decision%20Processes&amp;journal=Operations%20Research&amp;volume=27&amp;pages=616-620&amp;publication_year=1979&amp;author=Serfozo%2CR.F.">
                        Google Scholar</a></li></ul></li></ol><h3 class="c-article-references__heading u-h3">References</h3><ol class="c-article-references" data-test="references-list-section"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.. Haviv, M.L.. Puterman, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Haviv M. and Puterman M.L. (1998). Bias Optimality in Controlled Queuing Systems.Journal of Applied Probabilit" /><p class="c-article-references__text" id="ref-CR125">Haviv M. and Puterman M.L. (1998). Bias Optimality in Controlled Queuing Systems.<i>Journal of Applied Probability</i> 35, 136–150.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1032192558" aria-label="View reference 1">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20in%20Controlled%20Queuing%20Systems&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=35&amp;pages=136-150&amp;publication_year=1998&amp;author=Haviv%2CM.&amp;author=Puterman%2CM.L.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, H.. Ayhan, R.D.. Foley, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Lewis M.E., Ayhan H. and Foley R.D. (1999). Bias Optimality in a Queue with Admission Control.Probability in t" /><p class="c-article-references__text" id="ref-CR126">Lewis M.E., Ayhan H. and Foley R.D. (1999). Bias Optimality in a Queue with Admission Control.<i>Probability in the Engineering and Informational Sciences</i> 13, 309–327.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1017%2FS0269964899133047" aria-label="View reference 2">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimality%20in%20a%20Queue%20with%20Admission%20Control&amp;journal=Probability%20in%20the%20Engineering%20and%20Informational%20Sciences&amp;volume=13&amp;pages=309-327&amp;publication_year=1999&amp;author=Lewis%2CM.E.&amp;author=Ayhan%2CH.&amp;author=Foley%2CR.D.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M.E.. Lewis, H.. Ayhan, R.D.. Foley, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Lewis M.E., Ayhan H. and Foley R.D. (2002). Bias Optimal Admission Policies for a Nonstationary Multiclass Que" /><p class="c-article-references__text" id="ref-CR127">Lewis M.E., Ayhan H. and Foley R.D. (2002). Bias Optimal Admission Policies for a Nonstationary Multiclass Queueing System.<i>Journal of Applied Probability</i> 39, 20–37.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1239%2Fjap%2F1019737985" aria-label="View reference 3">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bias%20Optimal%20Admission%20Policies%20for%20a%20Nonstationary%20Multiclass%20Queueing%20System&amp;journal=Journal%20of%20Applied%20Probability&amp;volume=39&amp;pages=20-37&amp;publication_year=2002&amp;author=Lewis%2CM.E.&amp;author=Ayhan%2CH.&amp;author=Foley%2CR.D.">
                        Google Scholar</a></li></ul></li></ol><h3 class="c-article-references__heading u-h3">References</h3><ol class="c-article-references" data-test="references-list-section"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V.S.. Borkar, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Borkar V.S. (2004). Controlled Diffusion Processes.Probability Surveys 2, 213–244." /><p class="c-article-references__text" id="ref-CR128">Borkar V.S. (2004). Controlled Diffusion Processes.<i>Probability Surveys</i> 2, 213–244.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Controlled%20Diffusion%20Processes&amp;journal=Probability%20Surveys&amp;volume=2&amp;pages=213-244&amp;publication_year=2004&amp;author=Borkar%2CV.S.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cao X.R. and Guo X.P. (2004). Partially Observable Markov Decision Processes With Reward Information Proceedin" /><p class="c-article-references__text" id="ref-CR129">Cao X.R. and Guo X.P. (2004). Partially Observable Markov Decision Processes With Reward Information Proceeding of 43rd IEEE Conference on Decision and Control, 4393–4398.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Lerma O. (1989).Adaptive Markov Control Processes. Springer." /><p class="c-article-references__text" id="ref-CR130">Hernández-Lerma O. (1989).<i>Adaptive Markov Control Processes</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Lerma O. and Lasserre J.B. (1996).Discrete-Time Markov Control Processes: Basic Optimality Criteria." /><p class="c-article-references__text" id="ref-CR131">Hernández-Lerma O. and Lasserre J.B. (1996).<i>Discrete-Time Markov Control Processes: Basic Optimality Criteria</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Lerma O. and Lasserre J.B. (1999).Further Topics on Discrete-Time Markov Control Processes. Springer" /><p class="c-article-references__text" id="ref-CR132">Hernández-Lerma O. and Lasserre J.B. (1999).<i>Further Topics on Discrete-Time Markov Control Processes</i>. Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Howard R.A. (1960).Dynamic Programming and Markov Processes. MIT Press." /><p class="c-article-references__text" id="ref-CR133">Howard R.A. (1960).<i>Dynamic Programming and Markov Processes</i>. MIT Press.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L.P.. Kaelbling, M.L.. Littman, A.W.. Moore, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Kaelbling L.P., Littman M.L. and Moore A.W. (1996). Reinforcement Learning: A Survey,Journal of Artificial Int" /><p class="c-article-references__text" id="ref-CR134">Kaelbling L.P., Littman M.L. and Moore A.W. (1996). Reinforcement Learning: A Survey,<i>Journal of Artificial Intelligence Research</i> 4, 237–285.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20Learning%3A%20A%20Survey&amp;journal=Journal%20of%20Artificial%20Intelligence%20Research&amp;volume=4&amp;pages=237-285&amp;publication_year=1996&amp;author=Kaelbling%2CL.P.&amp;author=Littman%2CM.L.&amp;author=Moore%2CA.W.">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Puterman M.L. (1994).Markov Decision Processes. Wiley." /><p class="c-article-references__text" id="ref-CR135">Puterman M.L. (1994).<i>Markov Decision Processes</i>. Wiley.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Neyman A. and Sorin S. (2001).Stochastic Games and Applications. NATO Science Series, 570." /><p class="c-article-references__text" id="ref-CR136">Neyman A. and Sorin S. (2001).<i>Stochastic Games and Applications</i>. NATO Science Series, 570.</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-category="article body" data-track-label="link" href="/article/10.1007/BF02837562-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article-author-information__subtitle u-h3" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><span class="c-article-author-affiliation__address u-h3">Zhongshan University, P.R. China</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Xianping Guo</li></ul></li><li id="Aff2"><span class="c-article-author-affiliation__address u-h3">CINVESTAV-IPN, Mexico</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Onésimo Hernández-Lerma</li></ul></li><li id="Aff3"><span class="c-article-author-affiliation__address u-h3">Universidad Nacional de Educación a Distancia, Spain</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Tomás Prieto-Rumeau</li></ul></li><li id="Aff4"><span class="c-article-author-affiliation__address u-h3">Hong Kong University of Science and Technology, Hong Kong</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Xi-Ren Cao</li><li class="c-article-author-affiliation__authors-item"> &amp; Junyu Zhang</li></ul></li><li id="Aff5"><span class="c-article-author-affiliation__address u-h3">Shanghai University, China</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Qiying Hu</li></ul></li><li id="Aff6"><span class="c-article-author-affiliation__address u-h3">Cornell University, USA</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Mark E. Lewis</li></ul></li><li id="Aff7"><span class="c-article-author-affiliation__address u-h3">Universidad Nacinal de Educación a Distancia, Spain</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Ricardo Vélez</li></ul></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article-author-information__subtitle u-h3">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-1"><span class="c-article-authors-search__title u-h3 js-search-name">Xianping Guo</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Xianping+Guo&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Xianping+Guo" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Xianping+Guo%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-2"><span class="c-article-authors-search__title u-h3 js-search-name">Onésimo Hernández-Lerma</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;On%C3%A9simo+Hern%C3%A1ndez-Lerma&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=On%C3%A9simo+Hern%C3%A1ndez-Lerma" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22On%C3%A9simo+Hern%C3%A1ndez-Lerma%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-3"><span class="c-article-authors-search__title u-h3 js-search-name">Tomás Prieto-Rumeau</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Tom%C3%A1s+Prieto-Rumeau&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tom%C3%A1s+Prieto-Rumeau" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tom%C3%A1s+Prieto-Rumeau%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-4"><span class="c-article-authors-search__title u-h3 js-search-name">Xi-Ren Cao</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Xi-Ren+Cao&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Xi-Ren+Cao" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Xi-Ren+Cao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-5"><span class="c-article-authors-search__title u-h3 js-search-name">Junyu Zhang</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Junyu+Zhang&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Junyu+Zhang" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Junyu+Zhang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-6"><span class="c-article-authors-search__title u-h3 js-search-name">Qiying Hu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Qiying+Hu&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Qiying+Hu" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Qiying+Hu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-7"><span class="c-article-authors-search__title u-h3 js-search-name">Mark E. Lewis</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Mark E.+Lewis&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mark E.+Lewis" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mark E.+Lewis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-8"><span class="c-article-authors-search__title u-h3 js-search-name">Ricardo Vélez</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ricardo+V%C3%A9lez&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ricardo+V%C3%A9lez" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ricardo+V%C3%A9lez%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li></ol></div></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>Research partially supported by grants NSFC, DRFP and NCET.</p><p>Research partially supported by CONACyT (Mexico) Grant 45693-F.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-category="article body" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20survey%20of%20recent%20results%20on%20continuous-time%20Markov%20decision%20processes&amp;author=Xianping%20Guo%20et%20al&amp;contentID=10.1007%2FBF02837562&amp;publication=1134-5764&amp;publicationDate=2006-12&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Guo, X., Hernández-Lerma, O., Prieto-Rumeau, T. <i>et al.</i> A survey of recent results on continuous-time Markov decision processes.
                    <i>TOP</i> <b>14, </b>177–261 (2006). https://doi.org/10.1007/BF02837562</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-category="article body" data-track-label="link" href="/article/10.1007/BF02837562.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2006-12">December 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><a href="https://doi.org/10.1007/BF02837562" data-track="click" data-track-action="view doi" data-track-category="article body" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/BF02837562</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading u-h3">Key Words</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Continuous-time Markov decision processes (also known as controlled Markov chains)</span></li><li class="c-article-subject-list__subject"><span itemprop="about">unbounded reward and transition rates</span></li><li class="c-article-subject-list__subject"><span itemprop="about">discounted reward</span></li><li class="c-article-subject-list__subject"><span itemprop="about">average reward</span></li><li class="c-article-subject-list__subject"><span itemprop="about">bias optimality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">sensitive discount criteria</span></li></ul><h3 class="c-article__sub-heading u-h3">AMS subject classification</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">90C40</span></li><li class="c-article-subject-list__subject"><span itemprop="about">93E20</span></li><li class="c-article-subject-list__subject"><span itemprop="about">60J27</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                    </div>
                </article>
            </main>

            <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
                <aside>
                    <div data-test="download-article-link-wrapper">
                        
                    </div>

                    <div data-test="collections">
                        
                    </div>

                    <div data-test="editorial-summary">
                        
                    </div>

                    <div class="c-reading-companion">
                        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                            
                                <div class="c-article-buy-box">
                                    <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">37,40 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/BF02837562">
     <input type="hidden" name="isxn" value="1863-8279">
     <input type="hidden" name="contenttitle" value="A survey of recent results on continuous-time Markov decision processes">
     <input type="hidden" name="copyrightyear" value="2006">
     <input type="hidden" name="year" value="">
     <input type="hidden" name="authors" value="Xianping Guo, et al.">
     <input type="hidden" name="title" value="TOP">
     <input type="hidden" name="mac" value="37E2A931385D5AD3D8C22140AD7ECD00">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action, new buybox" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">81 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="TOP">
     <input type="hidden" name="journalnumber" value="11750">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/BF02837562&journal=1863-8279&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                                </div>
                            

                            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                                <div class="js-ad">
    <div class="c-ad c-ad--MPU1">
        <div class="c-ad c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/11750/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=BF02837562;"></div>
        </div>
    </div>
</div>

                            </div>
                            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                        </div>
                    </div>
                </aside>
            </div>

        </div>
    </div>

    <div class="c-page-layout__footer">
        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 79.12.216.170</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 14 14">
            <path d="M13.545 12.648a.641.641 0 01.006.903.646.646 0 01-.903-.006l-2.664-2.663a6.125 6.125 0 11.897-.898l2.664 2.664zm-7.42-1.273a5.25 5.25 0 100-10.5 5.25 5.25 0 000 10.5z"></path>
        </symbol>
    </svg>

    </footer>



    </div>

    <script>
    window.config = {
        mustardcut: false
    };

    
    (function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement);

        
    var mustardcutlink = document.getElementById('js-mustard');
    if (mustardcutlink && window.matchMedia && window.matchMedia(mustardcutlink.media).matches) {
        window.config.mustardcut = true;
    }
</script>

<script src=/oscar-static/app-springerlink/js/app-bundle-baa27ae2fe.js></script>

<script>
    if (window.config && window.config.mustardcut) {
        var globalArticle = document.createElement('script');

        globalArticle.src = '/oscar-static/app-springerlink/js/global-article-bundle-53273b47c8.js';
        
        window.Component = {};
        document.body.appendChild(globalArticle);
        
    }
</script>

    <div id="googleanalytics-container">
    
        
    
</div>
<div id="google-tag-manager-head-container">
    
        
            <!-- Google Tag Manager -->
            <script>
                (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
            </script>
            <!-- End Google Tag Manager -->
        
    
</div>

<div id="google-tag-manager-body-container">
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript>
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                        height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    
</div>

</body>
</html>
