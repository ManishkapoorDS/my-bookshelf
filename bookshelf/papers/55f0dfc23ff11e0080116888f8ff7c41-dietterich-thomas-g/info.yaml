author: Dietterich, Thomas G.
author_list:
- affiliation: []
  family: Dietterich
  given: Thomas G.
citations:
- author: D. P. Bertsekas
  unstructured: Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming.
    Athena Scientific, Belmont, MA.
  volume-title: Neuro-Dynamic Programming
  year: '1996'
- author: R. H. Crites
  first-page: '1017'
  unstructured: Crites, R. H., & Barto, A. G. (1995). Improving elevator performance
    using reinforcement learning. In Advances in Neural Information Processing Systems,
    Vol. 8, pp. 1017–1023 San Francisco, CA. Morgan Kaufmann.
  volume-title: Advances in Neural Information Processing Systems
  year: '1995'
- author: P. Dayan
  first-page: '271'
  unstructured: Dayan, P., & Hinton, G. (1993). Feudal reinforcement learning. In
    Advances in Neural Information Processing Systems, 5, pp. 271–278. Morgan Kaufmann,
    San Francisco, CA.
  volume-title: Advances in Neural Information Processing Systems
  year: '1993'
- author: T. Dean
  unstructured: Dean, T., & Lin, S.-H. (1995). Decomposition techniques for planning
    in stochastic domains. Tech. rep. CS-95-10, Department of Computer Science, Brown
    University, Providence, Rhode Island.
  volume-title: Tech. rep. CS-95-10
  year: '1995'
- doi: 10.1613/jair.639
  unstructured: Dietterich, T. G. (2000). Hierarchical reinforcement learning with
    the MAXQ value function decomposition. Journal of Artificial Intelligence Research.
    To appear.
- author: L. P. Kaelbling
  first-page: '167'
  unstructured: 'Kaelbling, L. P. (1993). Hierarchical reinforcement learning: Preliminary
    results. In Proceedings of the Tenth International Conference on Machine Learning,
    pp. 167–173 San Francisco, CA. Morgan Kaufmann.'
  volume-title: Proceedings of the Tenth International Conference on Machine Learning
  year: '1993'
- author: A. W. Moore
  first-page: '103'
  journal-title: Machine Learning
  unstructured: 'Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement
    learning with less data and less time. Machine Learning, 13, 103.'
  volume: '13'
  year: '1993'
- author: R. Parr
  series-title: Ph.D. thesis
  unstructured: Parr, R. (1998). Hierarchical control and learning for Markov decision
    processes. Ph.D. thesis, University of California, Berkeley, California.
  volume-title: Hierarchical control and learning for Markov decision processes
  year: '1998'
- author: R. Parr
  first-page: '1043'
  unstructured: Parr, R., & Russell, S. (1998). Reinforcement learning with hierarchies
    of machines. In Advances in Neural Information Processing Systems, Vol. 10, pp.
    1043–1049 Cambridge, MA. MIT Press.
  volume-title: Advances in Neural Information Processing Systems
  year: '1998'
- author: S. Singh
  unstructured: Singh, S., Jaakkola, T., Littman, M. L., & Szepesvári, C. (1998).
    Convergence results for single-step on-policy reinforcement-learning algorithms.
    Tech. rep., University of Colorado, Department of Computer Science, Boulder, CO.
    To appear in Machine Learning.
  volume-title: Tech. rep.
  year: '1998'
- author: S. P. Singh
  first-page: '323'
  journal-title: Machine Learning
  unstructured: Singh, S. P. (1992). Transfer of learning by composing solutions of
    elemental sequential tasks. Machine Learning, 8, 323.
  volume: '8'
  year: '1992'
- author: R. Sutton
  unstructured: Sutton, R., & Barto, A. G. (1998). Introduction to Reinforcement Learning.
    MIT Press, Cambridge, MA.
  volume-title: Introduction to Reinforcement Learning
  year: '1998'
- author: R. S. Sutton
  unstructured: 'Sutton, R. S., Precup, D., & Singh, S. (1998). Between MDPs and Semi-MDPs:
    Learning, planning, and representing knowledge at multiple temporal scales. Tech.
    rep., University of Massachusetts, Department of Computer and Information Sciences,
    Amherst, MA. To appear in Artificial Intelligence.'
  volume-title: Tech. rep.
  year: '1998'
- author: G. Tesauro
  doi: 10.1145/203330.203343
  first-page: '58'
  issue: '3'
  journal-title: Communications of the ACM
  unstructured: Tesauro, G. (1995). Temporal difference learning and TD-Gammon. Communications
    of the ACM, 28(3), 58–68.
  volume: '28'
  year: '1995'
- author: W. Zhang
  first-page: '1114'
  unstructured: Zhang, W., & Dietterich, T. G. (1995). A reinforcement learning approach
    to job-shop scheduling. In 1995 International Joint Conference on Artificial Intelligence,
    pp. 1114–1120. Morgan Kaufmann, San Francisco, CA.
  volume-title: 1995 International Joint Conference on Artificial Intelligence
  year: '1995'
doi: 10.1007/3-540-44914-0_2
isbn:
- '9783540678397'
- '9783540449140'
journal: Lecture Notes in Computer Science
month: 8
pages: 26--44
publisher: Springer Berlin Heidelberg
title: An Overview of MAXQ Hierarchical Reinforcement Learning
type: inbook
url: http://dx.doi.org/10.1007/3-540-44914-0_2
year: 2000
