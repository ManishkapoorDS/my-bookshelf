abstract: Models based on deep convolutional networks have dominated recent image
  interpretation tasks; we investigate whether models which are also recurrent, or
  "temporally deep", are effective for tasks involving sequences, visual and otherwise.
  We develop a novel recurrent convolutional architecture suitable for large-scale
  visual learning which is end-to-end trainable, and demonstrate the value of these
  models on benchmark video recognition tasks, image description and retrieval problems,
  and video narration challenges. In contrast to current models which assume a fixed
  spatio-temporal receptive field or simple temporal averaging for sequential processing,
  recurrent convolutional models are "doubly deep"' in that they can be compositional
  in spatial and temporal "layers". Such models may have advantages when target concepts
  are complex and/or training data are limited. Learning long-term dependencies is
  possible when nonlinearities are incorporated into the network state updates. Long-term
  RNN models are appealing in that they directly can map variable-length inputs (e.g.,
  video frames) to variable length outputs (e.g., natural language text) and can model
  complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent
  long-term models are directly connected to modern visual convnet models and can
  be jointly trained to simultaneously learn temporal dynamics and convolutional perceptual
  representations. Our results show such models have distinct advantages over state-of-the-art
  models for recognition or generation which are separately defined and/or optimized.
archiveprefix: arXiv
author: Donahue, Jeff and Hendricks, Lisa Anne and Rohrbach, Marcus and Venugopalan,
  Subhashini and Guadarrama, Sergio and Saenko, Kate and Darrell, Trevor
author_list:
- family: Donahue
  given: Jeff
- family: Hendricks
  given: Lisa Anne
- family: Rohrbach
  given: Marcus
- family: Venugopalan
  given: Subhashini
- family: Guadarrama
  given: Sergio
- family: Saenko
  given: Kate
- family: Darrell
  given: Trevor
eprint: 1411.4389v4
file: 1411.4389v4.pdf
files:
- donahue-jeff-and-hendricks-lisa-anne-and-rohrbach-marcus-and-venugopalan-subhashini-and-guadarrama-sergio-and-saenko-kate-and-darrell-trevorlon.pdf
month: Nov
primaryclass: cs.CV
ref: 1411.4389v4
title: Long-term Recurrent Convolutional Networks for Visual Recognition and   Description
type: article
url: http://arxiv.org/abs/1411.4389v4
year: '2014'
