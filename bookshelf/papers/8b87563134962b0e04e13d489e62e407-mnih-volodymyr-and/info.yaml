abstract: Applying convolutional neural networks to large images is computationally
  expensive because the amount of computation scales linearly with the number of image
  pixels. We present a novel recurrent neural network model that is capable of extracting
  information from an image or video by adaptively selecting a sequence of regions
  or locations and only processing the selected regions at high resolution. Like convolutional
  neural networks, the proposed model has a degree of translation invariance built-in,
  but the amount of computation it performs can be controlled independently of the
  input image size. While the model is non-differentiable, it can be trained using
  reinforcement learning methods to learn task-specific policies. We evaluate our
  model on several image classification tasks, where it significantly outperforms
  a convolutional neural network baseline on cluttered images, and on a dynamic visual
  control problem, where it learns to track a simple object without an explicit training
  signal for doing so.
archiveprefix: arXiv
author: Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray
author_list:
- family: Mnih
  given: Volodymyr
- family: Heess
  given: Nicolas
- family: Graves
  given: Alex
- family: Kavukcuoglu
  given: Koray
eprint: 1406.6247v1
file: 1406.6247v1.pdf
files:
- mnih-volodymyr-and-heess-nicolas-and-graves-alex-and-kavukcuoglu-korayrecurrent-models-of-visual-attention2014.pdf
month: Jun
primaryclass: cs.LG
ref: 1406.6247v1
tags: deep-learning attention computer-vision
title: Recurrent Models of Visual Attention
type: article
url: http://arxiv.org/abs/1406.6247v1
year: '2014'
