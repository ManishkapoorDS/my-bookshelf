abstract: Representation learning algorithms are designed to learn abstract features
  that characterize data. State representation learning (SRL) focuses on a particular
  kind of representation learning where learned features are in low dimension, evolve
  through time, and are influenced by actions of an agent. The representation is learned
  to capture the variation in the environment generated by the agent's actions; this
  kind of representation is particularly suitable for robotics and control scenarios.
  In particular, the low dimension characteristic of the representation helps to overcome
  the curse of dimensionality, provides easier interpretation and utilization by humans
  and can help improve performance and speed in policy learning algorithms such as
  reinforcement learning.   This survey aims at covering the state-of-the-art on state
  representation learning in the most recent years. It reviews different SRL methods
  that involve interaction with the environment, their implementations and their applications
  in robotics control tasks (simulated or real). In particular, it highlights how
  generic learning objectives are differently exploited in the reviewed algorithms.
  Finally, it discusses evaluation methods to assess the representation learned and
  summarizes current and future lines of research.
archiveprefix: arXiv
author: Lesort, Timothée and Díaz-Rodríguez, Natalia and Goudou, Jean-François and
  Filliat, David
author_list:
- family: Lesort
  given: Timothée
- family: Díaz-Rodríguez
  given: Natalia
- family: Goudou
  given: Jean-François
- family: Filliat
  given: David
doi: 10.1016/j.neunet.2018.07.006
eprint: 1802.04181v2
file: 1802.04181v2.pdf
files:
- lesort-timothee-and-diaz-rodriguez-natalia-and-goudou-jean-francois-and-filliat-davidstate-representation-learning-for-control-an-overview2018.pdf
month: Feb
primaryclass: cs.AI
ref: 1802.04181v2
title: 'State Representation Learning for Control: An Overview'
type: article
url: http://arxiv.org/abs/1802.04181v2
year: '2018'
