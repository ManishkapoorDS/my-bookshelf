https://api.elsevier.com/content/article/pii/S0004370200000333 doi:10.1016/S0004-3702(00)00033-3 1-s2.0-S0004370200000333 10.1016/S0004-3702(00)00033-3 S0004-3702(00)00033-3 Stochastic dynamic programming with factored representations  Artificial Intelligence Journal 00043702 121 1-2 49 107 49-107 1-2 text/plain 2000-08-31 August 2000 Copyright © 2000 Elsevier Science B.V. All rights reserved. Elsevier Science B.V. Boutilier, Craig Dearden, Richard Goldszmidt, Moisés 
               Abstract
               
                  Markov decision processes (MDPs) have proven to be popular models for decision-theoretic planning, but standard dynamic programming algorithms for solving MDPs rely on explicit, state-based specifications and computations. To alleviate the combinatorial problems associated with such methods, we propose new representational and computational techniques for MDPs that exploit certain types of problem structure. We use dynamic Bayesian networks (with decision trees representing the local families of conditional probability distributions) to represent stochastic actions in an MDP, together with a decision-tree representation of rewards. Based on this representation, we develop versions of standard dynamic programming algorithms that directly manipulate decision-tree representations of policies and value functions. This generally obviates the need for state-by-state computation, aggregating states at the leaves of these trees and requiring computations only for each aggregate state. The key to these algorithms is a decision-theoretic generalization of classic regression analysis, in which we determine the features relevant to predicting expected value. We demonstrate the method empirically on several planning problems, showing significant savings for certain types of domains. We also identify certain classes of problems for which this technique fails to perform well and suggest extensions and related ideas that may prove useful in such circumstances. We also briefly describe an approximation scheme based on this approach.
               
             1 true Full true  ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ Decision-theoretic planning Markov decision processes Bayesian networks Regression Decision trees Abstraction    0034248853 2-s2.0-0034248853   