abstract: The field of meta-learning, or learning-to-learn, has seen a dramatic rise
  in interest in recent years. Contrary to conventional approaches to AI where a given
  task is solved from scratch using a fixed learning algorithm, meta-learning aims
  to improve the learning algorithm itself, given the experience of multiple learning
  episodes. This paradigm provides an opportunity to tackle many of the conventional
  challenges of deep learning, including data and computation bottlenecks, as well
  as the fundamental issue of generalization. In this survey we describe the contemporary
  meta-learning landscape. We first discuss definitions of meta-learning and position
  it with respect to related fields, such as transfer learning, multi-task learning,
  and hyperparameter optimization. We then propose a new taxonomy that provides a
  more comprehensive breakdown of the space of meta-learning methods today. We survey
  promising applications and successes of meta-learning including few-shot learning,
  reinforcement learning and architecture search. Finally, we discuss outstanding
  challenges and promising areas for future research.
archiveprefix: arXiv
author: Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey,
  Amos
author_list:
- family: Hospedales
  given: Timothy
- family: Antoniou
  given: Antreas
- family: Micaelli
  given: Paul
- family: Storkey
  given: Amos
eprint: 2004.05439v1
file: 2004.05439v1.pdf
files:
- hospedales-timothy-and-antoniou-antreas-and-micaelli-paul-and-storkey-amosmeta-learning-in-neural-networks-a-survey2020.pdf
month: Apr
primaryclass: cs.LG
ref: 2004.05439v1
time-added: 2020-06-05-17:56:12
title: 'Meta-Learning in Neural Networks: A Survey'
type: article
url: http://arxiv.org/abs/2004.05439v1
year: '2020'
