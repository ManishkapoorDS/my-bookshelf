author: Stolle, Martin and Precup, Doina
author_list:
- affiliation: []
  family: Stolle
  given: Martin
- affiliation: []
  family: Precup
  given: Doina
citations:
- unstructured: '[1995]Bradtke:SMDPQ Bradtke, S. J.,& Duff, M. O. (1995). Reinforcement
    learning methods for continuous-time Markov Decision Problems. Advances in Neural
    Information Processing Systems 7 (pp. 393–400). MIT Press.'
- unstructured: '[1998]Dietterich:MAXQ Dietterich, T. G. (1998). The MAXQ method for
    hierarchical reinforcement learning. Proceedings of the Fifteenth International
    Conference on Machine Learning. Morgan Kaufmann.'
- author: P.E. Hart
  doi: 10.1016/0004-3702(72)90051-3
  first-page: '251'
  journal-title: Artificial Intelligence
  unstructured: '[1972]Fikes:RobotPlan Fikes, R., P.E. Hart, & Nilsson, N. J. (1972).
    Learning and executing generalized robot plans. Artificial Intelligence, 3, 251–288.'
  volume: '3'
  year: '1972'
- author: G. A. Iba
  first-page: '285'
  journal-title: Machine Learning
  unstructured: '[1989]Iba:Macro Iba, G. A. (1989). A heuristic approach to the discovery
    of macro-operators. Machine Learning, 3, 285–317.'
  volume: '3'
  year: '1989'
- unstructured: '[1985]Korf:Macro Korf, R. E. (1985). Learning to solve problems by
    searching for macro-operators. Pitman Publishing Ltd.'
- author: J. E. Laird
  first-page: '11'
  journal-title: Machine Learning
  unstructured: '[1986]Laird:ChunkSOAR Laird, J. E., Rosenbloom, P. S., & Newell,
    A. (1986). Chunking in SOAR: The anatomy of a general learning mechanism. Machine
    Learning, 1, 11–46.'
  volume: '1'
  year: '1986'
- unstructured: '[1997]Mahadevan:SMDP Mahadevan, S., Mar-challek, N., Das, T. K.,
    & Gosavi, A. (1997). Self-improving factory simulation using continuous-time average-reward
    reinforcement learning. Proceedings of the Fourteenth International Conference
    on Machine Learning (pp. 202–210). Morgan Kaufmann.'
- unstructured: '[1997]McGovern:MacroRL McGovern, A., Sutton, R.S., & Fagg, A. H.
    (1997). Roles of macro-actions in accelerating reinforcement learning. Grace Hopper
    Celebration of Women in Computing (pp. 13–17).'
- author: E. A. McGovern
  unstructured: '[2002]McGovern:Thesis McGovern, E. A. (2002). Autonomous discovery
    of temporal abstractions from interaction with an environment. Doctoral dissertation,
    University of Massachusetts, Amherst.'
  volume-title: Autonomous discovery of temporal abstractions from interaction with
    an environment
  year: '2002'
- unstructured: '[2001]McGovern:ICML McGovern, E. A., & Barto, A. G. (2001). Automatic
    discovery of subgoals in reinforcement learning using diverse density. Proceedings
    of the Eighteenth International Conference on Machine Learning (pp. 361–368).
    Morgan Kaufman.'
- unstructured: '[1988]Minton:BookMinton, S. (1988). Learning search control knowledge.
    An explanation-based approach. Kluwer Academic Publishers.'
- unstructured: '[1972]Newell:Simon Newell, A., & Simon, H. A. (1972). Human problem
    solving. Prentice-Hall.'
- unstructured: '[1998]Parr:Thesis Parr, R. (1998). Hierarchical control and learning
    for Markov Decision Processes. Doctoral dissertation, Computer Science Division,
    University of California, Berkeley, USA.'
- unstructured: '[1998]Parr:HAMs Parr, R., & Russell, S. (1998). Reinforcement learning
    with hierarchies of machines. Advances in Neural Information Processing Systems
    10. MIT Press.'
- unstructured: '[2000]Precup:Thesis Precup, D. (2000)._Temporal abstraction in reinforcement
    learning. Doctoral dissertation, Department of Computer Science, University of
    Massachusetts, Amherst, USA.'
- unstructured: '[1994]Puterman:Book Puterman, M. L. (1994). Markov Decision Processes:
    Discrete stochastic dynamic programming. Wiley.'
- doi: 10.1016/0004-3702(74)90026-5
  unstructured: '[1974]Sacerdoti:PlanArt Sacerdoti, E. D. (1974). Planning in a hierarchy
    of abstraction spaces. Artificial Intelligence, 5, 115–135.'
- unstructured: '[1992]Singh:HDynaAAAI Singh, S. P. (1992). Reinforcement learning
    with a hierarchy of abstract models. Proceedings of the Tenth National Conference
    on Artificial Intelligence (pp. 202–207). MIT/AAAI Press.'
- unstructured: '[1998]Sutton:BookSutton,R.S.,&Barto, A.G. (1998). Reinforcement learning:
    An introduction. MIT Press.'
- author: R. S. Sutton
  doi: 10.1016/S0004-3702(99)00052-1
  first-page: '181'
  journal-title: Artificial Intelligence
  unstructured: '[1999]Precup:Options Sutton, R. S., Precup, D., & Singh, S. (1999).
    Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement
    learning. Artificial Intelligence, 112, 181–211.'
  volume: '112'
  year: '1999'
- unstructured: '[1989]Watkins:Qlearn Watkins, C. J. C. H. (1989). Learning with delayed
    rewards. Doctoral dissertation, Psychology Department, Cambridge University, Cambridge,
    UK.'
doi: 10.1007/3-540-45622-8_16
isbn:
- '9783540439417'
- '9783540456223'
journal: Lecture Notes in Computer Science
month: 7
pages: 212--223
publisher: Springer Berlin Heidelberg
title: Learning Options in Reinforcement Learning
type: inbook
url: http://dx.doi.org/10.1007/3-540-45622-8_16
year: 2002
