abstract: 'Simulation is a crucial component of any robotic system. In order to simulate
  correctly, we need to write complex rules of the environment: how dynamic agents
  behave, and how the actions of each of the agents affect the behavior of others.
  In this paper, we aim to learn a simulator by simply watching an agent interact
  with an environment. We focus on graphics games as a proxy of the real environment.
  We introduce GameGAN, a generative model that learns to visually imitate a desired
  game by ingesting screenplay and keyboard actions during training. Given a key pressed
  by the agent, GameGAN "renders" the next screen using a carefully designed generative
  adversarial network. Our approach offers key advantages over existing work: we design
  a memory module that builds an internal map of the environment, allowing for the
  agent to return to previously visited locations with high visual consistency. In
  addition, GameGAN is able to disentangle static and dynamic components within an
  image making the behavior of the model more interpretable, and relevant for downstream
  tasks that require explicit reasoning over dynamic elements. This enables many interesting
  applications such as swapping different components of the game to build new games
  that do not exist.'
archiveprefix: arXiv
author: Kim, Seung Wook and Zhou, Yuhao and Philion, Jonah and Torralba, Antonio and
  Fidler, Sanja
author_list:
- family: Kim
  given: Seung Wook
- family: Zhou
  given: Yuhao
- family: Philion
  given: Jonah
- family: Torralba
  given: Antonio
- family: Fidler
  given: Sanja
eprint: 2005.12126v1
file: 2005.12126v1.pdf
files:
- kim-seung-wook-and-zhou-yuhao-and-philion-jonah-and-torralba-antonio-and-fidler-sanjalearning-to-simulate-dynamic-environments-with-gamegan2020.pdf
month: May
primaryclass: cs.CV
ref: 2005.12126v1
time-added: 2020-06-20-21:46:28
title: Learning to Simulate Dynamic Environments with GameGAN
type: article
url: http://arxiv.org/abs/2005.12126v1
year: '2020'
