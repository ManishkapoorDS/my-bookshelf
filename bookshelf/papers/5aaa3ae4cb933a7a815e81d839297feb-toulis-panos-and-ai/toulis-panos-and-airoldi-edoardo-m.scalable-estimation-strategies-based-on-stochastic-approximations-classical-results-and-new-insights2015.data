<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="No">

    

    <meta name="journal_id" content="11222"/>

    <meta name="dc.title" content="Scalable estimation strategies based on stochastic approximations: classical results and new insights"/>

    <meta name="dc.source" content="Statistics and Computing 2015 25:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2015-06-11"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 Springer Science+Business Media New York"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Estimation with large amounts of data can be facilitated by stochastic gradient methods, in which model parameters are updated sequentially using small batches of data at each step. Here, we review early work and modern results that illustrate the statistical properties of these methods, including convergence rates, stability, and asymptotic bias and variance. We then overview modern applications where these methods are useful, ranging from an online version of the EM algorithm to deep learning. In light of these results, we argue that stochastic gradient methods are poised to become benchmark principled estimation procedures for large datasets, especially those in the family of stable proximal methods, such as implicit stochastic gradient descent."/>

    <meta name="prism.issn" content="1573-1375"/>

    <meta name="prism.publicationName" content="Statistics and Computing"/>

    <meta name="prism.publicationDate" content="2015-06-11"/>

    <meta name="prism.volume" content="25"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="781"/>

    <meta name="prism.endingPage" content="795"/>

    <meta name="prism.copyright" content="2015 Springer Science+Business Media New York"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s11222-015-9560-y"/>

    <meta name="prism.doi" content="doi:10.1007/s11222-015-9560-y"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s11222-015-9560-y.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s11222-015-9560-y"/>

    <meta name="citation_journal_title" content="Statistics and Computing"/>

    <meta name="citation_journal_abbrev" content="Stat Comput"/>

    <meta name="citation_publisher" content="Springer US"/>

    <meta name="citation_issn" content="1573-1375"/>

    <meta name="citation_title" content="Scalable estimation strategies based on stochastic approximations: classical results and new insights"/>

    <meta name="citation_volume" content="25"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2015/07"/>

    <meta name="citation_online_date" content="2015/06/11"/>

    <meta name="citation_firstpage" content="781"/>

    <meta name="citation_lastpage" content="795"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s11222-015-9560-y"/>

    <meta name="DOI" content="10.1007/s11222-015-9560-y"/>

    <meta name="citation_doi" content="10.1007/s11222-015-9560-y"/>

    <meta name="description" content="Estimation with large amounts of data can be facilitated by stochastic gradient methods, in which model parameters are updated sequentially using small bat"/>

    <meta name="dc.creator" content="Panos Toulis"/>

    <meta name="dc.creator" content="Edoardo M. Airoldi"/>

    <meta name="dc.subject" content="Statistics and Computing/Statistics Programs"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Statistical Theory and Methods"/>

    <meta name="dc.subject" content="Probability and Statistics in Computer Science"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Natural gradient works efficiently in learning; citation_author=S-I Amari; citation_volume=10; citation_issue=2; citation_publication_date=1998; citation_pages=251-276; citation_doi=10.1162/089976698300017746; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Adaptive method of realizing natural gradient learning for multilayer perceptrons; citation_author=S-I Amari, H Park, F Kenji; citation_volume=12; citation_issue=6; citation_publication_date=2000; citation_pages=1399-1409; citation_doi=10.1162/089976600300015420; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_title=Stochastic Approximation: A Generalisation of the Robbins&#8211;Monro Procedure; citation_publication_date=1989; citation_id=CR3; citation_author=JA Bather; citation_publisher=Cornell University, Mathematical Sciences Institute"/>

    <meta name="citation_reference" content="citation_journal_title=Oper. Res. Lett.; citation_title=Mirror descent and nonlinear projected subgradient methods for convex optimization; citation_author=A Beck, M Teboulle; citation_volume=31; citation_issue=3; citation_publication_date=2003; citation_pages=167-175; citation_doi=10.1016/S0167-6377(02)00231-6; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Mach. Learn.; citation_title=Learning deep architectures for ai. Foundations and trends 
                      
                      
                      
                    
                  ; citation_author=Y Bengio; citation_volume=2; citation_publication_date=2009; citation_pages=1-127; citation_doi=10.1561/2200000006; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Justifying and generalizing contrastive divergence; citation_author=Y Bengio, O Delalleau; citation_volume=21; citation_issue=6; citation_publication_date=2009; citation_pages=1601-1621; citation_doi=10.1162/neco.2008.11-07-647; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_title=Adaptive Algorithms and Stochastic Approximations; citation_publication_date=2012; citation_id=CR7; citation_author=A Benveniste; citation_author=M M&#233;tivier; citation_author=P Priouret; citation_publisher=Springer Publishing Company"/>

    <meta name="citation_reference" content="Bertsekas, D.P., Tsitsiklis, J.N.: Neuro-dynamic programming: an overview. In: Proceedings of the 34th IEEE Conference on Decision and Control, vol. 1, pp. 560&#8211;564 (1995)"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Sgd-qn: careful quasi-Newton stochastic gradient descent; citation_author=A Bordes, L Bottou, P Gallinari; citation_volume=10; citation_publication_date=2009; citation_pages=1737-1754; citation_id=CR9"/>

    <meta name="citation_reference" content="Bottou, L.: Large-scale machine learning with stochastic gradient descent. In: Proceedings of COMPSTAT&#8217;2010, pp. 177&#8211;186. Springer, New York (2010)"/>

    <meta name="citation_reference" content="citation_journal_title=Appl. Stoch. Models Bus. Ind.; citation_title=On-line learning for very large data sets; citation_author=L Bottou, Y Cun; citation_volume=21; citation_issue=2; citation_publication_date=2005; citation_pages=137-151; citation_doi=10.1002/asmb.538; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=The tradeoffs of large scale learning; citation_author=O Bousquet, L Bottou; citation_volume=20; citation_publication_date=2008; citation_pages=161-168; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Math. Comput.; citation_title=A class of methods for solving nonlinear simultaneous equations; citation_author=CG Broyden; citation_volume=19; citation_publication_date=1965; citation_pages=577-593; citation_doi=10.1090/S0025-5718-1965-0198670-6; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=J. Comput. Graph. Stat.; citation_title=Online em algorithm for hidden Markov models; citation_author=O Capp&#233;; citation_volume=20; citation_issue=3; citation_publication_date=2011; citation_pages=728-749; citation_doi=10.1198/jcgs.2011.09109; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc.; citation_title=On-line expectation-maximization algorithm for latent data models; citation_author=O Capp&#233;, M Moulines; citation_volume=71; citation_issue=3; citation_publication_date=2009; citation_pages=593-613; citation_doi=10.1111/j.1467-9868.2009.00698.x; citation_id=CR15"/>

    <meta name="citation_reference" content="Carreira-Perpinan, M.A., Hinton, G.E.: On contrastive divergence learning. In: Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics, pp. 33&#8211;40. Citeseer (2005)"/>

    <meta name="citation_reference" content="Cheng, L., Vishwanathan, S.V.N., Schuurmans, D., Wang, S., Caelli, T.: Implicit online learning with kernels. In: Proceedings of the 2006 Conference Advances in Neural Information Processing Systems 19, vol. 19, p. 249. MIT Press, Cambridge, 2007"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=On a stochastic approximation method; citation_author=KL Chung; citation_volume=25; citation_publication_date=1954; citation_pages=463-483; citation_doi=10.1214/aoms/1177728716; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. B; citation_title=Maximum likelihood from incomplete data via the EM algorithm; citation_author=A Dempster, N Laird, D Rubin; citation_volume=39; citation_publication_date=1977; citation_pages=1-38; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Adaptive subgradient methods for online learning and stochastic optimization; citation_author=J Duchi, E Hazan, Y Singer; citation_volume=999999; citation_publication_date=2011; citation_pages=2121-2159; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Autom. Control; citation_title=On sampling controlled stochastic approximation; citation_author=P Dupuis, R Simha; citation_volume=36; citation_issue=8; citation_publication_date=1991; citation_pages=915-924; citation_doi=10.1109/9.133185; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Stat.; citation_title=Spectrum estimation for large dimensional covariance matrices using random matrix theory; citation_author=N El Karoui; citation_volume=36; citation_publication_date=2008; citation_pages=2757-2790; citation_doi=10.1214/07-AOS581; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=On asymptotic normality in stochastic approximation; citation_author=V Fabian; citation_volume=39; citation_publication_date=1968; citation_pages=1327-1332; citation_doi=10.1214/aoms/1177698258; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Stat.; citation_title=Asymptotically efficient stochastic approximation; the RM case; citation_author=V Fabian; citation_volume=1; citation_publication_date=1973; citation_pages=486-495; citation_doi=10.1214/aos/1176342414; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=Philos. Trans. R. Soc. Lond. Ser. A; citation_title=On the mathematical foundations of theoretical statistics; citation_author=RA Fisher; citation_volume=222; citation_publication_date=1922; citation_pages=309-368; citation_doi=10.1098/rsta.1922.0009; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_title=Statistical Methods for Research Workers; citation_publication_date=1925; citation_id=CR26; citation_author=RA Fisher; citation_publisher=Oliver and Boyd"/>

    <meta name="citation_reference" content="Fisher, R.A.: Theory of statistical estimation. In: Mathematical Proceedings of the Cambridge Philosophical Society, vol. 22, pp. 700&#8211;725. Cambridge University Press, Cambridge (1925b)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.; citation_title=Stochastic relaxation, gibbs distributions, and the Bayesian restoration of images; citation_author=S Geman, D Geman; citation_volume=6; citation_publication_date=1984; citation_pages=721-741; citation_doi=10.1109/TPAMI.1984.4767596; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=Machine Learn.; citation_title=Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming; citation_author=AP George, WB Powell; citation_volume=65; citation_issue=1; citation_publication_date=2006; citation_pages=167-198; citation_doi=10.1007/s10994-006-8365-9; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. B; citation_title=Riemann manifold Langevin and Hamiltonian Monte Carlo methods; citation_author=M Girolami; citation_volume=73; citation_issue=2; citation_publication_date=2011; citation_pages=123-214; citation_doi=10.1111/j.1467-9868.2010.00765.x; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=INFORMS J. Comput.; citation_title=Reinforcement learning: a tutorial survey and recent advances; citation_author=A Gosavi; citation_volume=21; citation_issue=2; citation_publication_date=2009; citation_pages=178-192; citation_doi=10.1287/ijoc.1080.0305; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. B; citation_title=Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives; citation_author=PJ Green; citation_volume=46; citation_publication_date=1984; citation_pages=149-192; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_title=The Elements of Statistical Learning: Data Mining, Inference, and Prediction; citation_publication_date=2011; citation_id=CR33; citation_author=T Hastie; citation_author=R Tibshirani; citation_author=J Friedman; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Quasi-Newton methods: a new direction; citation_author=P Hennig, M Kiefel; citation_volume=14; citation_issue=1; citation_publication_date=2013; citation_pages=843-865; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Training products of experts by minimizing contrastive divergence; citation_author=GE Hinton; citation_volume=14; citation_issue=8; citation_publication_date=2002; citation_pages=1771-1800; citation_doi=10.1162/089976602760128018; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Stochastic variational inference; citation_author=MD Hoffman, DM Blei, C Wang, J Paisley; citation_volume=14; citation_issue=1; citation_publication_date=2013; citation_pages=1303-1347; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=Robust estimation of a location parameter; citation_author=PJ Huber; citation_volume=35; citation_issue=1; citation_publication_date=1964; citation_pages=73-101; citation_doi=10.1214/aoms/1177703732; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_title=Robust Statistics; citation_publication_date=2011; citation_id=CR38; citation_author=PJ Huber; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Accelerating stochastic gradient descent using predictive variance reduction; citation_author=R Johnson, T Zhang; citation_volume=26; citation_publication_date=2013; citation_pages=315-323; citation_id=CR39"/>

    <meta name="citation_reference" content="Kivinen, J., Warmuth, M.K.: Additive versus exponentiated gradient updates for linear prediction. In: Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, pp. 209&#8211;218"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Signal Process.; citation_title=The p-norm generalization of the lms algorithm for adaptive filtering; citation_author=J Kivinen, MK Warmuth, B Hassibi; citation_volume=54; citation_issue=5; citation_publication_date=2006; citation_pages=1782-1793; citation_doi=10.1109/TSP.2006.872551; citation_id=CR41"/>

    <meta name="citation_reference" content="Korattikara, A., Chen, Y., Welling, M.: Austerity in mcmc land: cutting the metropolis-hastings budget. In: Proceedings of the 31st International Conference on Machine Learning, pp. 181&#8211;189 (2014)"/>

    <meta name="citation_reference" content="Kulis, B., Bartlett, P.L.: Implicit online learning. In: Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 575&#8211;582 (2010)"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Stat.; citation_title=Adaptive design and stochastic approximation; citation_author=TL Lai, H Robbins; citation_volume=7; citation_publication_date=1979; citation_pages=1196-1221; citation_doi=10.1214/aos/1176344840; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. B; citation_title=A gradient algorithm locally equivalent to the EM algorithm; citation_author=K Lange; citation_volume=57; citation_publication_date=1995; citation_pages=425-437; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_title=Numerical Analysis for Statisticians; citation_publication_date=2010; citation_id=CR46; citation_author=K Lange; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Large scale online learning; citation_author=C Le, L Bottou Yann, L Bottou; citation_volume=16; citation_publication_date=2004; citation_pages=217; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_title=Theory of Point Estimation; citation_publication_date=2003; citation_id=CR48; citation_author=EH Lehmann; citation_author=G Casella; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Li, L.: A worst-case comparison between temporal difference and residual gradient with linear function approximation. In: Proceedings of the 25th International Conference on Machine Learning, ACM, pp. 560&#8211;567"/>

    <meta name="citation_reference" content="citation_journal_title=Comput. Stat. Data Anal.; citation_title=Online em algorithm for mixture with application to internet traffic modeling; citation_author=Z Liu, J Almhana, V Choulakian, R McGorman; citation_volume=50; citation_issue=4; citation_publication_date=2006; citation_pages=1052-1071; citation_doi=10.1016/j.csda.2004.11.002; citation_id=CR50"/>

    <meta name="citation_reference" content="Ljung, L., Pflug, G., Walk, H.: Stochastic Approximation and Optimization of Random Systems, vol. 17. Springer, New York (1992)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Inf. Theory; citation_title=Robust estimation via stochastic approximation; citation_author=RD Martin, C Masreliez; citation_volume=21; citation_issue=3; citation_publication_date=1975; citation_pages=263-271; citation_doi=10.1109/TIT.1975.1055386; citation_id=CR52"/>

    <meta name="citation_reference" content="citation_title=A Statistical Study of On-line Learning; citation_publication_date=1998; citation_id=CR53; citation_author=N Murata; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Autom. Control; citation_title=A learning method for system identification; citation_author=J-I Nagumo, A Noda; citation_volume=12; citation_issue=3; citation_publication_date=1967; citation_pages=282-287; citation_doi=10.1109/TAC.1967.1098599; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_title=Frontiers in Massive Data Analysis; citation_publication_date=2013; citation_id=CR55; citation_publisher=The National Academies Press"/>

    <meta name="citation_reference" content="Neal, R.M., Hinton, G.E.: A view of the em algorithm that justifies incremental, sparse, and other variants. In: Learning in Graphical Models, pp. 355&#8211;368. Springer, New York (1998)"/>

    <meta name="citation_reference" content="Neal, R.: Mcmc Using Hamiltonian Dynamics. Handbook of Markov Chain Monte Carlo 2 (2011)"/>

    <meta name="citation_reference" content="citation_title=Problem Complexity and Method Efficiency in Optimization; citation_publication_date=1983; citation_id=CR58; citation_author=AS Nemirovski; citation_author=DB Yudin; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM J. Optim.; citation_title=Robust stochastic approximation approach to stochastic programming; citation_author=A Nemirovski, A Juditsky, G Lan, A Shapiro; citation_volume=19; citation_issue=4; citation_publication_date=2009; citation_pages=1574-1609; citation_doi=10.1137/070704277; citation_id=CR59"/>

    <meta name="citation_reference" content="citation_title=Stochastic Approximation and Recursive Estimation; citation_publication_date=1973; citation_id=CR60; citation_author=MB Nevelson; citation_author=RZ Khasminski&#301;; citation_publisher=American Mathematical Society"/>

    <meta name="citation_reference" content="Nowlan, S.J.: Soft Competitive Adaptation: Neural Network Learning Algorithms Based on Fitting Statistical Mixtures. Carnegie&#160;Mellon University, Pittsburgh (1991)"/>

    <meta name="citation_reference" content="citation_journal_title=Found. Trends Optim.; citation_title=Proximal algorithms; citation_author=N Parikh, S Boyd; citation_volume=1; citation_issue=3; citation_publication_date=2013; citation_pages=123-231; citation_id=CR62"/>

    <meta name="citation_reference" content="Pillai, N.S., Smith, A.: Ergodicity of approximate mcmc chains with applications to large data sets. arXiv preprint 
                    http://arxiv.org/abs/1405.0182
                    
                   (2014)"/>

    <meta name="citation_reference" content="citation_journal_title=Autom. Remote Control; citation_title=Adaptive algorithms of estimation (convergence, optimality, stability); citation_author=BT Polyak, YZ Tsypkin; citation_volume=3; citation_publication_date=1979; citation_pages=74-84; citation_id=CR64"/>

    <meta name="citation_reference" content="Polyak, B.T., Juditsky, A.B.: Acceleration of stochastic approximation by averaging. SIAM J. Control Optim. 30(4), 838&#8211;855 (1992)"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=A stochastic approximation method; citation_author=H Robbins, S Monro; citation_volume=22; citation_publication_date=1951; citation_pages=400-407; citation_doi=10.1214/aoms/1177729586; citation_id=CR66"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM J. Control Optim.; citation_title=Monotone operators and the proximal point algorithm; citation_author=RT Rockafellar; citation_volume=14; citation_issue=5; citation_publication_date=1976; citation_pages=877-898; citation_doi=10.1137/0314056; citation_id=CR67"/>

    <meta name="citation_reference" content="Rosasco, L., Villa, S., C&#244;ng V&#361;, B.: Convergence of stochastic proximal gradient algorithm. arXiv preprint 
                    http://arxiv.org/abs/1403.5074
                    
                  , 2014"/>

    <meta name="citation_reference" content="Ruppert, D.: Efficient estimations from a slowly convergent robbins-monro process. Technical report, Cornell University Operations Research and Industrial Engineering (1988)"/>

    <meta name="citation_reference" content="Ryu, E.K., Boyd, S.: Stochastic proximal iteration: a non-asymptotic improvement upon stochastic gradient descent. Working paper. 
                    http://web.stanford.edu/~eryu/papers/spi.pdf
                    
                   (2014)"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=Asymptotic distribution of stochastic approximation procedures; citation_author=J Sacks; citation_volume=29; citation_issue=2; citation_publication_date=1958; citation_pages=373-405; citation_doi=10.1214/aoms/1177706619; citation_id=CR71"/>

    <meta name="citation_reference" content="citation_journal_title=Int. J. Eng. Sci.; citation_title=Efficient recursive estimation; application to estimating the parameters of a covariance function; citation_author=DJ Sakrison; citation_volume=3; citation_issue=4; citation_publication_date=1965; citation_pages=461-483; citation_doi=10.1016/0020-7225(65)90029-7; citation_id=CR72"/>

    <meta name="citation_reference" content="Salakhutdinov, R., Mnih, A., Hinton, G.: Restricted boltzmann machines for collaborative filtering. In: Proceedings of the 24th International Conference on Machine Learning, ACM, pp. 791&#8211;798 (2007)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=On-line em algorithm for the normalized Gaussian network; citation_author=M-A Sato, S Ishii; citation_volume=12; citation_issue=2; citation_publication_date=2000; citation_pages=407-432; citation_doi=10.1162/089976600300015853; citation_id=CR74"/>

    <meta name="citation_reference" content="citation_journal_title=JMLR W&amp;CP; citation_title=Approximation analysis of stochastic gradient langevin dynamics by using Fokker-Planck equation and ito process; citation_author=I Sato, H Nakagawa; citation_volume=32; citation_issue=1; citation_publication_date=2014; citation_pages=982-990; citation_id=CR75"/>

    <meta name="citation_reference" content="citation_journal_title=Mach. Learn.; citation_title=On the worst-case analysis of temporal-difference learning algorithms; citation_author=RE Schapire, MK Warmuth; citation_volume=22; citation_issue=1&#8211;3; citation_publication_date=1996; citation_pages=95-121; citation_id=CR76"/>

    <meta name="citation_reference" content="Schaul, T., Zhang, S., LeCun, Y.: No more pesky learning rates. arXiv preprint. 
                    http://arxiv.org/abs/1206.1106
                    
                  , 2012"/>

    <meta name="citation_reference" content="Schraudolph, N.N., Yu, J., G&#252;nter, S.: A stochastic quasi-Newton method for online convex optimization. In: Meila M., Shen X. (eds.) Proceedings of the 11th International Conference on Artificial Intelligence and Statistics (AISTATS), vol. 2, pp. 436&#8211;443. San Juan, Puerto Rico (2007)"/>

    <meta name="citation_reference" content="Slock, D.T.M.: On the convergence behavior of the LMS and the normalized LMS algorithms. IEEE Trans. Signal Process. 41(9), 2811&#8211;2825 (1993)"/>

    <meta name="citation_reference" content="citation_journal_title=Mach. Learn.; citation_title=Learning to predict by the methods of temporal differences; citation_author=RS Sutton; citation_volume=3; citation_issue=1; citation_publication_date=1988; citation_pages=9-44; citation_id=CR80"/>

    <meta name="citation_reference" content="Tamar, A., Toulis, P., Mannor, S., Airoldi, E.: Implicit temporal differences. In: Neural Information Processing Systems, Workshop on Large-Scale Reinforcement Learning (2014)"/>

    <meta name="citation_reference" content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Modeling human motion using binary latent variables; citation_author=GW Taylor, GE Hinton, ST Roweis; citation_volume=19; citation_publication_date=2006; citation_pages=1345-1352; citation_id=CR82"/>

    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. B; citation_title=Recursive parameter estimation using incomplete data; citation_author=MD Titterington; citation_volume=46; citation_publication_date=1984; citation_pages=257-267; citation_id=CR83"/>

    <meta name="citation_reference" content="Toulis, P., Airoldi, E.M.: Implicit stochastic gradient descent for principled estimation with large datasets. arXiv preprint 
                    http://arxiv.org/abs/1408.2923
                    
                  , 2014"/>

    <meta name="citation_reference" content="citation_journal_title=JMLR W&amp;CP; citation_title=Statistical analysis of stochastic gradient methods for generalized linear models; citation_author=P Toulis, E Airoldi, J Rennie; citation_volume=32; citation_issue=1; citation_publication_date=2014; citation_pages=667-675; citation_id=CR85"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=An extension of the robbins-monro procedur; citation_author=JH Venter; citation_volume=38; citation_publication_date=1967; citation_pages=181-190; citation_doi=10.1214/aoms/1177699069; citation_id=CR86"/>

    <meta name="citation_reference" content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Variance reduction for stochastic gradient optimization; citation_author=C Wang, X Chen, A Smola, E Xing; citation_volume=26; citation_publication_date=2013; citation_pages=181-189; citation_id=CR87"/>

    <meta name="citation_reference" content="citation_journal_title=Math. Oper. Res.; citation_title=Stabilization of stochastic iterative methods for singular and nearly singular linear systems; citation_author=M Wang, DP Bertsekas; citation_volume=39; citation_issue=1; citation_publication_date=2013; citation_pages=1-30; citation_doi=10.1287/moor.2013.0596; citation_id=CR88"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Stat.; citation_title=Multivariate adaptive stochastic approximation; citation_author=CZ Wei; citation_volume=3; citation_publication_date=1987; citation_pages=1115-1130; citation_doi=10.1214/aos/1176350496; citation_id=CR89"/>

    <meta name="citation_reference" content="Welling, M., Teh, Y.W.: Bayesian learning via stochastic gradient langevin dynamics. In: Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 681&#8211;688 (2011)"/>

    <meta name="citation_reference" content="Xu, W.: Towards optimal one pass large scale learning with averaged stochastic gradient descent. arXiv preprint 
                    http://arxiv.org/abs/1107.2490
                    
                  , 2011"/>

    <meta name="citation_reference" content="Younes, L.: On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates. Stochastics 65(3&#8211;4), 177&#8211;228 (1999)"/>

    <meta name="citation_reference" content="Zhang, T.: Solving large scale linear prediction problems using stochastic gradient descent algorithms. In: Proceedings of the Twenty-First International Conference on Machine Learning, ACM, p. 116 (2004)"/>

    <meta name="citation_author" content="Panos Toulis"/>

    <meta name="citation_author_email" content="ptoulis@fas.harvard.edu"/>

    <meta name="citation_author_institution" content="Department of Statistics, Harvard University, Cambridge, USA"/>

    <meta name="citation_author" content="Edoardo M. Airoldi"/>

    <meta name="citation_author_email" content="airoldi@fas.harvard.edu"/>

    <meta name="citation_author_institution" content="Department of Statistics, Harvard University, Cambridge, USA"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Scalable estimation strategies based on stochastic approximations: cla"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Estimation with large amounts of data can be facilitated by stochastic gradient methods, in which model parameters are updated sequentially using small batches of data at each step. Here, we review early work and modern results that illustrate the statistical properties of these methods, including convergence rates, stability, and asymptotic bias and variance. We then overview modern applications where these methods are useful, ranging from an online version of the EM algorithm to deep learning. In light of these results, we argue that stochastic gradient methods are poised to become benchmark principled estimation procedures for large datasets, especially those in the family of stable proximal methods, such as implicit stochastic gradient descent."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/11222/25/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s11222-015-9560-y&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2015/07/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s11222-015-9560-y"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Statistics and Computing"/>
        <meta property="og:title" content="Scalable estimation strategies based on stochastic approximations: classical results and new insights"/>
        <meta property="og:description" content="Estimation with large amounts of data can be facilitated by stochastic gradient methods, in which model parameters are updated sequentially using small batches of data at each step. Here, we review early work and modern results that illustrate the statistical properties of these methods, including convergence rates, stability, and asymptotic bias and variance. We then overview modern applications where these methods are useful, ranging from an online version of the EM algorithm to deep learning. In light of these results, we argue that stochastic gradient methods are poised to become benchmark principled estimation procedures for large datasets, especially those in the family of stable proximal methods, such as implicit stochastic gradient descent."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/11222.jpg"/>
    

    <title>Scalable estimation strategies based on stochastic approximations: classical results and new insights | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-c36432aacc.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-ca71d04fc0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"IT","doi":"10.1007-s11222-015-9560-y","Journal Title":"Statistics and Computing","Journal Id":11222,"Keywords":"Maximum likelihood, Recursive estimation, Implicit stochastic gradient descent methods, Optimal learning rate, Asymptotic analysis, Big data","kwrd":["Maximum_likelihood","Recursive_estimation","Implicit_stochastic_gradient_descent_methods","Optimal_learning_rate","Asymptotic_analysis","Big_data"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"no-access","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s11222-015-9560-y","Full HTML":"N","Subject Codes":["SCS","SCS12008","SCI21000","SCS11001","SCI17036"],"pmc":["S","S12008","I21000","S11001","I17036"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-1375","pissn":"0960-3174"},"type":"Article","category":{"pmc":{"primarySubject":"Statistics","primarySubjectCode":"S","secondarySubjects":{"1":"Statistics and Computing/Statistics Programs","2":"Artificial Intelligence","3":"Statistical Theory and Methods","4":"Probability and Statistics in Computer Science"},"secondarySubjectCodes":{"1":"S12008","2":"I21000","3":"S11001","4":"I17036"}},"sucode":"SC10"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s11222-015-9560-y","Page":"article"}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return !(scriptEl.hasOwnProperty('noModule')) && scriptEl.hasOwnProperty('onbeforeload');
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-5a82bc1fe4.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-cba6a3f7dc.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-0c761bb6f7.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-db63800f6b.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-675d268b68.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-0d579dbecb.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
<div class="c-ad c-ad--LB1" data-test="springer-doubleclick-ad">
    <div class="c-ad c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/11222/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=9560;"></div>
    </div>
</div>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="true"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs11222-015-9560-y">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="c-banner c-banner--marketing">
	<div class="u-container">
		<p class="u-ma-0">
			We'd like to understand how you use our websites in order to improve them.
			<a class="c-banner__link u-underline"
				href="https://www.surveymonkey.co.uk/r/F2JMQ6L" data-track="click"
				data-track-action="Survey click" data-track-category="Blue Banner"
				data-track-label=10.1007/s11222-015-9560-y>Register your interest.</a>
		</p>
	</div>
</div>
    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">

        <main class="c-article-main-column u-float-left js-main-column">
            
            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-category="article body" data-track-label="link">Published: <time datetime="2015-06-11" itemprop="datePublished">11 June 2015</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Scalable estimation strategies based on stochastic approximations: classical results and new insights</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-1">Panos Toulis</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Harvard University" /><meta itemprop="address" content="grid.38142.3c, 000000041936754X, Department of Statistics, Harvard University, Cambridge, MA, 02138, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-2" data-corresp-id="c1">Edoardo M. Airoldi<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Harvard University" /><meta itemprop="address" content="grid.38142.3c, 000000041936754X, Department of Statistics, Harvard University, Cambridge, MA, 02138, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/11222"><i data-test="journal-title">Statistics and Computing</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 25</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">781</span>–<span itemprop="pageEnd">795</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-inline">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">863 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">13 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">9 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs11222-015-9560-y/metrics" data-track="click" data-track-action="view metrics" data-track-category="article body" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Estimation with large amounts of data can be facilitated by stochastic gradient methods, in which model parameters are updated sequentially using small batches of data at each step. Here, we review early work and modern results that illustrate the statistical properties of these methods, including convergence rates, stability, and asymptotic bias and variance. We then overview modern applications where these methods are useful, ranging from an online version of the EM algorithm to deep learning. In light of these results, we argue that stochastic gradient methods are poised to become benchmark principled estimation procedures for large datasets, especially those in the family of stable proximal methods, such as implicit stochastic gradient descent.</p></div></div></section>
                    
    


                    
                        
                            <div class="c-notes">
                                <p class="c-notes__text">This is a preview of subscription content, <a id="test-login-banner-link" href="//link.springer.com/signup-login?previousUrl&#x3D;https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs11222-015-9560-y" data-track="click" data-track-action="login" data-track-label="link">log in</a> to check access.</p>
                            </div>
                        
                        
                            <div class="c-article-buy-box c-article-buy-box--article">
                                <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">42,64 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/s11222-015-9560-y">
     <input type="hidden" name="isxn" value="1573-1375">
     <input type="hidden" name="contenttitle" value="Scalable estimation strategies based on stochastic approximations: classical results and new insights">
     <input type="hidden" name="copyrightyear" value="2015">
     <input type="hidden" name="year" value="2015">
     <input type="hidden" name="authors" value="Panos Toulis, Edoardo M. Airoldi">
     <input type="hidden" name="title" value="Statistics and Computing">
     <input type="hidden" name="mac" value="9D8C2C87C0178A6A91EC47E4595DD9A8">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action, new buybox" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">81 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="Statistics and Computing">
     <input type="hidden" name="journalnumber" value="11222">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/s11222-015-9560-y&journal=1573-1375&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                            </div>
                        
                        <div class="u-display-none">
                            
                        </div>
                    

                    

                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Second-order methods typically use the Hessian matrix of second-order derivatives of the log-likelihood and are discussed in detail in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11222-015-9560-y#Sec5">3</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>Procedure (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11222-015-9560-y#Equ2">2</a>) is actually an ascent algorithm because it aims to maximize the log-likelihood, and thus a more appropriate name would be stochastic gradient ascent. However, we will use the term “descent” in order to keep in line with the relevant optimization literature, which traditionally considers minimization problems through descent algorithms.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>The solution of the fixed-point equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11222-015-9560-y#Equ3">3</a>) requires additional computations per iterations. However, Toulis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Toulis, P., Airoldi, E., Rennie, J.: Statistical analysis of stochastic gradient methods for generalized linear models. JMLR W&amp;CP 32(1), 667–675 (2014)" href="/article/10.1007/s11222-015-9560-y#ref-CR85" id="ref-link-section-d59022e2522">2014</a>) derive a computationally efficient implicit algorithm in the context of generalized linear models. Furthermore, approximate solutions of implicit updates are possible for any statistical model (see Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11222-015-9560-y#Equ4">4</a>)).</p></div></li><li class="c-article-footnote--listed__item" id="Fn4"><span class="c-article-footnote--listed__index">4.</span><div class="c-article-footnote--listed__content"><p>This is an important distinction because, traditionally, the focus in optimization has been to obtain fast convergence to some point <span class="mathjax-tex">\(\widehat{\varvec{\theta }}\)</span> that minimizes the empirical loss, e.g., the maximum-likelihood estimator. From a statistical viewpoint, under variability of the data, there is a trade-off between convergence to an estimator and its asymptotic variance (Le et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Le, C., Bottou Yann, L., Bottou, L.: Large scale online learning. Adv. Neural Inf. Process. Syst. 16, 217 (2004)" href="/article/10.1007/s11222-015-9560-y#ref-CR47" id="ref-link-section-d59022e7429">2004</a>).</p></div></li><li class="c-article-footnote--listed__item" id="Fn5"><span class="c-article-footnote--listed__index">5.</span><div class="c-article-footnote--listed__content"><p>Similarly, a sequence of matrices <span class="mathjax-tex">\({\varvec{C}}_n\)</span> can be designed such that <span class="mathjax-tex">\({\varvec{C}}_n \rightarrow \varvec{\mathcal {I}}(\varvec{\theta _\star })^{-1}\)</span> (Sakrison <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1965" title="Sakrison, D.J.: Efficient recursive estimation; application to estimating the parameters of a covariance function. Int. J. Eng. Sci. 3(4), 461–483 (1965)" href="/article/10.1007/s11222-015-9560-y#ref-CR72" id="ref-link-section-d59022e16820">1965</a>).</p></div></li><li class="c-article-footnote--listed__item" id="Fn6"><span class="c-article-footnote--listed__index">6.</span><div class="c-article-footnote--listed__content"><p>The acronym ASGD is also used in machine learning to denote <i>asynchronous</i> SGD i.e., a variant of SGD that can be parallelized on multiple machines. We will not consider this variant here.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S-I. Amari, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Amari, S.-I.: Natural gradient works efficiently in learning. Neural Comput. 10(2), 251–276 (1998)" /><p class="c-article-references__text" id="ref-CR1">Amari, S.-I.: Natural gradient works efficiently in learning. Neural Comput. <b>10</b>(2), 251–276 (1998)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=653513" aria-label="View reference 1 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1162%2F089976698300017746" aria-label="View reference 1">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20gradient%20works%20efficiently%20in%20learning&amp;journal=Neural%20Comput.&amp;volume=10&amp;issue=2&amp;pages=251-276&amp;publication_year=1998&amp;author=Amari%2CS-I">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S-I. Amari, H. Park, F. Kenji, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Amari, S.-I., Park, H., Kenji, F.: Adaptive method of realizing natural gradient learning for multilayer perce" /><p class="c-article-references__text" id="ref-CR2">Amari, S.-I., Park, H., Kenji, F.: Adaptive method of realizing natural gradient learning for multilayer perceptrons. Neural Comput. <b>12</b>(6), 1399–1409 (2000)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1162%2F089976600300015420" aria-label="View reference 2">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20method%20of%20realizing%20natural%20gradient%20learning%20for%20multilayer%20perceptrons&amp;journal=Neural%20Comput.&amp;volume=12&amp;issue=6&amp;pages=1399-1409&amp;publication_year=2000&amp;author=Amari%2CS-I&amp;author=Park%2CH&amp;author=Kenji%2CF">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JA. Bather, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Bather, J.A.: Stochastic Approximation: A Generalisation of the Robbins–Monro Procedure, vol. 89. Cornell Univ" /><p class="c-article-references__text" id="ref-CR3">Bather, J.A.: Stochastic Approximation: A Generalisation of the Robbins–Monro Procedure, vol. 89. Cornell University, Mathematical Sciences Institute, New York (1989)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stochastic%20Approximation%3A%20A%20Generalisation%20of%20the%20Robbins%E2%80%93Monro%20Procedure&amp;publication_year=1989&amp;author=Bather%2CJA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Beck, M. Teboulle, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Beck, A., Teboulle, M.: Mirror descent and nonlinear projected subgradient methods for convex optimization. Op" /><p class="c-article-references__text" id="ref-CR4">Beck, A., Teboulle, M.: Mirror descent and nonlinear projected subgradient methods for convex optimization. Oper. Res. Lett. <b>31</b>(3), 167–175 (2003)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1046.90057" aria-label="View reference 4 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1967286" aria-label="View reference 4 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2FS0167-6377%2802%2900231-6" aria-label="View reference 4">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mirror%20descent%20and%20nonlinear%20projected%20subgradient%20methods%20for%20convex%20optimization&amp;journal=Oper.%20Res.%20Lett.&amp;volume=31&amp;issue=3&amp;pages=167-175&amp;publication_year=2003&amp;author=Beck%2CA&amp;author=Teboulle%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Bengio, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Bengio, Y.: Learning deep architectures for ai. Foundations and trends \(\textregistered \). Mach. Learn. 2, 1" /><p class="c-article-references__text" id="ref-CR5">Bengio, Y.: Learning deep architectures for ai. Foundations and trends <span class="mathjax-tex">\(\textregistered \)</span>. Mach. Learn. <b>2</b>, 1–127 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1192.68503" aria-label="View reference 5 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1561%2F2200000006" aria-label="View reference 5">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20deep%20architectures%20for%20ai.%20Foundations%20and%20trends%20%24%24%5Ctextregistered%20%24%24%20%C2%AE&amp;journal=Mach.%20Learn.&amp;volume=2&amp;pages=1-127&amp;publication_year=2009&amp;author=Bengio%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Bengio, O. Delalleau, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Bengio, Y., Delalleau, O.: Justifying and generalizing contrastive divergence. Neural Comput. 21(6), 1601–1621" /><p class="c-article-references__text" id="ref-CR6">Bengio, Y., Delalleau, O.: Justifying and generalizing contrastive divergence. Neural Comput. <b>21</b>(6), 1601–1621 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1183.68463" aria-label="View reference 6 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2527797" aria-label="View reference 6 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1162%2Fneco.2008.11-07-647" aria-label="View reference 6">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Justifying%20and%20generalizing%20contrastive%20divergence&amp;journal=Neural%20Comput.&amp;volume=21&amp;issue=6&amp;pages=1601-1621&amp;publication_year=2009&amp;author=Bengio%2CY&amp;author=Delalleau%2CO">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Benveniste, M. Métivier, P. Priouret, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Benveniste, A., Métivier, M., Priouret, P.: Adaptive Algorithms and Stochastic Approximations. Springer Publis" /><p class="c-article-references__text" id="ref-CR7">Benveniste, A., Métivier, M., Priouret, P.: Adaptive Algorithms and Stochastic Approximations. Springer Publishing Company, Incorporated, New York (2012)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20Algorithms%20and%20Stochastic%20Approximations&amp;publication_year=2012&amp;author=Benveniste%2CA&amp;author=M%C3%A9tivier%2CM&amp;author=Priouret%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bertsekas, D.P., Tsitsiklis, J.N.: Neuro-dynamic programming: an overview. In: Proceedings of the 34th IEEE Co" /><p class="c-article-references__text" id="ref-CR8">Bertsekas, D.P., Tsitsiklis, J.N.: Neuro-dynamic programming: an overview. In: Proceedings of the 34th IEEE Conference on Decision and Control, vol. 1, pp. 560–564 (1995)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Bordes, L. Bottou, P. Gallinari, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Bordes, A., Bottou, L., Gallinari, P.: Sgd-qn: careful quasi-Newton stochastic gradient descent. J. Mach. Lear" /><p class="c-article-references__text" id="ref-CR9">Bordes, A., Bottou, L., Gallinari, P.: Sgd-qn: careful quasi-Newton stochastic gradient descent. J. Mach. Learn. Res. <b>10</b>, 1737–1754 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1235.68130" aria-label="View reference 9 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2534877" aria-label="View reference 9 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sgd-qn%3A%20careful%20quasi-Newton%20stochastic%20gradient%20descent&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=10&amp;pages=1737-1754&amp;publication_year=2009&amp;author=Bordes%2CA&amp;author=Bottou%2CL&amp;author=Gallinari%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bottou, L.: Large-scale machine learning with stochastic gradient descent. In: Proceedings of COMPSTAT’2010, p" /><p class="c-article-references__text" id="ref-CR10">Bottou, L.: Large-scale machine learning with stochastic gradient descent. In: Proceedings of COMPSTAT’2010, pp. 177–186. Springer, New York (2010)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Bottou, Y. Cun, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Bottou, L., Le Cun, Y.: On-line learning for very large data sets. Appl. Stoch. Models Bus. Ind. 21(2), 137–15" /><p class="c-article-references__text" id="ref-CR11">Bottou, L., Le Cun, Y.: On-line learning for very large data sets. Appl. Stoch. Models Bus. Ind. <b>21</b>(2), 137–151 (2005)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1091.68063" aria-label="View reference 11 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2137546" aria-label="View reference 11 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fasmb.538" aria-label="View reference 11">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On-line%20learning%20for%20very%20large%20data%20sets&amp;journal=Appl.%20Stoch.%20Models%20Bus.%20Ind.&amp;volume=21&amp;issue=2&amp;pages=137-151&amp;publication_year=2005&amp;author=Bottou%2CL&amp;author=Cun%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Bousquet, L. Bottou, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Bousquet, O., Bottou, L.: The tradeoffs of large scale learning. Adv. Neural Inf. Process. Syst. 20, 161–168 (" /><p class="c-article-references__text" id="ref-CR12">Bousquet, O., Bottou, L.: The tradeoffs of large scale learning. Adv. Neural Inf. Process. Syst. <b>20</b>, 161–168 (2008)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20tradeoffs%20of%20large%20scale%20learning&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=20&amp;pages=161-168&amp;publication_year=2008&amp;author=Bousquet%2CO&amp;author=Bottou%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CG. Broyden, " /><meta itemprop="datePublished" content="1965" /><meta itemprop="headline" content="Broyden, C.G.: A class of methods for solving nonlinear simultaneous equations. Math. Comput. 19, 577–593 (196" /><p class="c-article-references__text" id="ref-CR13">Broyden, C.G.: A class of methods for solving nonlinear simultaneous equations. Math. Comput. <b>19</b>, 577–593 (1965)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0131.13905" aria-label="View reference 13 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=198670" aria-label="View reference 13 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1090%2FS0025-5718-1965-0198670-6" aria-label="View reference 13">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20class%20of%20methods%20for%20solving%20nonlinear%20simultaneous%20equations&amp;journal=Math.%20Comput.&amp;volume=19&amp;pages=577-593&amp;publication_year=1965&amp;author=Broyden%2CCG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Cappé, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Cappé, O.: Online em algorithm for hidden Markov models. J. Comput. Graph. Stat. 20(3), 728–749 (2011)" /><p class="c-article-references__text" id="ref-CR14">Cappé, O.: Online em algorithm for hidden Markov models. J. Comput. Graph. Stat. <b>20</b>(3), 728–749 (2011)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1198%2Fjcgs.2011.09109" aria-label="View reference 14">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Online%20em%20algorithm%20for%20hidden%20Markov%20models&amp;journal=J.%20Comput.%20Graph.%20Stat.&amp;volume=20&amp;issue=3&amp;pages=728-749&amp;publication_year=2011&amp;author=Capp%C3%A9%2CO">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Cappé, M. Moulines, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Cappé, O., Moulines, M.: On-line expectation-maximization algorithm for latent data models. J. R. Stat. Soc. 7" /><p class="c-article-references__text" id="ref-CR15">Cappé, O., Moulines, M.: On-line expectation-maximization algorithm for latent data models. J. R. Stat. Soc. <b>71</b>(3), 593–613 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1250.62015" aria-label="View reference 15 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2749909" aria-label="View reference 15 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-9868.2009.00698.x" aria-label="View reference 15">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On-line%20expectation-maximization%20algorithm%20for%20latent%20data%20models&amp;journal=J.%20R.%20Stat.%20Soc.&amp;volume=71&amp;issue=3&amp;pages=593-613&amp;publication_year=2009&amp;author=Capp%C3%A9%2CO&amp;author=Moulines%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Carreira-Perpinan, M.A., Hinton, G.E.: On contrastive divergence learning. In: Proceedings of the Tenth Intern" /><p class="c-article-references__text" id="ref-CR16">Carreira-Perpinan, M.A., Hinton, G.E.: On contrastive divergence learning. In: Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics, pp. 33–40. Citeseer (2005)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cheng, L., Vishwanathan, S.V.N., Schuurmans, D., Wang, S., Caelli, T.: Implicit online learning with kernels. " /><p class="c-article-references__text" id="ref-CR17">Cheng, L., Vishwanathan, S.V.N., Schuurmans, D., Wang, S., Caelli, T.: Implicit online learning with kernels. In: Proceedings of the 2006 Conference Advances in Neural Information Processing Systems 19, vol. 19, p. 249. MIT Press, Cambridge, 2007</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KL. Chung, " /><meta itemprop="datePublished" content="1954" /><meta itemprop="headline" content="Chung, K.L.: On a stochastic approximation method. Ann. Math. Stat. 25, 463–483 (1954)" /><p class="c-article-references__text" id="ref-CR18">Chung, K.L.: On a stochastic approximation method. Ann. Math. Stat. <b>25</b>, 463–483 (1954)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0059.13203" aria-label="View reference 18 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177728716" aria-label="View reference 18">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20a%20stochastic%20approximation%20method&amp;journal=Ann.%20Math.%20Stat.&amp;volume=25&amp;pages=463-483&amp;publication_year=1954&amp;author=Chung%2CKL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Dempster, N. Laird, D. Rubin, " /><meta itemprop="datePublished" content="1977" /><meta itemprop="headline" content="Dempster, A., Laird, N., Rubin, D.: Maximum likelihood from incomplete data via the EM algorithm. J. R. Stat. " /><p class="c-article-references__text" id="ref-CR19">Dempster, A., Laird, N., Rubin, D.: Maximum likelihood from incomplete data via the EM algorithm. J. R. Stat. Soc. Ser. B <b>39</b>, 1–38 (1977)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0364.62022" aria-label="View reference 19 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=501537" aria-label="View reference 19 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Maximum%20likelihood%20from%20incomplete%20data%20via%20the%20EM%20algorithm&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20B&amp;volume=39&amp;pages=1-38&amp;publication_year=1977&amp;author=Dempster%2CA&amp;author=Laird%2CN&amp;author=Rubin%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Duchi, E. Hazan, Y. Singer, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning and stochastic optimization" /><p class="c-article-references__text" id="ref-CR20">Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning and stochastic optimization. J. Mach. Learn. Res. <b>999999</b>, 2121–2159 (2011)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2825422" aria-label="View reference 20 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=999999&amp;pages=2121-2159&amp;publication_year=2011&amp;author=Duchi%2CJ&amp;author=Hazan%2CE&amp;author=Singer%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Dupuis, R. Simha, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Dupuis, P., Simha, R.: On sampling controlled stochastic approximation. IEEE Trans. Autom. Control 36(8), 915–" /><p class="c-article-references__text" id="ref-CR21">Dupuis, P., Simha, R.: On sampling controlled stochastic approximation. IEEE Trans. Autom. Control <b>36</b>(8), 915–924 (1991)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0749.93081" aria-label="View reference 21 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1116448" aria-label="View reference 21 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2F9.133185" aria-label="View reference 21">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20sampling%20controlled%20stochastic%20approximation&amp;journal=IEEE%20Trans.%20Autom.%20Control&amp;volume=36&amp;issue=8&amp;pages=915-924&amp;publication_year=1991&amp;author=Dupuis%2CP&amp;author=Simha%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. El Karoui, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="El Karoui, N.: Spectrum estimation for large dimensional covariance matrices using random matrix theory. Ann. " /><p class="c-article-references__text" id="ref-CR22">El Karoui, N.: Spectrum estimation for large dimensional covariance matrices using random matrix theory. Ann. Stat. <b>36</b>, 2757–2790 (2008)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1168.62052" aria-label="View reference 22 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2485012" aria-label="View reference 22 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2F07-AOS581" aria-label="View reference 22">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spectrum%20estimation%20for%20large%20dimensional%20covariance%20matrices%20using%20random%20matrix%20theory&amp;journal=Ann.%20Stat.&amp;volume=36&amp;pages=2757-2790&amp;publication_year=2008&amp;author=El%20Karoui%2CN">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Fabian, " /><meta itemprop="datePublished" content="1968" /><meta itemprop="headline" content="Fabian, V.: On asymptotic normality in stochastic approximation. Ann. Math. Stat. 39, 1327–1332 (1968)" /><p class="c-article-references__text" id="ref-CR23">Fabian, V.: On asymptotic normality in stochastic approximation. Ann. Math. Stat. <b>39</b>, 1327–1332 (1968)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0176.48402" aria-label="View reference 23 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=231429" aria-label="View reference 23 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177698258" aria-label="View reference 23">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20asymptotic%20normality%20in%20stochastic%20approximation&amp;journal=Ann.%20Math.%20Stat.&amp;volume=39&amp;pages=1327-1332&amp;publication_year=1968&amp;author=Fabian%2CV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Fabian, " /><meta itemprop="datePublished" content="1973" /><meta itemprop="headline" content="Fabian, V.: Asymptotically efficient stochastic approximation; the RM case. Ann. Stat. 1, 486–495 (1973)" /><p class="c-article-references__text" id="ref-CR24">Fabian, V.: Asymptotically efficient stochastic approximation; the RM case. Ann. Stat. <b>1</b>, 486–495 (1973)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0258.62048" aria-label="View reference 24 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=381189" aria-label="View reference 24 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176342414" aria-label="View reference 24">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Asymptotically%20efficient%20stochastic%20approximation%3B%20the%20RM%20case&amp;journal=Ann.%20Stat.&amp;volume=1&amp;pages=486-495&amp;publication_year=1973&amp;author=Fabian%2CV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Fisher, " /><meta itemprop="datePublished" content="1922" /><meta itemprop="headline" content="Fisher, R.A.: On the mathematical foundations of theoretical statistics. Philos. Trans. R. Soc. Lond. Ser. A 2" /><p class="c-article-references__text" id="ref-CR25">Fisher, R.A.: On the mathematical foundations of theoretical statistics. Philos. Trans. R. Soc. Lond. Ser. A <b>222</b>, 309–368 (1922)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?JFM%2048.1280.02" aria-label="View reference 25 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1098%2Frsta.1922.0009" aria-label="View reference 25">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20mathematical%20foundations%20of%20theoretical%20statistics&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20Ser.%20A&amp;volume=222&amp;pages=309-368&amp;publication_year=1922&amp;author=Fisher%2CRA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RA. Fisher, " /><meta itemprop="datePublished" content="1925" /><meta itemprop="headline" content="Fisher, R.A.: Statistical Methods for Research Workers. Oliver and Boyd, Edinburgh (1925a)" /><p class="c-article-references__text" id="ref-CR26">Fisher, R.A.: Statistical Methods for Research Workers. Oliver and Boyd, Edinburgh (1925a)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistical%20Methods%20for%20Research%20Workers&amp;publication_year=1925&amp;author=Fisher%2CRA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fisher, R.A.: Theory of statistical estimation. In: Mathematical Proceedings of the Cambridge Philosophical So" /><p class="c-article-references__text" id="ref-CR27">Fisher, R.A.: Theory of statistical estimation. In: Mathematical Proceedings of the Cambridge Philosophical Society, vol. 22, pp. 700–725. Cambridge University Press, Cambridge (1925b)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Geman, D. Geman, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Geman, S., Geman, D.: Stochastic relaxation, gibbs distributions, and the Bayesian restoration of images. IEEE" /><p class="c-article-references__text" id="ref-CR28">Geman, S., Geman, D.: Stochastic relaxation, gibbs distributions, and the Bayesian restoration of images. IEEE Trans. Pattern Anal. Mach. Intell. <b>6</b>, 721–741 (1984)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0573.62030" aria-label="View reference 28 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTPAMI.1984.4767596" aria-label="View reference 28">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stochastic%20relaxation%2C%20gibbs%20distributions%2C%20and%20the%20Bayesian%20restoration%20of%20images&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.&amp;volume=6&amp;pages=721-741&amp;publication_year=1984&amp;author=Geman%2CS&amp;author=Geman%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AP. George, WB. Powell, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="George, A.P., Powell, W.B.: Adaptive stepsizes for recursive estimation with applications in approximate dynam" /><p class="c-article-references__text" id="ref-CR29">George, A.P., Powell, W.B.: Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming. Machine Learn. <b>65</b>(1), 167–198 (2006)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs10994-006-8365-9" aria-label="View reference 29">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20stepsizes%20for%20recursive%20estimation%20with%20applications%20in%20approximate%20dynamic%20programming&amp;journal=Machine%20Learn.&amp;volume=65&amp;issue=1&amp;pages=167-198&amp;publication_year=2006&amp;author=George%2CAP&amp;author=Powell%2CWB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Girolami, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Girolami, M.: Riemann manifold Langevin and Hamiltonian Monte Carlo methods. J. R. Stat. Soc. Ser. B 73(2), 12" /><p class="c-article-references__text" id="ref-CR30">Girolami, M.: Riemann manifold Langevin and Hamiltonian Monte Carlo methods. J. R. Stat. Soc. Ser. B <b>73</b>(2), 123–214 (2011)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2814492" aria-label="View reference 30 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-9868.2010.00765.x" aria-label="View reference 30">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Riemann%20manifold%20Langevin%20and%20Hamiltonian%20Monte%20Carlo%20methods&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20B&amp;volume=73&amp;issue=2&amp;pages=123-214&amp;publication_year=2011&amp;author=Girolami%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Gosavi, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Gosavi, A.: Reinforcement learning: a tutorial survey and recent advances. INFORMS J. Comput. 21(2), 178–192 (" /><p class="c-article-references__text" id="ref-CR31">Gosavi, A.: Reinforcement learning: a tutorial survey and recent advances. INFORMS J. Comput. <b>21</b>(2), 178–192 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1243.68240" aria-label="View reference 31 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2549123" aria-label="View reference 31 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1287%2Fijoc.1080.0305" aria-label="View reference 31">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%3A%20a%20tutorial%20survey%20and%20recent%20advances&amp;journal=INFORMS%20J.%20Comput.&amp;volume=21&amp;issue=2&amp;pages=178-192&amp;publication_year=2009&amp;author=Gosavi%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PJ. Green, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Green, P.J.: Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resis" /><p class="c-article-references__text" id="ref-CR32">Green, P.J.: Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives. J. R. Stat. Soc. Ser. B <b>46</b>, 149–192 (1984)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0555.62028" aria-label="View reference 32 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Iteratively%20reweighted%20least%20squares%20for%20maximum%20likelihood%20estimation%2C%20and%20some%20robust%20and%20resistant%20alternatives&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20B&amp;volume=46&amp;pages=149-192&amp;publication_year=1984&amp;author=Green%2CPJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Hastie, R. Tibshirani, J. Friedman, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Hastie, T., Tibshirani, R., Friedman, J.: The Elements of Statistical Learning: Data Mining, Inference, and Pr" /><p class="c-article-references__text" id="ref-CR33">Hastie, T., Tibshirani, R., Friedman, J.: The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd edn. Springer, New York (2011)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Elements%20of%20Statistical%20Learning%3A%20Data%20Mining%2C%20Inference%2C%20and%20Prediction&amp;publication_year=2011&amp;author=Hastie%2CT&amp;author=Tibshirani%2CR&amp;author=Friedman%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Hennig, M. Kiefel, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Hennig, P., Kiefel, M.: Quasi-Newton methods: a new direction. J. Mach. Learn. Res. 14(1), 843–865 (2013)" /><p class="c-article-references__text" id="ref-CR34">Hennig, P., Kiefel, M.: Quasi-Newton methods: a new direction. J. Mach. Learn. Res. <b>14</b>(1), 843–865 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?06276255" aria-label="View reference 34 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3049491" aria-label="View reference 34 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Quasi-Newton%20methods%3A%20a%20new%20direction&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=14&amp;issue=1&amp;pages=843-865&amp;publication_year=2013&amp;author=Hennig%2CP&amp;author=Kiefel%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GE. Hinton, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Hinton, G.E.: Training products of experts by minimizing contrastive divergence. Neural Comput. 14(8), 1771–18" /><p class="c-article-references__text" id="ref-CR35">Hinton, G.E.: Training products of experts by minimizing contrastive divergence. Neural Comput. <b>14</b>(8), 1771–1800 (2002)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1010.68111" aria-label="View reference 35 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2978160" aria-label="View reference 35 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1162%2F089976602760128018" aria-label="View reference 35">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20products%20of%20experts%20by%20minimizing%20contrastive%20divergence&amp;journal=Neural%20Comput.&amp;volume=14&amp;issue=8&amp;pages=1771-1800&amp;publication_year=2002&amp;author=Hinton%2CGE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MD. Hoffman, DM. Blei, C. Wang, J. Paisley, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Hoffman, M.D., Blei, D.M., Wang, C., Paisley, J.: Stochastic variational inference. J. Mach. Learn. Res. 14(1)" /><p class="c-article-references__text" id="ref-CR36">Hoffman, M.D., Blei, D.M., Wang, C., Paisley, J.: Stochastic variational inference. J. Mach. Learn. Res. <b>14</b>(1), 1303–1347 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?06377992" aria-label="View reference 36 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3081926" aria-label="View reference 36 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stochastic%20variational%20inference&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=14&amp;issue=1&amp;pages=1303-1347&amp;publication_year=2013&amp;author=Hoffman%2CMD&amp;author=Blei%2CDM&amp;author=Wang%2CC&amp;author=Paisley%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PJ. Huber, " /><meta itemprop="datePublished" content="1964" /><meta itemprop="headline" content="Huber, P.J., et al.: Robust estimation of a location parameter. Ann. Math. Stat. 35(1), 73–101 (1964)" /><p class="c-article-references__text" id="ref-CR37">Huber, P.J., et al.: Robust estimation of a location parameter. Ann. Math. Stat. <b>35</b>(1), 73–101 (1964)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0136.39805" aria-label="View reference 37 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177703732" aria-label="View reference 37">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20estimation%20of%20a%20location%20parameter&amp;journal=Ann.%20Math.%20Stat.&amp;volume=35&amp;issue=1&amp;pages=73-101&amp;publication_year=1964&amp;author=Huber%2CPJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="PJ. Huber, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Huber, P.J.: Robust Statistics. Springer, New York (2011)" /><p class="c-article-references__text" id="ref-CR38">Huber, P.J.: Robust Statistics. Springer, New York (2011)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20Statistics&amp;publication_year=2011&amp;author=Huber%2CPJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Johnson, T. Zhang, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Johnson, R., Zhang, T.: Accelerating stochastic gradient descent using predictive variance reduction. Adv. Neu" /><p class="c-article-references__text" id="ref-CR39">Johnson, R., Zhang, T.: Accelerating stochastic gradient descent using predictive variance reduction. Adv. Neural Inf. Process. Syst. <b>26</b>, 315–323 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Accelerating%20stochastic%20gradient%20descent%20using%20predictive%20variance%20reduction&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=26&amp;pages=315-323&amp;publication_year=2013&amp;author=Johnson%2CR&amp;author=Zhang%2CT">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kivinen, J., Warmuth, M.K.: Additive versus exponentiated gradient updates for linear prediction. In: Proceedi" /><p class="c-article-references__text" id="ref-CR40">Kivinen, J., Warmuth, M.K.: Additive versus exponentiated gradient updates for linear prediction. In: Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, pp. 209–218</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Kivinen, MK. Warmuth, B. Hassibi, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Kivinen, J., Warmuth, M.K., Hassibi, B.: The p-norm generalization of the lms algorithm for adaptive filtering" /><p class="c-article-references__text" id="ref-CR41">Kivinen, J., Warmuth, M.K., Hassibi, B.: The p-norm generalization of the lms algorithm for adaptive filtering. IEEE Trans. Signal Process. <b>54</b>(5), 1782–1793 (2006)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTSP.2006.872551" aria-label="View reference 41">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20p-norm%20generalization%20of%20the%20lms%20algorithm%20for%20adaptive%20filtering&amp;journal=IEEE%20Trans.%20Signal%20Process.&amp;volume=54&amp;issue=5&amp;pages=1782-1793&amp;publication_year=2006&amp;author=Kivinen%2CJ&amp;author=Warmuth%2CMK&amp;author=Hassibi%2CB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Korattikara, A., Chen, Y., Welling, M.: Austerity in mcmc land: cutting the metropolis-hastings budget. In: Pr" /><p class="c-article-references__text" id="ref-CR42">Korattikara, A., Chen, Y., Welling, M.: Austerity in mcmc land: cutting the metropolis-hastings budget. In: Proceedings of the 31st International Conference on Machine Learning, pp. 181–189 (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kulis, B., Bartlett, P.L.: Implicit online learning. In: Proceedings of the 27th International Conference on M" /><p class="c-article-references__text" id="ref-CR43">Kulis, B., Bartlett, P.L.: Implicit online learning. In: Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 575–582 (2010)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TL. Lai, H. Robbins, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Lai, T.L., Robbins, H.: Adaptive design and stochastic approximation. Ann. Stat. 7, 1196–1221 (1979)" /><p class="c-article-references__text" id="ref-CR44">Lai, T.L., Robbins, H.: Adaptive design and stochastic approximation. Ann. Stat. <b>7</b>, 1196–1221 (1979)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0426.62059" aria-label="View reference 44 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=550144" aria-label="View reference 44 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176344840" aria-label="View reference 44">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20design%20and%20stochastic%20approximation&amp;journal=Ann.%20Stat.&amp;volume=7&amp;pages=1196-1221&amp;publication_year=1979&amp;author=Lai%2CTL&amp;author=Robbins%2CH">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Lange, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Lange, K.: A gradient algorithm locally equivalent to the EM algorithm. J. R. Stat. Soc. Ser. B 57, 425–437 (1" /><p class="c-article-references__text" id="ref-CR45">Lange, K.: A gradient algorithm locally equivalent to the EM algorithm. J. R. Stat. Soc. Ser. B <b>57</b>, 425–437 (1995)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0813.62021" aria-label="View reference 45 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20gradient%20algorithm%20locally%20equivalent%20to%20the%20EM%20algorithm&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20B&amp;volume=57&amp;pages=425-437&amp;publication_year=1995&amp;author=Lange%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="K. Lange, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Lange, K.: Numerical Analysis for Statisticians. Springer, New York (2010)" /><p class="c-article-references__text" id="ref-CR46">Lange, K.: Numerical Analysis for Statisticians. Springer, New York (2010)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Numerical%20Analysis%20for%20Statisticians&amp;publication_year=2010&amp;author=Lange%2CK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Le, L. Bottou Yann, L. Bottou, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Le, C., Bottou Yann, L., Bottou, L.: Large scale online learning. Adv. Neural Inf. Process. Syst. 16, 217 (200" /><p class="c-article-references__text" id="ref-CR47">Le, C., Bottou Yann, L., Bottou, L.: Large scale online learning. Adv. Neural Inf. Process. Syst. <b>16</b>, 217 (2004)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Large%20scale%20online%20learning&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=16&amp;publication_year=2004&amp;author=Le%2CC&amp;author=Bottou%20Yann%2CL&amp;author=Bottou%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="EH. Lehmann, G. Casella, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Lehmann, E.H., Casella, G.: Theory of Point Estimation, 2nd edn. Springer, New York (2003)" /><p class="c-article-references__text" id="ref-CR48">Lehmann, E.H., Casella, G.: Theory of Point Estimation, 2nd edn. Springer, New York (2003)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Theory%20of%20Point%20Estimation&amp;publication_year=2003&amp;author=Lehmann%2CEH&amp;author=Casella%2CG">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Li, L.: A worst-case comparison between temporal difference and residual gradient with linear function approxi" /><p class="c-article-references__text" id="ref-CR49">Li, L.: A worst-case comparison between temporal difference and residual gradient with linear function approximation. In: Proceedings of the 25th International Conference on Machine Learning, ACM, pp. 560–567</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Z. Liu, J. Almhana, V. Choulakian, R. McGorman, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Liu, Z., Almhana, J., Choulakian, V., McGorman, R.: Online em algorithm for mixture with application to intern" /><p class="c-article-references__text" id="ref-CR50">Liu, Z., Almhana, J., Choulakian, V., McGorman, R.: Online em algorithm for mixture with application to internet traffic modeling. Comput. Stat. Data Anal. <b>50</b>(4), 1052–1071 (2006)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?06408140" aria-label="View reference 50 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2210745" aria-label="View reference 50 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2Fj.csda.2004.11.002" aria-label="View reference 50">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Online%20em%20algorithm%20for%20mixture%20with%20application%20to%20internet%20traffic%20modeling&amp;journal=Comput.%20Stat.%20Data%20Anal.&amp;volume=50&amp;issue=4&amp;pages=1052-1071&amp;publication_year=2006&amp;author=Liu%2CZ&amp;author=Almhana%2CJ&amp;author=Choulakian%2CV&amp;author=McGorman%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ljung, L., Pflug, G., Walk, H.: Stochastic Approximation and Optimization of Random Systems, vol. 17. Springer" /><p class="c-article-references__text" id="ref-CR51">Ljung, L., Pflug, G., Walk, H.: Stochastic Approximation and Optimization of Random Systems, vol. 17. Springer, New York (1992)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RD. Martin, C. Masreliez, " /><meta itemprop="datePublished" content="1975" /><meta itemprop="headline" content="Martin, R.D., Masreliez, C.: Robust estimation via stochastic approximation. IEEE Trans. Inf. Theory 21(3), 26" /><p class="c-article-references__text" id="ref-CR52">Martin, R.D., Masreliez, C.: Robust estimation via stochastic approximation. IEEE Trans. Inf. Theory <b>21</b>(3), 263–271 (1975)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0363.62024" aria-label="View reference 52 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=395111" aria-label="View reference 52 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTIT.1975.1055386" aria-label="View reference 52">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20estimation%20via%20stochastic%20approximation&amp;journal=IEEE%20Trans.%20Inf.%20Theory&amp;volume=21&amp;issue=3&amp;pages=263-271&amp;publication_year=1975&amp;author=Martin%2CRD&amp;author=Masreliez%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="N. Murata, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Murata, N.: A Statistical Study of On-line Learning. Online Learning and Neural Networks. Cambridge University" /><p class="c-article-references__text" id="ref-CR53">Murata, N.: A Statistical Study of On-line Learning. Online Learning and Neural Networks. Cambridge University Press, Cambridge (1998)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Statistical%20Study%20of%20On-line%20Learning&amp;publication_year=1998&amp;author=Murata%2CN">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J-I. Nagumo, A. Noda, " /><meta itemprop="datePublished" content="1967" /><meta itemprop="headline" content="Nagumo, J.-I., Noda, A.: A learning method for system identification. IEEE Trans. Autom. Control 12(3), 282–28" /><p class="c-article-references__text" id="ref-CR54">Nagumo, J.-I., Noda, A.: A learning method for system identification. IEEE Trans. Autom. Control <b>12</b>(3), 282–287 (1967)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1109%2FTAC.1967.1098599" aria-label="View reference 54">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20learning%20method%20for%20system%20identification&amp;journal=IEEE%20Trans.%20Autom.%20Control&amp;volume=12&amp;issue=3&amp;pages=282-287&amp;publication_year=1967&amp;author=Nagumo%2CJ-I&amp;author=Noda%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="National Research Council: Frontiers in Massive Data Analysis. The National Academies Press, Washington, DC (2" /><p class="c-article-references__text" id="ref-CR55">National Research Council: Frontiers in Massive Data Analysis. The National Academies Press, Washington, DC (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Frontiers%20in%20Massive%20Data%20Analysis&amp;publication_year=2013">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Neal, R.M., Hinton, G.E.: A view of the em algorithm that justifies incremental, sparse, and other variants. I" /><p class="c-article-references__text" id="ref-CR56">Neal, R.M., Hinton, G.E.: A view of the em algorithm that justifies incremental, sparse, and other variants. In: Learning in Graphical Models, pp. 355–368. Springer, New York (1998)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Neal, R.: Mcmc Using Hamiltonian Dynamics. Handbook of Markov Chain Monte Carlo 2 (2011)" /><p class="c-article-references__text" id="ref-CR57">Neal, R.: Mcmc Using Hamiltonian Dynamics. Handbook of Markov Chain Monte Carlo 2 (2011)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="AS. Nemirovski, DB. Yudin, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Nemirovski, A.S., Yudin, D.B.: Problem Complexity and Method Efficiency in Optimization. Wiley, Chichester (19" /><p class="c-article-references__text" id="ref-CR58">Nemirovski, A.S., Yudin, D.B.: Problem Complexity and Method Efficiency in Optimization. Wiley, Chichester (1983)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Problem%20Complexity%20and%20Method%20Efficiency%20in%20Optimization&amp;publication_year=1983&amp;author=Nemirovski%2CAS&amp;author=Yudin%2CDB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Nemirovski, A. Juditsky, G. Lan, A. Shapiro, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Nemirovski, A., Juditsky, A., Lan, G., Shapiro, A.: Robust stochastic approximation approach to stochastic pro" /><p class="c-article-references__text" id="ref-CR59">Nemirovski, A., Juditsky, A., Lan, G., Shapiro, A.: Robust stochastic approximation approach to stochastic programming. SIAM J. Optim. <b>19</b>(4), 1574–1609 (2009)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?1189.90109" aria-label="View reference 59 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2486041" aria-label="View reference 59 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F070704277" aria-label="View reference 59">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20stochastic%20approximation%20approach%20to%20stochastic%20programming&amp;journal=SIAM%20J.%20Optim.&amp;volume=19&amp;issue=4&amp;pages=1574-1609&amp;publication_year=2009&amp;author=Nemirovski%2CA&amp;author=Juditsky%2CA&amp;author=Lan%2CG&amp;author=Shapiro%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="MB. Nevelson, RZ. Khasminskiĭ, " /><meta itemprop="datePublished" content="1973" /><meta itemprop="headline" content="Nevelson, M.B., Khasminskiĭ, R.Z.: Stochastic Approximation and Recursive Estimation, vol. 47. American Mathem" /><p class="c-article-references__text" id="ref-CR60">Nevelson, M.B., Khasminskiĭ, R.Z.: Stochastic Approximation and Recursive Estimation, vol. 47. American Mathematical Society, Providence (1973)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 60 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stochastic%20Approximation%20and%20Recursive%20Estimation&amp;publication_year=1973&amp;author=Nevelson%2CMB&amp;author=Khasminski%C4%AD%2CRZ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nowlan, S.J.: Soft Competitive Adaptation: Neural Network Learning Algorithms Based on Fitting Statistical Mix" /><p class="c-article-references__text" id="ref-CR61">Nowlan, S.J.: Soft Competitive Adaptation: Neural Network Learning Algorithms Based on Fitting Statistical Mixtures. Carnegie Mellon University, Pittsburgh (1991)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Parikh, S. Boyd, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Parikh, N., Boyd, S.: Proximal algorithms. Found. Trends Optim. 1(3), 123–231 (2013)" /><p class="c-article-references__text" id="ref-CR62">Parikh, N., Boyd, S.: Proximal algorithms. Found. Trends Optim. <b>1</b>(3), 123–231 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proximal%20algorithms&amp;journal=Found.%20Trends%20Optim.&amp;volume=1&amp;issue=3&amp;pages=123-231&amp;publication_year=2013&amp;author=Parikh%2CN&amp;author=Boyd%2CS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pillai, N.S., Smith, A.: Ergodicity of approximate mcmc chains with applications to large data sets. arXiv pre" /><p class="c-article-references__text" id="ref-CR63">Pillai, N.S., Smith, A.: Ergodicity of approximate mcmc chains with applications to large data sets. arXiv preprint <a href="http://arxiv.org/abs/1405.0182">http://arxiv.org/abs/1405.0182</a> (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BT. Polyak, YZ. Tsypkin, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Polyak, B.T., Tsypkin, Y.Z.: Adaptive algorithms of estimation (convergence, optimality, stability). Autom. Re" /><p class="c-article-references__text" id="ref-CR64">Polyak, B.T., Tsypkin, Y.Z.: Adaptive algorithms of estimation (convergence, optimality, stability). Autom. Remote Control <b>3</b>, 74–84 (1979)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 64 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20algorithms%20of%20estimation%20%28convergence%2C%20optimality%2C%20stability%29&amp;journal=Autom.%20Remote%20Control&amp;volume=3&amp;pages=74-84&amp;publication_year=1979&amp;author=Polyak%2CBT&amp;author=Tsypkin%2CYZ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Polyak, B.T., Juditsky, A.B.: Acceleration of stochastic approximation by averaging. SIAM J. Control Optim. 30" /><p class="c-article-references__text" id="ref-CR65">Polyak, B.T., Juditsky, A.B.: Acceleration of stochastic approximation by averaging. SIAM J. Control Optim. <b>30</b>(4), 838–855 (1992)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Robbins, S. Monro, " /><meta itemprop="datePublished" content="1951" /><meta itemprop="headline" content="Robbins, H., Monro, S.: A stochastic approximation method. Ann. Math. Stat. 22, 400–407 (1951)" /><p class="c-article-references__text" id="ref-CR66">Robbins, H., Monro, S.: A stochastic approximation method. Ann. Math. Stat. <b>22</b>, 400–407 (1951)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0054.05901" aria-label="View reference 66 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=42668" aria-label="View reference 66 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177729586" aria-label="View reference 66">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 66 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20stochastic%20approximation%20method&amp;journal=Ann.%20Math.%20Stat.&amp;volume=22&amp;pages=400-407&amp;publication_year=1951&amp;author=Robbins%2CH&amp;author=Monro%2CS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RT. Rockafellar, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Rockafellar, R.T.: Monotone operators and the proximal point algorithm. SIAM J. Control Optim. 14(5), 877–898 " /><p class="c-article-references__text" id="ref-CR67">Rockafellar, R.T.: Monotone operators and the proximal point algorithm. SIAM J. Control Optim. <b>14</b>(5), 877–898 (1976)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0358.90053" aria-label="View reference 67 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=410483" aria-label="View reference 67 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1137%2F0314056" aria-label="View reference 67">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 67 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Monotone%20operators%20and%20the%20proximal%20point%20algorithm&amp;journal=SIAM%20J.%20Control%20Optim.&amp;volume=14&amp;issue=5&amp;pages=877-898&amp;publication_year=1976&amp;author=Rockafellar%2CRT">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rosasco, L., Villa, S., Công Vũ, B.: Convergence of stochastic proximal gradient algorithm. arXiv preprint htt" /><p class="c-article-references__text" id="ref-CR68">Rosasco, L., Villa, S., Công Vũ, B.: Convergence of stochastic proximal gradient algorithm. arXiv preprint <a href="http://arxiv.org/abs/1403.5074">http://arxiv.org/abs/1403.5074</a>, 2014</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ruppert, D.: Efficient estimations from a slowly convergent robbins-monro process. Technical report, Cornell U" /><p class="c-article-references__text" id="ref-CR69">Ruppert, D.: Efficient estimations from a slowly convergent robbins-monro process. Technical report, Cornell University Operations Research and Industrial Engineering (1988)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ryu, E.K., Boyd, S.: Stochastic proximal iteration: a non-asymptotic improvement upon stochastic gradient desc" /><p class="c-article-references__text" id="ref-CR70">Ryu, E.K., Boyd, S.: Stochastic proximal iteration: a non-asymptotic improvement upon stochastic gradient descent. Working paper. <a href="http://web.stanford.edu/~eryu/papers/spi.pdf">http://web.stanford.edu/~eryu/papers/spi.pdf</a> (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Sacks, " /><meta itemprop="datePublished" content="1958" /><meta itemprop="headline" content="Sacks, J.: Asymptotic distribution of stochastic approximation procedures. Ann. Math. Stat. 29(2), 373–405 (19" /><p class="c-article-references__text" id="ref-CR71">Sacks, J.: Asymptotic distribution of stochastic approximation procedures. Ann. Math. Stat. <b>29</b>(2), 373–405 (1958)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0229.62010" aria-label="View reference 71 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=98427" aria-label="View reference 71 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177706619" aria-label="View reference 71">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 71 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Asymptotic%20distribution%20of%20stochastic%20approximation%20procedures&amp;journal=Ann.%20Math.%20Stat.&amp;volume=29&amp;issue=2&amp;pages=373-405&amp;publication_year=1958&amp;author=Sacks%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DJ. Sakrison, " /><meta itemprop="datePublished" content="1965" /><meta itemprop="headline" content="Sakrison, D.J.: Efficient recursive estimation; application to estimating the parameters of a covariance funct" /><p class="c-article-references__text" id="ref-CR72">Sakrison, D.J.: Efficient recursive estimation; application to estimating the parameters of a covariance function. Int. J. Eng. Sci. <b>3</b>(4), 461–483 (1965)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0137.37202" aria-label="View reference 72 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=182082" aria-label="View reference 72 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1016%2F0020-7225%2865%2990029-7" aria-label="View reference 72">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 72 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Efficient%20recursive%20estimation%3B%20application%20to%20estimating%20the%20parameters%20of%20a%20covariance%20function&amp;journal=Int.%20J.%20Eng.%20Sci.&amp;volume=3&amp;issue=4&amp;pages=461-483&amp;publication_year=1965&amp;author=Sakrison%2CDJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Salakhutdinov, R., Mnih, A., Hinton, G.: Restricted boltzmann machines for collaborative filtering. In: Procee" /><p class="c-article-references__text" id="ref-CR73">Salakhutdinov, R., Mnih, A., Hinton, G.: Restricted boltzmann machines for collaborative filtering. In: Proceedings of the 24th International Conference on Machine Learning, ACM, pp. 791–798 (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M-A. Sato, S. Ishii, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Sato, M.-A., Ishii, S.: On-line em algorithm for the normalized Gaussian network. Neural Comput. 12(2), 407–43" /><p class="c-article-references__text" id="ref-CR74">Sato, M.-A., Ishii, S.: On-line em algorithm for the normalized Gaussian network. Neural Comput. <b>12</b>(2), 407–432 (2000)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1162%2F089976600300015853" aria-label="View reference 74">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 74 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On-line%20em%20algorithm%20for%20the%20normalized%20Gaussian%20network&amp;journal=Neural%20Comput.&amp;volume=12&amp;issue=2&amp;pages=407-432&amp;publication_year=2000&amp;author=Sato%2CM-A&amp;author=Ishii%2CS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="I. Sato, H. Nakagawa, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Sato, I., Nakagawa, H.: Approximation analysis of stochastic gradient langevin dynamics by using Fokker-Planck" /><p class="c-article-references__text" id="ref-CR75">Sato, I., Nakagawa, H.: Approximation analysis of stochastic gradient langevin dynamics by using Fokker-Planck equation and ito process. JMLR W&amp;CP <b>32</b>(1), 982–990 (2014)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 75 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Approximation%20analysis%20of%20stochastic%20gradient%20langevin%20dynamics%20by%20using%20Fokker-Planck%20equation%20and%20ito%20process&amp;journal=JMLR%20W%26CP&amp;volume=32&amp;issue=1&amp;pages=982-990&amp;publication_year=2014&amp;author=Sato%2CI&amp;author=Nakagawa%2CH">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RE. Schapire, MK. Warmuth, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Schapire, R.E., Warmuth, M.K.: On the worst-case analysis of temporal-difference learning algorithms. Mach. Le" /><p class="c-article-references__text" id="ref-CR76">Schapire, R.E., Warmuth, M.K.: On the worst-case analysis of temporal-difference learning algorithms. Mach. Learn. <b>22</b>(1–3), 95–121 (1996)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0843.68093" aria-label="View reference 76 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 76 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20worst-case%20analysis%20of%20temporal-difference%20learning%20algorithms&amp;journal=Mach.%20Learn.&amp;volume=22&amp;issue=1%E2%80%933&amp;pages=95-121&amp;publication_year=1996&amp;author=Schapire%2CRE&amp;author=Warmuth%2CMK">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schaul, T., Zhang, S., LeCun, Y.: No more pesky learning rates. arXiv preprint. http://arxiv.org/abs/1206.1106" /><p class="c-article-references__text" id="ref-CR77">Schaul, T., Zhang, S., LeCun, Y.: No more pesky learning rates. arXiv preprint. <a href="http://arxiv.org/abs/1206.1106">http://arxiv.org/abs/1206.1106</a>, 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schraudolph, N.N., Yu, J., Günter, S.: A stochastic quasi-Newton method for online convex optimization. In: Me" /><p class="c-article-references__text" id="ref-CR78">Schraudolph, N.N., Yu, J., Günter, S.: A stochastic quasi-Newton method for online convex optimization. In: Meila M., Shen X. (eds.) Proceedings of the 11th International Conference on Artificial Intelligence and Statistics (AISTATS), vol. 2, pp. 436–443. San Juan, Puerto Rico (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Slock, D.T.M.: On the convergence behavior of the LMS and the normalized LMS algorithms. IEEE Trans. Signal Pr" /><p class="c-article-references__text" id="ref-CR79">Slock, D.T.M.: On the convergence behavior of the LMS and the normalized LMS algorithms. IEEE Trans. Signal Process. <b>41</b>(9), 2811–2825 (1993)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RS. Sutton, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Sutton, R.S.: Learning to predict by the methods of temporal differences. Mach. Learn. 3(1), 9–44 (1988)" /><p class="c-article-references__text" id="ref-CR80">Sutton, R.S.: Learning to predict by the methods of temporal differences. Mach. Learn. <b>3</b>(1), 9–44 (1988)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 80 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20to%20predict%20by%20the%20methods%20of%20temporal%20differences&amp;journal=Mach.%20Learn.&amp;volume=3&amp;issue=1&amp;pages=9-44&amp;publication_year=1988&amp;author=Sutton%2CRS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tamar, A., Toulis, P., Mannor, S., Airoldi, E.: Implicit temporal differences. In: Neural Information Processi" /><p class="c-article-references__text" id="ref-CR81">Tamar, A., Toulis, P., Mannor, S., Airoldi, E.: Implicit temporal differences. In: Neural Information Processing Systems, Workshop on Large-Scale Reinforcement Learning (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GW. Taylor, GE. Hinton, ST. Roweis, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Taylor, G.W., Hinton, G.E., Roweis, S.T.: Modeling human motion using binary latent variables. Adv. Neural Inf" /><p class="c-article-references__text" id="ref-CR82">Taylor, G.W., Hinton, G.E., Roweis, S.T.: Modeling human motion using binary latent variables. Adv. Neural Inf. Process. Syst. <b>19</b>, 1345–1352 (2006)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 82 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20human%20motion%20using%20binary%20latent%20variables&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=19&amp;pages=1345-1352&amp;publication_year=2006&amp;author=Taylor%2CGW&amp;author=Hinton%2CGE&amp;author=Roweis%2CST">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MD. Titterington, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Titterington, M.D.: Recursive parameter estimation using incomplete data. J. R. Stat. Soc. Ser. B 46, 257–267 " /><p class="c-article-references__text" id="ref-CR83">Titterington, M.D.: Recursive parameter estimation using incomplete data. J. R. Stat. Soc. Ser. B <b>46</b>, 257–267 (1984)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0556.62061" aria-label="View reference 83 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=781884" aria-label="View reference 83 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 83 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Recursive%20parameter%20estimation%20using%20incomplete%20data&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20B&amp;volume=46&amp;pages=257-267&amp;publication_year=1984&amp;author=Titterington%2CMD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Toulis, P., Airoldi, E.M.: Implicit stochastic gradient descent for principled estimation with large datasets." /><p class="c-article-references__text" id="ref-CR84">Toulis, P., Airoldi, E.M.: Implicit stochastic gradient descent for principled estimation with large datasets. arXiv preprint <a href="http://arxiv.org/abs/1408.2923">http://arxiv.org/abs/1408.2923</a>, 2014</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Toulis, E. Airoldi, J. Rennie, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Toulis, P., Airoldi, E., Rennie, J.: Statistical analysis of stochastic gradient methods for generalized linea" /><p class="c-article-references__text" id="ref-CR85">Toulis, P., Airoldi, E., Rennie, J.: Statistical analysis of stochastic gradient methods for generalized linear models. JMLR W&amp;CP <b>32</b>(1), 667–675 (2014)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 85 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistical%20analysis%20of%20stochastic%20gradient%20methods%20for%20generalized%20linear%20models&amp;journal=JMLR%20W%26CP&amp;volume=32&amp;issue=1&amp;pages=667-675&amp;publication_year=2014&amp;author=Toulis%2CP&amp;author=Airoldi%2CE&amp;author=Rennie%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JH. Venter, " /><meta itemprop="datePublished" content="1967" /><meta itemprop="headline" content="Venter, J.H.: An extension of the robbins-monro procedur. Ann. Math. Stat. 38, 181–190 (1967)" /><p class="c-article-references__text" id="ref-CR86">Venter, J.H.: An extension of the robbins-monro procedur. Ann. Math. Stat. <b>38</b>, 181–190 (1967)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.emis.de/MATH-item?0158.36901" aria-label="View reference 86 on MATH">MATH</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=205396" aria-label="View reference 86 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faoms%2F1177699069" aria-label="View reference 86">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 86 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20extension%20of%20the%20robbins-monro%20procedur&amp;journal=Ann.%20Math.%20Stat.&amp;volume=38&amp;pages=181-190&amp;publication_year=1967&amp;author=Venter%2CJH">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Wang, X. Chen, A. Smola, E. Xing, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Wang, C., Chen, X., Smola, A., Xing, E.: Variance reduction for stochastic gradient optimization. Adv. Neural " /><p class="c-article-references__text" id="ref-CR87">Wang, C., Chen, X., Smola, A., Xing, E.: Variance reduction for stochastic gradient optimization. Adv. Neural Inf. Process. Syst. <b>26</b>, 181–189 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 87 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Variance%20reduction%20for%20stochastic%20gradient%20optimization&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=26&amp;pages=181-189&amp;publication_year=2013&amp;author=Wang%2CC&amp;author=Chen%2CX&amp;author=Smola%2CA&amp;author=Xing%2CE">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Wang, DP. Bertsekas, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Wang, M., Bertsekas, D.P.: Stabilization of stochastic iterative methods for singular and nearly singular line" /><p class="c-article-references__text" id="ref-CR88">Wang, M., Bertsekas, D.P.: Stabilization of stochastic iterative methods for singular and nearly singular linear systems. Math. Oper. Res. <b>39</b>(1), 1–30 (2013)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3173001" aria-label="View reference 88 on MathSciNet">MathSciNet</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1287%2Fmoor.2013.0596" aria-label="View reference 88">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 88 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stabilization%20of%20stochastic%20iterative%20methods%20for%20singular%20and%20nearly%20singular%20linear%20systems&amp;journal=Math.%20Oper.%20Res.&amp;volume=39&amp;issue=1&amp;pages=1-30&amp;publication_year=2013&amp;author=Wang%2CM&amp;author=Bertsekas%2CDP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CZ. Wei, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Wei, C.Z.: Multivariate adaptive stochastic approximation. Ann. Stat. 3, 1115–1130 (1987)" /><p class="c-article-references__text" id="ref-CR89">Wei, C.Z.: Multivariate adaptive stochastic approximation. Ann. Stat. <b>3</b>, 1115–1130 (1987)</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176350496" aria-label="View reference 89">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 89 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multivariate%20adaptive%20stochastic%20approximation&amp;journal=Ann.%20Stat.&amp;volume=3&amp;pages=1115-1130&amp;publication_year=1987&amp;author=Wei%2CCZ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Welling, M., Teh, Y.W.: Bayesian learning via stochastic gradient langevin dynamics. In: Proceedings of the 28" /><p class="c-article-references__text" id="ref-CR90">Welling, M., Teh, Y.W.: Bayesian learning via stochastic gradient langevin dynamics. In: Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 681–688 (2011)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Xu, W.: Towards optimal one pass large scale learning with averaged stochastic gradient descent. arXiv preprin" /><p class="c-article-references__text" id="ref-CR91">Xu, W.: Towards optimal one pass large scale learning with averaged stochastic gradient descent. arXiv preprint <a href="http://arxiv.org/abs/1107.2490">http://arxiv.org/abs/1107.2490</a>, 2011</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Younes, L.: On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates. St" /><p class="c-article-references__text" id="ref-CR92">Younes, L.: On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates. Stochastics <b>65</b>(3–4), 177–228 (1999)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhang, T.: Solving large scale linear prediction problems using stochastic gradient descent algorithms. In: Pr" /><p class="c-article-references__text" id="ref-CR93">Zhang, T.: Solving large scale linear prediction problems using stochastic gradient descent algorithms. In: Proceedings of the Twenty-First International Conference on Machine Learning, ACM, p. 116 (2004)</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-category="article body" data-track-label="link" href="/article/10.1007/s11222-015-9560-y-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors wish to thank Leon Bottou, Bob Carpenter, David Dunson, Andrew Gelman, Brian Kulis, Xiao-Li Meng, Natesh Pillai, Neil Shephard, Daniel Sussman and Alexander Volfovsky for useful comments and discussion. This research was sponsored, in part, by NSF CAREER award IIS-1149662, ARO MURI award W911NF-11-1-0036, and ONR YIP award N00014-14-1-0485. PT is a Google Fellow in Statistics. EMA is an Alfred P. Sloan Research Fellow.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><span class="c-article-author-affiliation__address">Department of Statistics, Harvard University, Cambridge, MA, 02138, USA</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Panos Toulis</li><li class="c-article-author-affiliation__authors-item"> &amp; Edoardo M. Airoldi</li></ul></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-1"><span class="c-article-authors-search__title u-h3 js-search-name">Panos Toulis</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Panos+Toulis&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Panos+Toulis" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Panos+Toulis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-2"><span class="c-article-authors-search__title u-h3 js-search-name">Edoardo M. Airoldi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Edoardo M.+Airoldi&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Edoardo M.+Airoldi" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Edoardo M.+Airoldi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p>Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s11222-015-9560-y/email/correspondent/c1/new">Edoardo M. Airoldi</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-category="article body" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Scalable%20estimation%20strategies%20based%20on%20stochastic%20approximations%3A%20classical%20results%20and%20new%20insights&amp;author=Panos%20Toulis%20et%20al&amp;contentID=10.1007%2Fs11222-015-9560-y&amp;publication=0960-3174&amp;publicationDate=2015-06-11&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s11222-015-9560-y" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s11222-015-9560-y" data-track="click" data-track-action="Click Crossmark" data-track-category="article body" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Toulis, P., Airoldi, E.M. Scalable estimation strategies based on stochastic approximations: classical results and new insights.
                    <i>Stat Comput</i> <b>25, </b>781–795 (2015). https://doi.org/10.1007/s11222-015-9560-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-category="article body" data-track-label="link" href="/article/10.1007/s11222-015-9560-y.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2015-03-08">08 March 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2015-06-11">11 June 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2015-07">July 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><a href="https://doi.org/10.1007/s11222-015-9560-y" data-track="click" data-track-action="view doi" data-track-category="article body" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s11222-015-9560-y</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Maximum likelihood</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Recursive estimation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Implicit stochastic gradient descent methods</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Optimal learning rate</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Asymptotic analysis</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Big data</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        
                            <div class="c-article-buy-box">
                                <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">42,64 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/s11222-015-9560-y">
     <input type="hidden" name="isxn" value="1573-1375">
     <input type="hidden" name="contenttitle" value="Scalable estimation strategies based on stochastic approximations: classical results and new insights">
     <input type="hidden" name="copyrightyear" value="2015">
     <input type="hidden" name="year" value="2015">
     <input type="hidden" name="authors" value="Panos Toulis, Edoardo M. Airoldi">
     <input type="hidden" name="title" value="Statistics and Computing">
     <input type="hidden" name="mac" value="9D8C2C87C0178A6A91EC47E4595DD9A8">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action, new buybox" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">81 €</p>
    <p class="buybox__price-info">Price <b>includes VAT</b> for Italy</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="Statistics and Computing">
     <input type="hidden" name="journalnumber" value="11222">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/s11222-015-9560-y&journal=1573-1375&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                            </div>
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <div class="c-ad c-ad--MPU1">
        <div class="c-ad c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/11222/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=9560;"></div>
        </div>
    </div>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 79.49.21.188</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 14 14">
            <path d="M13.545 12.648a.641.641 0 01.006.903.646.646 0 01-.903-.006l-2.664-2.663a6.125 6.125 0 11.897-.898l2.664 2.664zm-7.42-1.273a5.25 5.25 0 100-10.5 5.25 5.25 0 000 10.5z"></path>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

