abstract: We propose an algorithm for meta-learning that is model-agnostic, in the
  sense that it is compatible with any model trained with gradient descent and applicable
  to a variety of different learning problems, including classification, regression,
  and reinforcement learning. The goal of meta-learning is to train a model on a variety
  of learning tasks, such that it can solve new learning tasks using only a small
  number of training samples. In our approach, the parameters of the model are explicitly
  trained such that a small number of gradient steps with a small amount of training
  data from a new task will produce good generalization performance on that task.
  In effect, our method trains the model to be easy to fine-tune. We demonstrate that
  this approach leads to state-of-the-art performance on two few-shot image classification
  benchmarks, produces good results on few-shot regression, and accelerates fine-tuning
  for policy gradient reinforcement learning with neural network policies.
archiveprefix: arXiv
author: Finn, Chelsea and Abbeel, Pieter and Levine, Sergey
author_list:
- family: Finn
  given: Chelsea
- family: Abbeel
  given: Pieter
- family: Levine
  given: Sergey
eprint: 1703.03400v3
file: 1703.03400v3.pdf
files:
- finn-chelsea-and-abbeel-pieter-and-levine-sergeymodel-agnostic-meta-learning-for-fast-adaptation-of-deep-networks2017.pdf
month: Mar
primaryclass: cs.LG
ref: 1703.03400v3
time-added: 2020-05-30-18:25:42
title: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
type: article
url: http://arxiv.org/abs/1703.03400v3
year: '2017'
