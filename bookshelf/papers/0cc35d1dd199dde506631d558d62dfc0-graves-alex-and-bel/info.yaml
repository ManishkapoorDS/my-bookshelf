abstract: 'We introduce a method for automatically selecting the path, or syllabus,
  that a neural network follows through a curriculum so as to maximise learning efficiency.
  A measure of the amount that the network learns from each data sample is provided
  as a reward signal to a nonstationary multi-armed bandit algorithm, which then determines
  a stochastic syllabus. We consider a range of signals derived from two distinct
  indicators of learning progress: rate of increase in prediction accuracy, and rate
  of increase in network complexity. Experimental results for LSTM networks on three
  curricula demonstrate that our approach can significantly accelerate learning, in
  some cases halving the time required to attain a satisfactory performance level.'
archiveprefix: arXiv
author: Graves, Alex and Bellemare, Marc G. and Menick, Jacob and Munos, Remi and
  Kavukcuoglu, Koray
author_list:
- family: Graves
  given: Alex
- family: Bellemare
  given: Marc G.
- family: Menick
  given: Jacob
- family: Munos
  given: Remi
- family: Kavukcuoglu
  given: Koray
eprint: 1704.03003v1
file: 1704.03003v1.pdf
files:
- graves-alex-and-bellemare-marc-g.-and-menick-jacob-and-munos-remi-and-kavukcuoglu-korayautomated-curriculum-learning-for-neural-networks2017.pdf
month: Apr
primaryclass: cs.NE
ref: 1704.03003v1
tags: deep-reinforcement-learning reinforcement-learning
title: Automated Curriculum Learning for Neural Networks
type: article
url: http://arxiv.org/abs/1704.03003v1
year: '2017'
