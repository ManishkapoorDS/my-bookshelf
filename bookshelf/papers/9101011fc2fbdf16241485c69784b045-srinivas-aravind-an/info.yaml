abstract: A key challenge in complex visuomotor control is learning abstract representations
  that are effective for specifying goals, planning, and generalization. To this end,
  we introduce universal planning networks (UPN). UPNs embed differentiable planning
  within a goal-directed policy. This planning computation unrolls a forward model
  in a latent space and infers an optimal action plan through gradient descent trajectory
  optimization. The plan-by-gradient-descent process and its underlying representations
  are learned end-to-end to directly optimize a supervised imitation learning objective.
  We find that the representations learned are not only effective for goal-directed
  visual imitation via gradient-based trajectory optimization, but can also provide
  a metric for specifying goals using images. The learned representations can be leveraged
  to specify distance-based rewards to reach new target states for model-free reinforcement
  learning, resulting in substantially more effective learning when solving new tasks
  described via image-based goals. We were able to achieve successful transfer of
  visuomotor planning strategies across robots with significantly different morphologies
  and actuation capabilities.
archiveprefix: arXiv
author: Srinivas, Aravind and Jabri, Allan and Abbeel, Pieter and Levine, Sergey and
  Finn, Chelsea
author_list:
- family: Srinivas
  given: Aravind
- family: Jabri
  given: Allan
- family: Abbeel
  given: Pieter
- family: Levine
  given: Sergey
- family: Finn
  given: Chelsea
eprint: 1804.00645v2
file: 1804.00645v2.pdf
files:
- srinivas-aravind-and-jabri-allan-and-abbeel-pieter-and-levine-sergey-and-finn-chelseauniversal-planning-networks2018.pdf
month: Apr
primaryclass: cs.LG
ref: 1804.00645v2
title: Universal Planning Networks
type: article
url: http://arxiv.org/abs/1804.00645v2
year: '2018'
