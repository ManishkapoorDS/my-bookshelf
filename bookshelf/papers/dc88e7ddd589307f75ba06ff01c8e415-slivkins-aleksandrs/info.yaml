abstract: 'Multi-armed bandits a simple but very powerful framework for algorithms
  that make decisions over time under uncertainty. An enormous body of work has accumulated
  over the years, covered in several books and surveys. This book provides a more
  introductory, textbook-like treatment of the subject. Each chapter tackles a particular
  line of work, providing a self-contained, teachable technical introduction and a
  brief review of the further developments. The chapters are as follows: stochastic
  bandits, lower bounds; Bayesian bandits and Thompson Sampling; Lipschitz Bandits;
  full Feedback and adversarial costs; adversarial bandits; linear costs and semi-bandits;
  contextual Bandits; bandits and games; bandits with knapsacks; bandits and incentives.'
archiveprefix: arXiv
author: Slivkins, Aleksandrs
author_list:
- family: Slivkins
  given: Aleksandrs
eprint: 1904.07272v5
file: 1904.07272v5.pdf
files:
- slivkins-aleksandrsintroduction-to-multi-armed-bandits2019.pdf
month: Apr
primaryclass: cs.LG
ref: 1904.07272v5
time-added: 2020-09-20-10:39:06
title: Introduction to Multi-Armed Bandits
type: article
url: http://arxiv.org/abs/1904.07272v5
year: '2019'
