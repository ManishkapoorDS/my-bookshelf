author: Pecka, Martin and Svoboda, Tomas
author_list:
- affiliation: []
  family: Pecka
  given: Martin
- affiliation: []
  family: Svoboda
  given: Tomas
citations:
- unstructured: 'Abbeel, P., Coates, A., Quigley, M., Ng, A.Y.: An application of
    reinforcement learning to aerobatic helicopter flight. In: Proceedings of the
    2006 Conference on Advances in Neural Information Processing Systems, vol. 19,
    p. 1 (2007)'
- author: B.D. Argall
  doi: 10.1016/j.robot.2008.10.024
  first-page: '469'
  issue: '5'
  journal-title: Robotics and Autonomous Systems
  unstructured: 'Argall, B.D., Chernova, S., Veloso, M., Browning, B.: A survey of
    robot learning from demonstration. Robotics and Autonomous Systems 57(5), 469–483
    (2009)'
  volume: '57'
  year: '2009'
- doi: 10.1007/BF00453370
  unstructured: 'Barto, A.G., Sutton, R.S., Brouwer, P.S.: Associative search network:
    A reinforcement learning associative memory. Biological Cybernetics (1981)'
- unstructured: 'Bertsekas, D.P.: Dynamic programming: deterministic and stochastic
    models. Prentice-Hall (1987)'
- doi: 10.1145/1329125.1329407
  unstructured: 'Chernova, S., Veloso, M.: Confidence-based policy learning from demonstration
    using Gaussian mixture models. In: AAMAS 2007 Proceedings, p. 1. ACM Press (2007)'
- unstructured: 'Consortium, N.: NIFTi robotic UGV platform (2010)'
- doi: 10.1016/S0005-1098(98)00153-8
  unstructured: 'Coraluppi, S.P., Marcus, S.I.: Risk-sensitive and minimax control
    of discrete-time, finite-state Markov decision processes. Automatica (1999)'
- author: E. Delage
  first-page: '225'
  unstructured: 'Delage, E., Mannor, S.: Percentile optimization in uncertain Markov
    decision processes with application to efficient exploration. In: Proceedings
    of the 24th International Conference on Machine Learning, ICML 2007, pp. 225–232.
    ACM Press, New York (2007)'
  volume-title: Proceedings of the 24th International Conference on Machine Learning,
    ICML 2007
  year: '2007'
- doi: 10.1109/IROS.2012.6385714
  unstructured: 'Ertle, P., Tokic, M., Cubek, R., Voos, H., Soffker, D.: Towards learning
    of safety knowledge from human demonstrations. In: 2012 IEEE/RSJ International
    Conference on Intelligent Robots and Systems, pp. 5394–5399. IEEE (October 2012)'
- author: J. Garcia
  doi: 10.1613/jair.3761
  first-page: '515'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Garcia, J., Fernández, F.: Safe exploration of state and action spaces
    in reinforcement learning. Journal of Artificial Intelligence Research 45, 515–564
    (2012)'
  volume: '45'
  year: '2012'
- doi: 10.1109/ADPRL.2011.5967356
  unstructured: 'Garcia Polo, F.J., Rebollo, F.F.: Safe reinforcement learning in
    high-risk tasks through policy improvement. In: 2011 IEEE Symposium on Adaptive
    Dynamic Programming and Reinforcement Learning (ADPRL), pp. 76–83. IEEE (April
    2011)'
- unstructured: 'Geibel, P.: Reinforcement learning with bounded risk. In: ICML, pp.
    162–169 (2001)'
- doi: 10.1109/IROS.2011.6048864
  unstructured: 'Gillula, J.H., Tomlin, C.J.: Guaranteed safe online learning of a
    bounded system. In: 2011 IEEE/RSJ International Conference on Intelligent Robots
    and Systems, pp. 2979–2984. IEEE (September 2011)'
- unstructured: 'Hans, A., Schneegaß, D., Schäfer, A., Udluft, S.: Safe exploration
    for reinforcement learning. In: Proceedings of European Symposium on Artificial
    Neural Networks, pp. 23–25 (April 2008)'
- doi: 10.1016/B978-1-55860-335-6.50021-0
  unstructured: 'Heger, M.: Consideration of risk in reinforcement learning. In: 11th
    International Machine Learning Conference (1994)'
- unstructured: 'Howard, R.A.: Dynamic Programming and Markov Processes. Technology
    Press of Massachusetts Institute of Technology (1960)'
- author: L.P. Kaelbling
  doi: 10.1613/jair.301
  first-page: '237'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Kaelbling, L.P., Littman, M.L., Moore, A.W.: Reinforcement Learning:
    A Survey. Journal of Artificial Intelligence Research 4, 237–285 (1996)'
  volume: '4'
  year: '1996'
- unstructured: 'Kim, D., Kim, K.E., Poupart, P.: Cost-Sensitive Exploration in Bayesian
    Reinforcement Learning. In: Proceedings of Neural Information Processing Systems
    (NIPS) (2012)'
- author: O. Mihatsch
  doi: 10.1023/A:1017940631555
  first-page: '267'
  issue: 2-3
  journal-title: Machine Learning
  unstructured: 'Mihatsch, O., Neuneier, R.: Risk-sensitive reinforcement learning.
    Machine Learning 49(2-3), 267–290 (2002)'
  volume: '49'
  year: '2002'
- unstructured: 'Moldovan, T.M., Abbeel, P.: Safe Exploration in Markov Decision Processes.
    In: Proceedings of the 29th International Conference on Machine Learning (May
    2012)'
- author: A. Nilim
  doi: 10.1287/opre.1050.0216
  first-page: '780'
  issue: '5'
  journal-title: Operations Research
  unstructured: 'Nilim, A., El Ghaoui, L.: Robust Control of Markov Decision Processes
    with Uncertain Transition Matrices. Operations Research 53(5), 780–798 (2005)'
  volume: '53'
  year: '2005'
- author: P. Geibel
  doi: 10.1613/jair.1666
  first-page: '81'
  journal-title: Journal Of Artificial Intelligence Research
  unstructured: 'Geibel, P., Wysotzki, F.: Risk-Sensitive Reinforcement Learning Applied
    to Control under Constraints. Journal Of Artificial Intelligence Research 24,
    81–108 (2011)'
  volume: '24'
  year: '2011'
- author: M.L. Puterman
  doi: 10.1002/9780470316887
  edition: '1'
  unstructured: 'Puterman, M.L.: Markov Decision Processes: Discrete Stochastic Dynamic
    Programming, 1st edn. John Wiley & Sons, Inc., New York (1994)'
  volume-title: 'Markov Decision Processes: Discrete Stochastic Dynamic Programming'
  year: '1994'
- author: J.G. Schneider
  first-page: '1047'
  journal-title: Neural Information Processing Systems
  unstructured: 'Schneider, J.G.: Exploiting model uncertainty estimates for safe
    dynamic control learning. Neural Information Processing Systems 9, 1047–1053 (1996)'
  volume: '9'
  year: '1996'
- author: C.J. Watkins
  doi: 10.1007/BF00992698
  first-page: '279'
  issue: 3-4
  journal-title: Machine Learning
  unstructured: 'Watkins, C.J., Dayan, P.: Q-learning. Machine Learning 8(3-4), 279–292
    (1992)'
  volume: '8'
  year: '1992'
- unstructured: 'Williams, R.J., Baird, L.C.: Tight performance bounds on greedy policies
    based on imperfect value functions. Tech. rep., Northeastern University,College
    of Computer Science (1993)'
doi: 10.1007/978-3-319-13823-7_31
files:
- pecka-martin-and-svoboda-tomassafe-exploration-techniques-for-reinforcement-learning-an-overview2014.pdf
isbn:
- '9783319138220'
- '9783319138237'
journal: Modelling and Simulation for Autonomous Systems
pages: 357--375
publisher: Springer International Publishing
title: Safe Exploration Techniques for Reinforcement Learning – An Overview
type: inbook
url: http://dx.doi.org/10.1007/978-3-319-13823-7_31
year: 2014
