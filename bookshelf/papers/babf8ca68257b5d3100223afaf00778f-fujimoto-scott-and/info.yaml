abstract: Widely-used deep reinforcement learning algorithms have been shown to fail
  in the batch setting--learning from a fixed data set without interaction with the
  environment. Following this result, there have been several papers showing reasonable
  performances under a variety of environments and batch settings. In this paper,
  we benchmark the performance of recent off-policy and batch reinforcement learning
  algorithms under unified settings on the Atari domain, with data generated by a
  single partially-trained behavioral policy. We find that under these conditions,
  many of these algorithms underperform DQN trained online with the same amount of
  data, as well as the partially-trained behavioral policy. To introduce a strong
  baseline, we adapt the Batch-Constrained Q-learning algorithm to a discrete-action
  setting, and show it outperforms all existing algorithms at this task.
archiveprefix: arXiv
author: Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle
author_list:
- family: Fujimoto
  given: Scott
- family: Conti
  given: Edoardo
- family: Ghavamzadeh
  given: Mohammad
- family: Pineau
  given: Joelle
eprint: 1910.01708v1
file: 1910.01708v1.pdf
files:
- fujimoto-scott-and-conti-edoardo-and-ghavamzadeh-mohammad-and-pineau-joellebenchmarking-batch-deep-reinforcement-learning-algorithms2019.pdf
month: Oct
primaryclass: cs.LG
ref: 1910.01708v1
title: Benchmarking Batch Deep Reinforcement Learning Algorithms
type: article
url: http://arxiv.org/abs/1910.01708v1
year: '2019'
