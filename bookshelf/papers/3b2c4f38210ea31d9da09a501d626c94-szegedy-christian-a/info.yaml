abstract: 'Convolutional networks are at the core of most state-of-the-art computer
  vision solutions for a wide variety of tasks. Since 2014 very deep convolutional
  networks started to become mainstream, yielding substantial gains in various benchmarks.
  Although increased model size and computational cost tend to translate to immediate
  quality gains for most tasks (as long as enough labeled data is provided for training),
  computational efficiency and low parameter count are still enabling factors for
  various use cases such as mobile vision and big-data scenarios. Here we explore
  ways to scale up networks in ways that aim at utilizing the added computation as
  efficiently as possible by suitably factorized convolutions and aggressive regularization.
  We benchmark our methods on the ILSVRC 2012 classification challenge validation
  set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%
  top-5 error for single frame evaluation using a network with a computational cost
  of 5 billion multiply-adds per inference and with using less than 25 million parameters.
  With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error
  on the validation set (3.6% error on the test set) and 17.3% top-1 error on the
  validation set.'
archiveprefix: arXiv
author: Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon
  and Wojna, Zbigniew
author_list:
- family: Szegedy
  given: Christian
- family: Vanhoucke
  given: Vincent
- family: Ioffe
  given: Sergey
- family: Shlens
  given: Jonathon
- family: Wojna
  given: Zbigniew
eprint: 1512.00567v3
file: 1512.00567v3.pdf
files:
- szegedy-christian-and-vanhoucke-vincent-and-ioffe-sergey-and-shlens-jonathon-and-wojna-zbigniewrethinking-the-inception-architecture-for-computer.pdf
month: Dec
primaryclass: cs.CV
ref: 1512.00567v3
time-added: 2020-06-21-00:45:24
title: Rethinking the Inception Architecture for Computer Vision
type: article
url: http://arxiv.org/abs/1512.00567v3
year: '2015'
