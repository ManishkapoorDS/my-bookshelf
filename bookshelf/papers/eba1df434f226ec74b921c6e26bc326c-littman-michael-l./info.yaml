abstract: We propose a new task-specification language for Markov decision processes
  that is designed to be an improvement over reward functions by being environment
  independent. The language is a variant of Linear Temporal Logic (LTL) that is extended
  to probabilistic specifications in a way that permits approximations to be learned
  in finite time. We provide several small environments that demonstrate the advantages
  of our geometric LTL (GLTL) language and illustrate how it can be used to specify
  standard reinforcement-learning tasks straightforwardly.
archiveprefix: arXiv
author: Littman, Michael L. and Topcu, Ufuk and Fu, Jie and Isbell, Charles and Wen,
  Min and MacGlashan, James
author_list:
- family: Littman
  given: Michael L.
- family: Topcu
  given: Ufuk
- family: Fu
  given: Jie
- family: Isbell
  given: Charles
- family: Wen
  given: Min
- family: MacGlashan
  given: James
eprint: 1704.04341v1
file: 1704.04341v1.pdf
files:
- littman-michael-l.-and-topcu-ufuk-and-fu-jie-and-isbell-charles-and-wen-min-and-macglashan-jamesenvironment-independent-task-specifications-via.pdf
month: Apr
primaryclass: cs.AI
ref: 1704.04341v1
title: Environment-Independent Task Specifications via GLTL
type: article
url: http://arxiv.org/abs/1704.04341v1
year: '2017'
