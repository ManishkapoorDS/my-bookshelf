abstract: '<jats:p>Artificial Neural Networks are powerful function approximators
  capable of modelling solutions to a wide variety of problems, both supervised and
  unsupervised. As their size and expressivity increases, so too does the variance
  of the model, yielding a nearly ubiquitous overfitting problem. Although mitigated
  by a variety of model regularisation methods, the common cure is to seek large amounts
  of training data--which is not necessarily easily obtained--that sufficiently approximates
  the data distribution of the domain we wish to test on. In contrast, logic programming
  methods such as Inductive Logic Programming offer an extremely data-efficient process
  by which models can be trained to reason on symbolic domains. However, these methods
  are unable to deal with the variety of domains neural networks can be applied to:
  they are not robust to noise in or mislabelling of inputs, and perhaps more importantly,
  cannot be applied to non-symbolic domains where the data is ambiguous, such as operating
  on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework,
  which can not only solve tasks which traditional ILP systems are suited for, but
  shows a robustness to noise and error in the training data which ILP cannot cope
  with. Furthermore, as it is trained by backpropagation against a likelihood objective,
  it can be hybridised by connecting it with neural networks over ambiguous data in
  order to be applied to domains which ILP cannot address, while providing data efficiency
  and generalisation beyond what neural networks on their own can achieve.</jats:p>'
author: Evans, Richard and Grefenstette, Edward
author_list:
- affiliation: []
  family: Evans
  given: Richard
- affiliation: []
  family: Grefenstette
  given: Edward
doc_url: https://jair.org/index.php/jair/article/download/11172/26377
doi: 10.1613/jair.5714
files:
- evans-richard-and-grefenstette-edwardlearning-explanatory-rules-from-noisy-data2018.ps
- evans-richard-and-grefenstette-edwardlearning-explanatory-rules-from-noisy-data2018-a.pdf
journal: Journal of Artificial Intelligence Research
month: 1
pages: 1--64
publisher: AI Access Foundation
time-added: 2020-07-13-00:07:56
title: Learning Explanatory Rules from Noisy Data
type: article
url: http://dx.doi.org/10.1613/jair.5714
volume: '61'
year: 2018
