abstract: Research at the intersection of machine learning, programming languages,
  and software engineering has recently taken important steps in proposing learnable
  probabilistic models of source code that exploit code's abundance of patterns. In
  this article, we survey this work. We contrast programming languages against natural
  languages and discuss how these similarities and differences drive the design of
  probabilistic models. We present a taxonomy based on the underlying design principles
  of each model and use it to navigate the literature. Then, we review how researchers
  have adapted these models to application areas and discuss cross-cutting and application-specific
  challenges and opportunities.
archiveprefix: arXiv
author: Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton,
  Charles
author_list:
- family: Allamanis
  given: Miltiadis
- family: Barr
  given: Earl T.
- family: Devanbu
  given: Premkumar
- family: Sutton
  given: Charles
eprint: 1709.06182v2
file: 1709.06182v2.pdf
files:
- allamanis-miltiadis-and-barr-earl-t.-and-devanbu-premkumar-and-sutton-charlesa-survey-of-machine-learning-for-big-code-and-naturalness2017.pdf
month: Sep
primaryclass: cs.SE
ref: 1709.06182v2
title: A Survey of Machine Learning for Big Code and Naturalness
type: article
url: http://arxiv.org/abs/1709.06182v2
year: '2017'
