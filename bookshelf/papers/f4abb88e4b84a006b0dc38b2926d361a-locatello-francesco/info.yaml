abstract: The key idea behind the unsupervised learning of disentangled representations
  is that real-world data is generated by a few explanatory factors of variation which
  can be recovered by unsupervised learning algorithms. In this paper, we provide
  a sober look at recent progress in the field and challenge some common assumptions.
  We first theoretically show that the unsupervised learning of disentangled representations
  is fundamentally impossible without inductive biases on both the models and the
  data. Then, we train more than 12000 models covering most prominent methods and
  evaluation metrics in a reproducible large-scale experimental study on seven different
  data sets. We observe that while the different methods successfully enforce properties
  ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot
  be identified without supervision. Furthermore, increased disentanglement does not
  seem to lead to a decreased sample complexity of learning for downstream tasks.
  Our results suggest that future work on disentanglement learning should be explicit
  about the role of inductive biases and (implicit) supervision, investigate concrete
  benefits of enforcing disentanglement of the learned representations, and consider
  a reproducible experimental setup covering several data sets.
archiveprefix: arXiv
author: Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Rätsch, Gunnar
  and Gelly, Sylvain and Schölkopf, Bernhard and Bachem, Olivier
author_list:
- family: Locatello
  given: Francesco
- family: Bauer
  given: Stefan
- family: Lucic
  given: Mario
- family: Rätsch
  given: Gunnar
- family: Gelly
  given: Sylvain
- family: Schölkopf
  given: Bernhard
- family: Bachem
  given: Olivier
eprint: 1811.12359v4
file: 1811.12359v4.pdf
files:
- locatello-francesco-and-bauer-stefan-and-lucic-mario-and-ratsch-gunnar-and-gelly-sylvain-and-scholkopf-bernhard-and-bachem-olivierchallenging-c.pdf
month: Nov
note: Proceedings of the 36th International Conference on Machine   Learning (ICML
  2019)
primaryclass: cs.LG
ref: 1811.12359v4
title: Challenging Common Assumptions in the Unsupervised Learning of   Disentangled
  Representations
type: article
url: http://arxiv.org/abs/1811.12359v4
year: '2018'
