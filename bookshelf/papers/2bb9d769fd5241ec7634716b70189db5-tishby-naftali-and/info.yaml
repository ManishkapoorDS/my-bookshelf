abstract: Deep Neural Networks (DNNs) are analyzed via the theoretical framework of
  the information bottleneck (IB) principle. We first show that any DNN can be quantified
  by the mutual information between the layers and the input and output variables.
  Using this representation we can calculate the optimal information theoretic limits
  of the DNN and obtain finite sample generalization bounds. The advantage of getting
  closer to the theoretical limit is quantifiable both by the generalization bound
  and by the network's simplicity. We argue that both the optimal architecture, number
  of layers and features/connections at each layer, are related to the bifurcation
  points of the information bottleneck tradeoff, namely, relevant compression of the
  input layer with respect to the output layer. The hierarchical representations at
  the layered network naturally correspond to the structural phase transitions along
  the information curve. We believe that this new insight can lead to new optimality
  bounds and deep learning algorithms.
archiveprefix: arXiv
author: Tishby, Naftali and Zaslavsky, Noga
author_list:
- family: Tishby
  given: Naftali
- family: Zaslavsky
  given: Noga
eprint: 1503.02406v1
file: 1503.02406v1.pdf
files:
- tishby-naftali-and-zaslavsky-nogadeep-learning-and-the-information-bottleneck-principle2015.pdf
month: Mar
primaryclass: cs.LG
ref: 1503.02406v1
title: Deep Learning and the Information Bottleneck Principle
type: article
url: http://arxiv.org/abs/1503.02406v1
year: '2015'
