author: Spaan, Matthijs T. J.
author_list:
- affiliation: []
  family: Spaan
  given: Matthijs T. J.
citations:
- unstructured: 'Aberdeen, D., Baxter, J.: Scaling internal-state policy-gradient
    methods for POMDPs. In: International Conference on Machine Learning (2002)'
- author: K.J. Åström
  doi: 10.1016/0022-247X(65)90154-X
  first-page: '174'
  issue: '1'
  journal-title: Journal of Mathematical Analysis and Applications
  unstructured: 'Åström, K.J.: Optimal control of Markov processes with incomplete
    state information. Journal of Mathematical Analysis and Applications 10(1), 174–205
    (1965)'
  volume: '10'
  year: '1965'
- unstructured: 'Bagnell, J.A., Kakade, S., Ng, A.Y., Schneider, J.: Policy search
    by dynamic programming. In: Advances in Neural Information Processing Systems,
    vol. 16. MIT Press (2004)'
- unstructured: 'Baird, L., Moore, A.: Gradient descent for general reinforcement
    learning. In: Advances in Neural Information Processing Systems, vol. 11. MIT
    Press (1999)'
- unstructured: 'Bakker, B.: Reinforcement learning with long short-term memory. In:
    Advances in Neural Information Processing Systems, vol. 14. MIT Press (2002)'
- author: J. Baxter
  doi: 10.1613/jair.806
  first-page: '319'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Baxter, J., Bartlett, P.L.: Infinite-horizon policy-gradient estimation.
    Journal of Artificial Intelligence Research 15, 319–350 (2001)'
  volume: '15'
  year: '2001'
- author: J. Baxter
  doi: 10.1613/jair.807
  first-page: '351'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Baxter, J., Bartlett, P.L., Weaver, L.: Experiments with infinite-horizon,
    policy-gradient estimation. Journal of Artificial Intelligence Research 15, 351–381
    (2001)'
  volume: '15'
  year: '2001'
- author: D.S. Bernstein
  doi: 10.1287/moor.27.4.819.297
  first-page: '819'
  issue: '4'
  journal-title: Mathematics of Operations Research
  unstructured: 'Bernstein, D.S., Givan, R., Immerman, N., Zilberstein, S.: The complexity
    of decentralized control of Markov decision processes. Mathematics of Operations
    Research 27(4), 819–840 (2002)'
  volume: '27'
  year: '2002'
- unstructured: 'Bonet, B.: An epsilon-optimal grid-based algorithm for partially
    observable Markov decision processes. In: International Conference on Machine
    Learning (2002)'
- unstructured: 'Boutilier, C., Poole, D.: Computing optimal policies for partially
    observable decision processes using compact representations. In: Proc. of the
    National Conference on Artificial Intelligence (1996)'
- unstructured: 'Brafman, R.I.: A heuristic variable grid solution method for POMDPs.
    In: Proc. of the National Conference on Artificial Intelligence (1997)'
- unstructured: 'Braziunas, D., Boutilier, C.: Stochastic local search for POMDP controllers.
    In: Proc. of the National Conference on Artificial Intelligence (2004)'
- unstructured: 'Brunskill, E., Kaelbling, L., Lozano-Perez, T., Roy, N.: Continuous-state
    POMDPs with hybrid dynamics. In: Proc. of the Int. Symposium on Artificial Intelligence
    and Mathematics (2008)'
- unstructured: 'Cassandra, A.R.: Exact and approximate algorithms for partially observable
    Markov decision processes. PhD thesis, Brown University (1998)'
- unstructured: 'Cassandra, A.R., Kaelbling, L.P., Littman, M.L.: Acting optimally
    in partially observable stochastic domains. In: Proc. of the National Conference
    on Artificial Intelligence (1994)'
- unstructured: 'Cassandra, A.R., Kaelbling, L.P., Kurien, J.A.: Acting under uncertainty:
    Discrete Bayesian models for mobile robot navigation. In: Proc. of International
    Conference on Intelligent Robots and Systems (1996)'
- unstructured: 'Cassandra, A.R., Littman, M.L., Zhang, N.L.: Incremental pruning:
    A simple, fast, exact method for partially observable Markov decision processes.
    In: Proc. of Uncertainty in Artificial Intelligence (1997)'
- unstructured: 'Cheng, H.T.: Algorithms for partially observable Markov decision
    processes. PhD thesis, University of British Columbia (1988)'
- unstructured: 'Doshi, F., Roy, N.: The permutable POMDP: fast solutions to POMDPs
    for preference elicitation. In: Proc. of Int. Conference on Autonomous Agents
    and Multi Agent Systems (2008)'
- unstructured: 'Drake, A.W.: Observation of a Markov process through a noisy channel.
    Sc.D. thesis, Massachusetts Institute of Technology (1962)'
- unstructured: 'Duff, M.: Optimal learning: Computational procedures for Bayes-adaptive
    Markov decision processes. PhD thesis, University of Massachusetts, Amherst (2002)'
- author: E.B. Dynkin
  doi: 10.1137/1110001
  first-page: '1'
  issue: '1'
  journal-title: Theory of Probability and its Applications
  unstructured: 'Dynkin, E.B.: Controlled random sequences. Theory of Probability
    and its Applications 10(1), 1–14 (1965)'
  volume: '10'
  year: '1965'
- author: J.H. Ellis
  doi: 10.1061/(ASCE)1076-0342(1995)1:2(92)
  first-page: '92'
  issue: '2'
  journal-title: Journal of Infrastructure Systems
  unstructured: 'Ellis, J.H., Jiang, M., Corotis, R.: Inspection, maintenance, and
    repair with partial observability. Journal of Infrastructure Systems 1(2), 92–99
    (1995)'
  volume: '1'
  year: '1995'
- unstructured: 'Feng, Z., Zilberstein, S.: Region-based incremental pruning for POMDPs.
    In: Proc. of Uncertainty in Artificial Intelligence (2004)'
- author: A. Foka
  doi: 10.1016/j.robot.2007.01.004
  first-page: '561'
  issue: '7'
  journal-title: Robotics and Autonomous Systems
  unstructured: 'Foka, A., Trahanias, P.: Real-time hierarchical POMDPs for autonomous
    robot navigation. Robotics and Autonomous Systems 55(7), 561–571 (2007)'
  volume: '55'
  year: '2007'
- author: D. Fox
  doi: 10.1613/jair.616
  first-page: '391'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Fox, D., Burgard, W., Thrun, S.: Markov localization for mobile robots
    in dynamic environments. Journal of Artificial Intelligence Research 11, 391–427
    (1999)'
  volume: '11'
  year: '1999'
- doi: 10.1016/j.reseneeco.2010.04.005
  unstructured: 'Haight, R.G., Polasky, S.: Optimal control of an invasive species
    with imperfect information about the level of infestation. Resource and Energy
    Economics (2010) (in Press, Corrected Proof)'
- unstructured: 'Hansen, E.A.: Finite-memory control of partially observable systems.
    PhD thesis, University of Massachusetts, Amherst (1998a)'
- unstructured: 'Hansen, E.A.: Solving POMDPs by searching in policy space. In: Proc.
    of Uncertainty in Artificial Intelligence (1998b)'
- unstructured: 'Hansen, E.A., Feng, Z.: Dynamic programming for POMDPs using a factored
    state representation. In: Int. Conf. on Artificial Intelligence Planning and Scheduling
    (2000)'
- author: M. Hauskrecht
  doi: 10.1613/jair.678
  first-page: '33'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Hauskrecht, M.: Value function approximations for partially observable
    Markov decision processes. Journal of Artificial Intelligence Research 13, 33–95
    (2000)'
  volume: '13'
  year: '2000'
- author: M. Hauskrecht
  doi: 10.1016/S0933-3657(99)00042-1
  first-page: '221'
  journal-title: Artificial Intelligence in Medicine
  unstructured: 'Hauskrecht, M., Fraser, H.: Planning treatment of ischemic heart
    disease with partially observable Markov decision processes. Artificial Intelligence
    in Medicine 18, 221–244 (2000)'
  volume: '18'
  year: '2000'
- author: S. Hochreiter
  doi: 10.1162/neco.1997.9.8.1735
  first-page: '1735'
  issue: '8'
  journal-title: Neural Computation
  unstructured: 'Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation 9(8),
    1735–1780 (1997)'
  volume: '9'
  year: '1997'
- author: J. Hoey
  doi: 10.1109/TPAMI.2007.1145
  first-page: '1'
  issue: '7'
  journal-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  unstructured: 'Hoey, J., Little, J.J.: Value-directed human behavior analysis from
    video using partially observable Markov decision processes. IEEE Transactions
    on Pattern Analysis and Machine Intelligence 29(7), 1–15 (2007)'
  volume: '29'
  year: '2007'
- unstructured: 'Hoey, J., Poupart, P.: Solving POMDPs with continuous or large discrete
    observation spaces. In: Proc. Int. Joint Conf. on Artificial Intelligence (2005)'
- doi: 10.1109/ROBOT.2007.364201
  unstructured: 'Hsiao, K., Kaelbling, L., Lozano-Perez, T.: Grasping pomdps. In:
    Proc. of the IEEE Int. Conf. on Robotics and Automation, pp. 4685–4692 (2007)'
- unstructured: 'Jaakkola, T., Singh, S.P., Jordan, M.I.: Reinforcement learning algorithm
    for partially observable Markov decision problems. In: Advances in Neural Information
    Processing Systems, vol. 7 (1995)'
- author: R. Jaulmes
  doi: 10.1007/11564096_59
  first-page: '601'
  series-title: Lecture Notes in Artificial Intelligence
  unstructured: 'Jaulmes, R., Pineau, J., Precup, D.: Active Learning in Partially
    Observable Markov Decision Processes. In: Gama, J., Camacho, R., Brazdil, P.B.,
    Jorge, A.M., Torgo, L. (eds.) ECML 2005. LNCS (LNAI), vol. 3720, pp. 601–608.
    Springer, Heidelberg (2005)'
  volume-title: 'Machine Learning: ECML 2005'
  year: '2005'
- author: L.P. Kaelbling
  doi: 10.1016/S0004-3702(98)00023-X
  first-page: '99'
  journal-title: Artificial Intelligence
  unstructured: 'Kaelbling, L.P., Littman, M.L., Cassandra, A.R.: Planning and acting
    in partially observable stochastic domains. Artificial Intelligence 101, 99–134
    (1998)'
  volume: '101'
  year: '1998'
- unstructured: 'Kearns, M., Mansour, Y., Ng, A.Y.: Approximate planning in large
    POMDPs via reusable trajectories. In: Advances in Neural Information Processing
    Systems, vol. 12. MIT Press (2000)'
- unstructured: 'Koenig, S., Simmons, R.: Unsupervised learning of probabilistic models
    for robot navigation. In: Proc. of the IEEE Int. Conf. on Robotics and Automation
    (1996)'
- doi: 10.15607/RSS.2008.IV.009
  unstructured: 'Kurniawati, H., Hsu, D., Lee, W.: SARSOP: Efficient point-based POMDP
    planning by approximating optimally reachable belief spaces. In: Robotics: Science
    and Systems (2008)'
- unstructured: 'Lin, L., Mitchell, T.: Memory approaches to reinforcement learning
    in non-Markovian domains. Tech. rep., Carnegie Mellon University, Pittsburgh,
    PA, USA (1992)'
- author: Z.Z. Lin
  doi: 10.1287/ijoc.1020.0024
  first-page: '27'
  issue: '1'
  journal-title: INFORMS Journal on Computing
  unstructured: 'Lin, Z.Z., Bean, J.C., White, C.C.: A hybrid genetic/optimization
    algorithm for finite horizon, partially observed Markov decision processes. INFORMS
    Journal on Computing 16(1), 27–38 (2004)'
  volume: '16'
  year: '2004'
- author: M.L. Littman
  first-page: '238'
  unstructured: 'Littman, M.L.: Memoryless policies: theoretical limitations and practical
    results. In: Proc. of the 3rd Int. Conf. on Simulation of Adaptive Behavior: from
    Animals to Animats 3, pp. 238–245. MIT Press, Cambridge (1994)'
  volume-title: 'Proc. of the 3rd Int. Conf. on Simulation of Adaptive Behavior :
    from Animals to Animats 3'
  year: '1994'
- unstructured: 'Littman, M.L.: Algorithms for sequential decision making. PhD thesis,
    Brown University (1996)'
- doi: 10.1016/B978-1-55860-377-6.50052-9
  unstructured: 'Littman, M.L., Cassandra, A.R., Kaelbling, L.P.: Learning policies
    for partially observable environments: Scaling up. In: International Conference
    on Machine Learning (1995)'
- unstructured: 'Littman, M.L., Sutton, R.S., Singh, S.: Predictive representations
    of state. In: Advances in Neural Information Processing Systems, vol. 14. MIT
    Press (2002)'
- unstructured: 'Loch, J., Singh, S.: Using eligibility traces to find the best memoryless
    policy in partially observable Markov decision processes. In: International Conference
    on Machine Learning (1998)'
- author: W.S. Lovejoy
  doi: 10.1287/opre.39.1.162
  first-page: '162'
  issue: '1'
  journal-title: Operations Research
  unstructured: 'Lovejoy, W.S.: Computationally feasible bounds for partially observed
    Markov decision processes. Operations Research 39(1), 162–175 (1991)'
  volume: '39'
  year: '1991'
- author: O. Madani
  doi: 10.1016/S0004-3702(02)00378-8
  first-page: '5'
  issue: 1-2
  journal-title: Artificial Intelligence
  unstructured: 'Madani, O., Hanks, S., Condon, A.: On the undecidability of probabilistic
    planning and related stochastic optimization problems. Artificial Intelligence 147(1-2),
    5–34 (2003)'
  volume: '147'
  year: '2003'
- doi: 10.1016/B978-1-55860-307-3.50031-9
  unstructured: 'McCallum, R.A.: Overcoming incomplete perception with utile distinction
    memory. In: International Conference on Machine Learning (1993)'
- doi: 10.1016/B978-1-55860-377-6.50055-4
  unstructured: 'McCallum, R.A.: Instance-based utile distinctions for reinforcement
    learning with hidden state. In: International Conference on Machine Learning (1995)'
- unstructured: 'McCallum, R.A.: Reinforcement learning with selective perception
    and hidden state. PhD thesis, University of Rochester (1996)'
- unstructured: 'Meuleau, N., Kim, K.E., Kaelbling, L.P., Cassandra, A.R.: Solving
    POMDPs by searching the space of finite policies. In: Proc. of Uncertainty in
    Artificial Intelligence (1999a)'
- unstructured: 'Meuleau, N., Peshkin, L., Kim, K.E., Kaelbling, L.P.: Learning finite-state
    controllers for partially observable environments. In: Proc. of Uncertainty in
    Artificial Intelligence (1999b)'
- doi: 10.1287/mnsc.28.1.1
  unstructured: 'Monahan, G.E.: A survey of partially observable Markov decision processes:
    theory, models and algorithms. Management Science 28(1) (1982)'
- unstructured: 'Ng, A.Y., Jordan, M.: PEGASUS: A policy search method for large MDPs
    and POMDPs. In: Proc. of Uncertainty in Artificial Intelligence (2000)'
- author: F.A. Oliehoek
  doi: 10.1613/jair.2447
  first-page: '289'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Oliehoek, F.A., Spaan, M.T.J., Vlassis, N.: Optimal and approximate
    Q-value functions for decentralized POMDPs. Journal of Artificial Intelligence
    Research 32, 289–353 (2008)'
  volume: '32'
  year: '2008'
- author: C.H. Papadimitriou
  doi: 10.1287/moor.12.3.441
  first-page: '441'
  issue: '3'
  journal-title: Mathematics of Operations Research
  unstructured: 'Papadimitriou, C.H., Tsitsiklis, J.N.: The complexity of Markov decision
    processes. Mathematics of Operations Research 12(3), 441–450 (1987)'
  volume: '12'
  year: '1987'
- unstructured: 'Parr, R., Russell, S.: Approximating optimal policies for partially
    observable stochastic domains. In: Proc. Int. Joint Conf. on Artificial Intelligence
    (1995)'
- unstructured: 'Peters, J., Bagnell, J.A.D.: Policy gradient methods. In: Springer
    Encyclopedia of Machine Learning. Springer, Heidelberg (2010)'
- author: J. Peters
  doi: 10.1016/j.neucom.2007.11.026
  first-page: '1180'
  journal-title: Neurocomputing
  unstructured: 'Peters, J., Schaal, S.: Natural actor-critic. Neurocomputing 71,
    1180–1190 (2008)'
  volume: '71'
  year: '2008'
- unstructured: 'Pineau, J., Thrun, S.: An integrated approach to hierarchy and abstraction
    for POMDPs. Tech. Rep. CMU-RI-TR-02-21, Robotics Institute, Carnegie Mellon University
    (2002)'
- unstructured: 'Pineau, J., Gordon, G., Thrun, S.: Point-based value iteration: An
    anytime algorithm for POMDPs. In: Proc. Int. Joint Conf. on Artificial Intelligence
    (2003)'
- unstructured: 'Platzman, L.K.: A feasible computational approach to infinite-horizon
    partially-observed Markov decision problems. Tech. Rep. J-81-2, School of Industrial
    and Systems Engineering, Georgia Institute of Technology, reprinted in working
    notes AAAI, Fall Symposium on Planning with POMDPs (1981)'
- unstructured: 'Poon, K.M.: A fast heuristic algorithm for decision-theoretic planning.
    Master’s thesis, The Hong-Kong University of Science and Technology (2001)'
- unstructured: 'Porta, J.M., Spaan, M.T.J., Vlassis, N.: Robot planning in partially
    observable continuous domains. In: Robotics: Science and Systems (2005)'
- author: J.M. Porta
  first-page: '2329'
  journal-title: Journal of Machine Learning Research
  unstructured: 'Porta, J.M., Vlassis, N., Spaan, M.T.J., Poupart, P.: Point-based
    value iteration for continuous POMDPs. Journal of Machine Learning Research 7,
    2329–2367 (2006)'
  volume: '7'
  year: '2006'
- unstructured: 'Poupart, P.: Exploiting structure to efficiently solve large scale
    partially observable Markov decision processes. PhD thesis, University of Toronto
    (2005)'
- unstructured: 'Poupart, P., Boutilier, C.: Bounded finite state controllers. In:
    Advances in Neural Information Processing Systems, vol. 16. MIT Press (2004)'
- unstructured: 'Poupart, P., Vlassis, N.: Model-based Bayesian reinforcement learning
    in partially observable domains. In: International Symposium on Artificial Intelligence
    and Mathematics, ISAIM (2008)'
- doi: 10.1145/1143844.1143932
  unstructured: 'Poupart, P., Vlassis, N., Hoey, J., Regan, K.: An analytic solution
    to discrete Bayesian reinforcement learning. In: International Conference on Machine
    Learning (2006)'
- unstructured: 'Ross, S., Chaib-draa, B., Pineau, J.: Bayes-adaptive POMDPs. In:
    Advances in Neural Information Processing Systems, vol. 20, pp. 1225–1232. MIT
    Press (2008a)'
- author: S. Ross
  doi: 10.1613/jair.2567
  first-page: '664'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Ross, S., Pineau, J., Paquet, S., Chaib-draa, B.: Online planning
    algorithms for POMDPs. Journal of Artificial Intelligence Research 32, 664–704
    (2008b)'
  volume: '32'
  year: '2008'
- unstructured: 'Roy, N., Gordon, G.: Exponential family PCA for belief compression
    in POMDPs. In: Advances in Neural Information Processing Systems, vol. 15. MIT
    Press (2003)'
- unstructured: 'Roy, N., Thrun, S.: Coastal navigation with mobile robots. In: Advances
    in Neural Information Processing Systems, vol. 12. MIT Press (2000)'
- author: N. Roy
  doi: 10.1016/j.artint.2005.06.002
  first-page: '1'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Roy, N., Gordon, G., Thrun, S.: Finding approximate POMDP solutions
    through belief compression. Journal of Artificial Intelligence Research 23, 1–40
    (2005)'
  volume: '23'
  year: '2005'
- unstructured: 'Sanner, S., Kersting, K.: Symbolic dynamic programming for first-order
    POMDPs. In: Proc. of the National Conference on Artificial Intelligence (2010)'
- author: J.K. Satia
  doi: 10.1287/mnsc.20.1.1
  first-page: '1'
  issue: '1'
  journal-title: Management Science
  unstructured: 'Satia, J.K., Lave, R.E.: Markovian decision processes with probabilistic
    observation of states. Management Science 20(1), 1–13 (1973)'
  volume: '20'
  year: '1973'
- doi: 10.1007/s10458-007-9026-5
  unstructured: 'Seuken, S., Zilberstein, S.: Formal models and algorithms for decentralized
    decision making under uncertainty. Autonomous Agents and Multi-Agent Systems (2008)'
- author: G. Shani
  first-page: '1249'
  unstructured: 'Shani, G., Brafman, R.I.: Resolving perceptual aliasing in the presence
    of noisy sensors. In: Saul, L.K., Weiss, Y., Bottou, L. (eds.) Advances in Neural
    Information Processing Systems, vol. 17, pp. 1249–1256. MIT Press, Cambridge (2005)'
  volume-title: Advances in Neural Information Processing Systems
  year: '2005'
- author: G. Shani
  doi: 10.1007/11564096_35
  first-page: '353'
  series-title: Lecture Notes in Artificial Intelligence
  unstructured: 'Shani, G., Brafman, R.I., Shimony, S.E.: Model-Based Online Learning
    of POMDPs. In: Gama, J., Camacho, R., Brazdil, P.B., Jorge, A.M., Torgo, L. (eds.)
    ECML 2005. LNCS (LNAI), vol. 3720, pp. 353–364. Springer, Heidelberg (2005)'
  volume-title: 'Machine Learning: ECML 2005'
  year: '2005'
- unstructured: 'Shani, G., Brafman, R.I., Shimony, S.E.: Forward search value iteration
    for POMDPs. In: Proc. Int. Joint Conf. on Artificial Intelligence (2007)'
- unstructured: 'Shani, G., Poupart, P., Brafman, R.I., Shimony, S.E.: Efficient ADD
    operations for point-based algorithms. In: Int. Conf. on Automated Planning and
    Scheduling (2008)'
- unstructured: 'Silver, D., Veness, J.: Monte-carlo planning in large POMDPs. In:
    Lafferty, J., Williams, C.K.I., Shawe-Taylor, J., Zemel, R., Culotta, A. (eds.)
    Advances in Neural Information Processing Systems, vol. 23, pp. 2164–2172 (2010)'
- unstructured: 'Simmons, R., Koenig, S.: Probabilistic robot navigation in partially
    observable environments. In: Proc. Int. Joint Conf. on Artificial Intelligence
    (1995)'
- doi: 10.1016/B978-1-55860-335-6.50042-8
  unstructured: 'Singh, S., Jaakkola, T., Jordan, M.: Learning without state-estimation
    in partially observable Markovian decision processes. In: International Conference
    on Machine Learning (1994)'
- unstructured: 'Singh, S., James, M.R., Rudary, M.R.: Predictive state representations:
    A new theory for modeling dynamical systems. In: Proc. of Uncertainty in Artificial
    Intelligence (2004)'
- author: R.D. Smallwood
  doi: 10.1287/opre.21.5.1071
  first-page: '1071'
  journal-title: Operations Research
  unstructured: 'Smallwood, R.D., Sondik, E.J.: The optimal control of partially observable
    Markov decision processes over a finite horizon. Operations Research 21, 1071–1088
    (1973)'
  volume: '21'
  year: '1973'
- unstructured: 'Smith, T., Simmons, R.: Heuristic search value iteration for POMDPs.
    In: Proc. of Uncertainty in Artificial Intelligence (2004)'
- unstructured: 'Smith, T., Simmons, R.: Point-based POMDP algorithms: Improved analysis
    and implementation. In: Proc. of Uncertainty in Artificial Intelligence (2005)'
- unstructured: 'Sondik, E.J.: The optimal control of partially observable Markov
    processes. PhD thesis, Stanford University (1971)'
- doi: 10.1109/ROBOT.2004.1307420
  unstructured: 'Spaan, M.T.J., Vlassis, N.: A point-based POMDP algorithm for robot
    planning. In: Proc. of the IEEE Int. Conf. on Robotics and Automation (2004)'
- author: M.T.J. Spaan
  doi: 10.1613/jair.1659
  first-page: '195'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: 'Spaan, M.T.J., Vlassis, N.: Perseus: Randomized point-based value
    iteration for POMDPs. Journal of Artificial Intelligence Research 24, 195–220
    (2005a)'
  volume: '24'
  year: '2005'
- unstructured: 'Spaan, M.T.J., Vlassis, N.: Planning with continuous actions in partially
    observable environments. In: Proc. of the IEEE Int. Conf. on Robotics and Automation
    (2005b)'
- doi: 10.1109/IROS.2010.5648856
  unstructured: 'Spaan, M.T.J., Veiga, T.S., Lima, P.U.: Active cooperative perception
    in network robot systems using POMDPs. In: Proc. of International Conference on
    Intelligent Robots and Systems (2010)'
- author: M. Sridharan
  doi: 10.1016/j.artint.2010.04.022
  first-page: '704'
  journal-title: Artificial Intelligence
  unstructured: 'Sridharan, M., Wyatt, J., Dearden, R.: Planning to see: A hierarchical
    approach to planning visual actions on a robot using POMDPs. Artificial Intelligence 174,
    704–725 (2010)'
  volume: '174'
  year: '2010'
- author: B. Stankiewicz
  doi: 10.1109/TSMCA.2007.897713
  first-page: '970'
  issue: '6'
  journal-title: 'IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems
    and Humans'
  unstructured: 'Stankiewicz, B., Cassandra, A., McCabe, M., Weathers, W.: Development
    and evaluation of a Bayesian low-vision navigation aid. IEEE Transactions on Systems,
    Man and Cybernetics, Part A: Systems and Humans 37(6), 970–983 (2007)'
  volume: '37'
  year: '2007'
- author: R.L. Stratonovich
  doi: 10.1137/1105015
  first-page: '156'
  issue: '2'
  journal-title: Theory of Probability and Its Applications
  unstructured: 'Stratonovich, R.L.: Conditional Markov processes. Theory of Probability
    and Its Applications 5(2), 156–178 (1960)'
  volume: '5'
  year: '1960'
- doi: 10.1109/TNN.1998.712192
  unstructured: 'Sutton, R.S., Barto, A.G.: Reinforcement Learning: An Introduction.
    MIT Press (1998)'
- unstructured: 'Theocharous, G., Mahadevan, S.: Approximate planning with hierarchical
    partially observable Markov decision processes for robot navigation. In: Proc.
    of the IEEE Int. Conf. on Robotics and Automation (2002)'
- unstructured: 'Thrun, S.: Monte Carlo POMDPs. In: Advances in Neural Information
    Processing Systems, vol. 12. MIT Press (2000)'
- unstructured: 'Thrun, S., Burgard, W., Fox, D.: Probabilistic Robotics. MIT Press
    (2005)'
- doi: 10.1145/1082473.1082621
  unstructured: 'Varakantham, P., Maheswaran, R., Tambe, M.: Exploiting belief bounds:
    Practical POMDPs for personal assistant agents. In: Proc. of Int. Conference on
    Autonomous Agents and Multi Agent Systems (2005)'
- doi: 10.1145/1553374.1553512
  unstructured: 'Vlassis, N., Toussaint, M.: Model-free reinforcement learning as
    mixture learning. In: International Conference on Machine Learning, pp. 1081–1088.
    ACM (2009)'
- unstructured: 'Wang, C., Khardon, R.: Relational partially observable MDPs. In:
    Proc. of the National Conference on Artificial Intelligence (2010)'
- doi: 10.1007/BF02204836
  unstructured: 'White, C.C.: Partially observed Markov decision processes: a survey.
    Annals of Operations Research 32 (1991)'
- author: M. Wiering
  doi: 10.1177/105971239700600202
  first-page: '219'
  issue: '2'
  journal-title: Adaptive Behavior
  unstructured: 'Wiering, M., Schmidhuber, J.: HQ-learning. Adaptive Behavior 6(2),
    219–246 (1997)'
  volume: '6'
  year: '1997'
- doi: 10.1145/1015330.1015346
  unstructured: 'Wierstra, D., Wiering, M.: Utile distinction hidden Markov models.
    In: International Conference on Machine Learning (2004)'
- author: J.D. Williams
  doi: 10.1016/j.csl.2006.06.008
  first-page: '393'
  issue: '2'
  journal-title: Computer Speech and Language
  unstructured: 'Williams, J.D., Young, S.: Partially observable Markov decision processes
    for spoken dialog systems. Computer Speech and Language 21(2), 393–422 (2007)'
  volume: '21'
  year: '2007'
- unstructured: 'Williams, J.K., Singh, S.: Experimental results on learning stochastic
    memoryless policies for partially observable Markov decision processes. In: Advances
    in Neural Information Processing Systems, vol. 11 (1999)'
- unstructured: 'Zhang, N.L., Liu, W.: Planning in stochastic domains: problem characteristics
    and approximations. Tech. Rep. HKUST-CS96-31, Department of Computer Science,
    The Hong Kong University of Science and Technology (1996)'
- unstructured: 'Zhou, R., Hansen, E.A.: An improved grid-based approximation algorithm
    for POMDPs. In: Proc. Int. Joint Conf. on Artificial Intelligence (2001)'
doi: 10.1007/978-3-642-27645-3_12
isbn:
- '9783642276446'
- '9783642276453'
journal: Adaptation, Learning, and Optimization
pages: 387--414
publisher: Springer Berlin Heidelberg
title: Partially Observable Markov Decision Processes
type: inbook
url: http://dx.doi.org/10.1007/978-3-642-27645-3_12
year: 2012
