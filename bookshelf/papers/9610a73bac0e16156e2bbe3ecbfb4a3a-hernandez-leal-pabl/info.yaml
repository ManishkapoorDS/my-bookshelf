abstract: 'Deep reinforcement learning (RL) has achieved outstanding results in recent
  years. This has led to a dramatic increase in the number of applications and methods.
  Recent works have explored learning beyond single-agent scenarios and have considered
  multiagent learning (MAL) scenarios. Initial results report successes in complex
  multiagent domains, although there are several challenges to be addressed. The primary
  goal of this article is to provide a clear overview of current multiagent deep reinforcement
  learning (MDRL) literature. Additionally, we complement the overview with a broader
  analysis: (i) we revisit previous key components, originally presented in MAL and
  RL, and highlight how they have been adapted to multiagent deep reinforcement learning
  settings. (ii) We provide general guidelines to new practitioners in the area: describing
  lessons learned from MDRL works, pointing to recent benchmarks, and outlining open
  avenues of research. (iii) We take a more critical tone raising practical challenges
  of MDRL (e.g., implementation and computational demands). We expect this article
  will help unify and motivate future research to take advantage of the abundant literature
  that exists (e.g., RL and MAL) in a joint effort to promote fruitful research in
  the multiagent community.'
archiveprefix: arXiv
author: Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E.
author_list:
- family: Hernandez-Leal
  given: Pablo
- family: Kartal
  given: Bilal
- family: Taylor
  given: Matthew E.
doi: 10.1007/s10458-019-09421-1
eprint: 1810.05587v3
file: 1810.05587v3.pdf
files:
- hernandez-leal-pablo-and-kartal-bilal-and-taylor-matthew-e.a-survey-and-critique-of-multiagent-deep-reinforcement-learning2018.pdf
month: Oct
primaryclass: cs.MA
ref: 1810.05587v3
time-added: 2020-06-10-12:06:38
title: A Survey and Critique of Multiagent Deep Reinforcement Learning
type: article
url: http://arxiv.org/abs/1810.05587v3
year: '2018'
