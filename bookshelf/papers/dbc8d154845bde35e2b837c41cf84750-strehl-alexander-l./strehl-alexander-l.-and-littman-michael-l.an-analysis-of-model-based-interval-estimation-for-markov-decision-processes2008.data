https://api.elsevier.com/content/article/pii/S0022000008000767 doi:10.1016/j.jcss.2007.08.009 1-s2.0-S0022000008000767 10.1016/j.jcss.2007.08.009 S0022-0000(08)00076-7 An analysis of model-based Interval Estimation for Markov Decision Processes  Journal of Computer and System Sciences Journal 00220000 74 8 1309 1331 1309-1331 8 text/plain 2008-12-31 December 2008 Copyright © 2008 Elsevier Inc. All rights reserved. Elsevier Inc. Learning Theory 2005 Strehl, Alexander L. Littman, Michael L. 
               Abstract
               
                  Several algorithms for learning near-optimal policies in Markov Decision Processes have been analyzed and proven efficient. Empirical results have suggested that Model-based Interval Estimation (MBIE) learns efficiently in practice, effectively balancing exploration and exploitation. This paper presents a theoretical analysis of MBIE and a new variation called MBIE-EB, proving their efficiency even under worst-case conditions. The paper also introduces a new performance metric, average loss, and relates it to its less “online” cousins from the literature.
               
             1 true Full true  ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ Reinforcement learning Learning theory Markov Decision Processes    55549110436 2-s2.0-55549110436   