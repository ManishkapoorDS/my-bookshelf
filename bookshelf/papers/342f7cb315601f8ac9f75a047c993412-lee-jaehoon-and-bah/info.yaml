abstract: It has long been known that a single-layer fully-connected neural network
  with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP),
  in the limit of infinite network width. This correspondence enables exact Bayesian
  inference for infinite width neural networks on regression tasks by means of evaluating
  the corresponding GP. Recently, kernel functions which mimic multi-layer random
  neural networks have been developed, but only outside of a Bayesian framework. As
  such, previous work has not identified that these kernels can be used as covariance
  functions for GPs and allow fully Bayesian prediction with a deep neural network.   In
  this work, we derive the exact equivalence between infinitely wide deep networks
  and GPs. We further develop a computationally efficient pipeline to compute the
  covariance function for these GPs. We then use the resulting GPs to perform Bayesian
  inference for wide deep neural networks on MNIST and CIFAR-10. We observe that trained
  neural network accuracy approaches that of the corresponding GP with increasing
  layer width, and that the GP uncertainty is strongly correlated with trained network
  prediction error. We further find that test performance increases as finite-width
  trained networks are made wider and more similar to a GP, and thus that GP predictions
  typically outperform those of finite-width networks. Finally we connect the performance
  of these GPs to the recent theory of signal propagation in random neural networks.
archiveprefix: arXiv
author: Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S.
  and Pennington, Jeffrey and Sohl-Dickstein, Jascha
author_list:
- family: Lee
  given: Jaehoon
- family: Bahri
  given: Yasaman
- family: Novak
  given: Roman
- family: Schoenholz
  given: Samuel S.
- family: Pennington
  given: Jeffrey
- family: Sohl-Dickstein
  given: Jascha
eprint: 1711.00165v3
file: 1711.00165v3.pdf
files:
- lee-jaehoon-and-bahri-yasaman-and-novak-roman-and-schoenholz-samuel-s.-and-pennington-jeffrey-and-sohl-dickstein-jaschadeep-neural-networks-as-g.pdf
month: Nov
primaryclass: stat.ML
ref: 1711.00165v3
title: Deep Neural Networks as Gaussian Processes
type: article
url: http://arxiv.org/abs/1711.00165v3
year: '2017'
