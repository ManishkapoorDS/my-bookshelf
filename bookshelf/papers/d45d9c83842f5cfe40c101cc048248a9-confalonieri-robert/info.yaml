abstract: Explainability in Artificial Intelligence has been revived as a topic of
  active research by the need of conveying safety and trust to users in the `how'
  and `why' of automated decision-making. Whilst a plethora of approaches have been
  developed for post-hoc explainability, only a few focus on how to use domain knowledge,
  and how this influences the understandability of global explanations from the users'
  perspective. In this paper, we show how ontologies help the understandability of
  global post-hoc explanations, presented in the form of symbolic models. In particular,
  we build on Trepan, an algorithm that explains artificial neural networks by means
  of decision trees, and we extend it to include ontologies modeling domain knowledge
  in the process of generating explanations. We present the results of a user study
  that measures the understandability of decision trees using a syntactic complexity
  measure, and through time and accuracy of responses as well as reported user confidence
  and understandability. The user study considers domains where explanations are critical,
  namely, in finance and medicine. The results show that decision trees generated
  with our algorithm, taking into account domain knowledge, are more understandable
  than those generated by standard Trepan without the use of ontologies.
archiveprefix: arXiv
author: Confalonieri, Roberto and Weyde, Tillman and Besold, Tarek R. and del Prado
  Martín, Fermín Moscoso
author_list:
- family: Confalonieri
  given: Roberto
- family: Weyde
  given: Tillman
- family: Besold
  given: Tarek R.
- family: del Prado Martín
  given: Fermín Moscoso
eprint: 1906.08362v2
file: 1906.08362v2.pdf
files:
- confalonieri-roberto-and-weyde-tillman-and-besold-tarek-r.-and-del-prado-martin-fermin-moscosotrepan-reloaded-a-knowledge-driven-approach-to-expl.pdf
month: Jun
primaryclass: cs.AI
ref: 1906.08362v2
time-added: 2020-09-03-12:31:25
title: 'Trepan Reloaded: A Knowledge-driven Approach to Explaining Artificial   Neural
  Networks'
type: article
url: http://arxiv.org/abs/1906.08362v2
year: '2019'
