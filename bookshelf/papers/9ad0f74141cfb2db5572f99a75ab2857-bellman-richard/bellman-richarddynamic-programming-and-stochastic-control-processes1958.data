https://api.elsevier.com/content/article/pii/S0019995858800030 doi:10.1016/S0019-9958(58)80003-0 1-s2.0-S0019995858800030 10.1016/S0019-9958(58)80003-0 S0019-9958(58)80003-0 Dynamic programming and stochastic control processes  Information and Control Journal 00199958 1 3 228 239 228-239 3 text/plain 1958-09-30 September 1958 Copyright © 1958 Published by Elsevier Inc. Published by Elsevier Inc. Bellman, Richard 
               
                  Consider a system S specified at any time t by a finite dimensional vector x(t) satisfying a vector differential equation dx/dt = g[x, r(t), f(t)], x(0) = c, where c is the initial state, r(t) is a random forcing term possessing a known distribution, and f(t) is a forcing term chosen, via a feedback process, so as to minimize the expected value of a functional J(x) = ƒ0
                     
                        T
                      
                     h(x − y, t) dG(t), where y(t) is a known function, or chosen so as to minimize the functional defined by the probability that max0 ≦ t ≦ T
                      
                     h(x − y, t) exceed a specified bound. It is shown how the functional equation technique of dynamic programming may be used to obtain a new computational and analytic approach to problems of this genre. The limited memory capacity of present-day digital computers limits the routine application of these techniques to first and second order systems at the moment, with limited application to higher order systems.
               
             1 true Full true  ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/    0011743913 2-s2.0-0011743913   