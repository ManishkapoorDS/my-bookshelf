abstract: 'Backpropagation is driving today''s artificial neural networks (ANNs).
  However, despite extensive research, it remains unclear if the brain implements
  this algorithm. Among neuroscientists, reinforcement learning (RL) algorithms are
  often seen as a realistic alternative: neurons can randomly introduce change, and
  use unspecific feedback signals to observe their effect on the cost and thus approximate
  their gradient. However, the convergence rate of such learning scales poorly with
  the number of involved neurons. Here we propose a hybrid learning approach. Each
  neuron uses an RL-type strategy to learn how to approximate the gradients that backpropagation
  would provide. We provide proof that our approach converges to the true gradient
  for certain classes of networks. In both feedforward and convolutional networks,
  we empirically show that our approach learns to approximate the gradient, and can
  match the performance of gradient-based learning. Learning feedback weights provides
  a biologically plausible mechanism of achieving good performance, without the need
  for precise, pre-specified learning rules.'
archiveprefix: arXiv
author: Lansdell, Benjamin James and Prakash, Prashanth Ravi and Kording, Konrad Paul
author_list:
- family: Lansdell
  given: Benjamin James
- family: Prakash
  given: Prashanth Ravi
- family: Kording
  given: Konrad Paul
eprint: 1906.00889v3
file: 1906.00889v3.pdf
files:
- lansdell-benjamin-james-and-prakash-prashanth-ravi-and-kording-konrad-paullearning-to-solve-the-credit-assignment-problem2019.pdf
month: Jun
primaryclass: q-bio.NC
ref: 1906.00889v3
title: Learning to solve the credit assignment problem
type: article
url: http://arxiv.org/abs/1906.00889v3
year: '2019'
